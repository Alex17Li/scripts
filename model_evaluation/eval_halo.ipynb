{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dl.dataset.datamodes.npz import rectifiedrgb, debayeredrgb\n",
    "from dl.config.label_map_helper import LabelMapHelper, LabelConversion\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dirs = [\n",
    "    Path('/mnt/sandbox1/alex.li/introspection/25079_alleyson'),\n",
    "    Path('/mnt/sandbox1/alex.li/introspection/25080_alleyson'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/sandbox1/alex.li/introspection/25079_alleyson/halo_productivity_combined_no_mislocalization_alleyson/results.txt\n",
      "\n",
      "General metrics. Note TPs and FNs are based on gt_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']                 and pred_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']:\n",
      "true_positive: 0\n",
      "true_negative: 180576\n",
      "false_positive: 3387\n",
      "false_negative: 0\n",
      "precision_image: 0.0\n",
      "recall_image: nan\n",
      "f1_image: 0.0\n",
      "productivity_image: 0.9815886890298593\n",
      "\n",
      "Strict metrics on humans:\n",
      "human_true_positive: 0\n",
      "human_true_negative: 181305\n",
      "human_false_positive: 2658\n",
      "human_false_negative: 0\n",
      "human_precision_image: 0.0\n",
      "human_recall_image: nan\n",
      "human_f1_image: 0.0\n",
      "human_productivity_image: 0.985551442409615\n",
      "\n",
      "Strict metrics on vehicles:\n",
      "vehicle_true_positive: 0\n",
      "vehicle_true_negative: 183708\n",
      "vehicle_false_positive: 255\n",
      "vehicle_false_negative: 0\n",
      "vehicle_precision_image: 0.0\n",
      "vehicle_recall_image: nan\n",
      "vehicle_f1_image: 0.0\n",
      "vehicle_productivity_image: 0.9986138516984394\n",
      "\n",
      "General metrics per operation time and camera pod:\n",
      "Some nan or bad values found in operation_time or camera_location columns. Below results are not accurate.\n",
      "day_fp: 1300\n",
      "night_fp: 2087\n",
      "front_fp: 0\n",
      "rear_fp: 3387\n",
      "day_front_fp: 0\n",
      "day_rear_fp: 1300\n",
      "night_front_fp: 0\n",
      "night_rear_fp: 2087\n",
      "\n",
      "/mnt/sandbox1/alex.li/introspection/25079_alleyson/halo_rgb_stereo_test_v6_2_alleysson/results.txt\n",
      "\n",
      "General metrics. Note TPs and FNs are based on gt_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']                 and pred_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']:\n",
      "true_positive: 17140\n",
      "true_negative: 39689\n",
      "false_positive: 775\n",
      "false_negative: 2641\n",
      "precision_image: 0.9567401618755234\n",
      "recall_image: 0.8664880440827056\n",
      "f1_image: 0.9093803056027164\n",
      "productivity_image: 0.9808471727955713\n",
      "\n",
      "Strict metrics on humans:\n",
      "human_true_positive: 10023\n",
      "human_true_negative: 48467\n",
      "human_false_positive: 1127\n",
      "human_false_negative: 628\n",
      "human_precision_image: 0.8989237668161435\n",
      "human_recall_image: 0.9410384001502207\n",
      "human_f1_image: 0.9194991055456172\n",
      "human_productivity_image: 0.9772754768722023\n",
      "\n",
      "Strict metrics on vehicles:\n",
      "vehicle_true_positive: 1977\n",
      "vehicle_true_negative: 56457\n",
      "vehicle_false_positive: 1669\n",
      "vehicle_false_negative: 142\n",
      "vehicle_precision_image: 0.5422380691168404\n",
      "vehicle_recall_image: 0.9329872581406323\n",
      "vehicle_f1_image: 0.6858629661751952\n",
      "vehicle_productivity_image: 0.9712865155008086\n",
      "\n",
      "General metrics per operation time and camera pod:\n",
      "Some nan or bad values found in operation_time or camera_location columns. Below results are not accurate.\n",
      "day_safety: 0.8586204580562832\n",
      "night_safety: 0.8904333605887162\n",
      "front_safety: nan\n",
      "rear_safety: 0.8664880440827056\n",
      "day_front_safety: nan\n",
      "day_rear_safety: 0.8586204580562832\n",
      "night_front_safety: nan\n",
      "night_rear_safety: 0.8904333605887162\n",
      "\n",
      "/mnt/sandbox1/alex.li/introspection/25079_alleyson/halo_humans_on_path_test_v6_2_8_mainline_alleysson/results.txt\n",
      "\n",
      "General metrics. Note TPs and FNs are based on gt_classes ['Humans']                 and pred_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']:\n",
      "true_positive: 7709\n",
      "true_negative: 3457\n",
      "false_positive: 290\n",
      "false_negative: 87\n",
      "precision_image: 0.9637454681835229\n",
      "recall_image: 0.9888404309902514\n",
      "f1_image: 0.9761316872427983\n",
      "productivity_image: 0.9226047504670403\n",
      "\n",
      "Strict metrics on humans:\n",
      "human_true_positive: 7539\n",
      "human_true_negative: 3694\n",
      "human_false_positive: 53\n",
      "human_false_negative: 257\n",
      "human_precision_image: 0.9930189673340358\n",
      "human_recall_image: 0.9670343766033863\n",
      "human_f1_image: 0.9798544320249545\n",
      "human_productivity_image: 0.9858553509474246\n",
      "\n",
      "General metrics per operation time and camera pod:\n",
      "Some nan or bad values found in operation_time or camera_location columns. Below results are not accurate.\n",
      "day_safety: 0.9879941434846267\n",
      "night_safety: 0.994824016563147\n",
      "front_safety: nan\n",
      "rear_safety: 0.9888404309902514\n",
      "day_front_safety: nan\n",
      "day_rear_safety: 0.9879941434846267\n",
      "night_front_safety: nan\n",
      "night_rear_safety: 0.994824016563147\n",
      "\n",
      "/mnt/sandbox1/alex.li/introspection/25080_alleyson/labelbox_import_tire_tracks_100k_diverse/results.txt\n",
      "\n",
      "General metrics. Note TPs and FNs are based on gt_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']                 and pred_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']:\n",
      "true_positive: 0\n",
      "true_negative: 46315\n",
      "false_positive: 4130\n",
      "false_negative: 0\n",
      "precision_image: 0.0\n",
      "recall_image: nan\n",
      "f1_image: 0.0\n",
      "productivity_image: 0.9181286549707602\n",
      "\n",
      "Strict metrics on humans:\n",
      "human_true_positive: 0\n",
      "human_true_negative: 49515\n",
      "human_false_positive: 930\n",
      "human_false_negative: 0\n",
      "human_precision_image: 0.0\n",
      "human_recall_image: nan\n",
      "human_f1_image: 0.0\n",
      "human_productivity_image: 0.9815640796907523\n",
      "\n",
      "Strict metrics on vehicles:\n",
      "vehicle_true_positive: 0\n",
      "vehicle_true_negative: 49853\n",
      "vehicle_false_positive: 592\n",
      "vehicle_false_negative: 0\n",
      "vehicle_precision_image: 0.0\n",
      "vehicle_recall_image: nan\n",
      "vehicle_f1_image: 0.0\n",
      "vehicle_productivity_image: 0.9882644464268014\n",
      "\n",
      "General metrics per operation time and camera pod:\n",
      "Some nan or bad values found in operation_time or camera_location columns. Below results are not accurate.\n",
      "day_fp: 4075\n",
      "night_fp: 55\n",
      "front_fp: 0\n",
      "rear_fp: 4130\n",
      "day_front_fp: 0\n",
      "day_rear_fp: 4075\n",
      "night_front_fp: 0\n",
      "night_rear_fp: 55\n",
      "\n",
      "/mnt/sandbox1/alex.li/introspection/25080_alleyson/halo_humans_on_path_test_v6_2_8_mainline/results.txt\n",
      "\n",
      "General metrics. Note TPs and FNs are based on gt_classes ['Humans']                 and pred_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']:\n",
      "true_positive: 7946\n",
      "true_negative: 3605\n",
      "false_positive: 244\n",
      "false_negative: 89\n",
      "precision_image: 0.9702075702075702\n",
      "recall_image: 0.9889234598630989\n",
      "f1_image: 0.9794761171032358\n",
      "productivity_image: 0.9366069108859444\n",
      "\n",
      "Strict metrics on humans:\n",
      "human_true_positive: 7773\n",
      "human_true_negative: 3795\n",
      "human_false_positive: 54\n",
      "human_false_negative: 262\n",
      "human_precision_image: 0.9931008049060943\n",
      "human_recall_image: 0.9673926571250778\n",
      "human_f1_image: 0.9800781742529315\n",
      "human_productivity_image: 0.9859703819173812\n",
      "\n",
      "General metrics per operation time and camera pod:\n",
      "Some nan or bad values found in operation_time or camera_location columns. Below results are not accurate.\n",
      "day_safety: 0.987993857322351\n",
      "night_safety: 0.9965596330275229\n",
      "front_safety: nan\n",
      "rear_safety: 0.9889234598630989\n",
      "day_front_safety: nan\n",
      "day_rear_safety: 0.987993857322351\n",
      "night_front_safety: nan\n",
      "night_rear_safety: 0.9965596330275229\n",
      "\n",
      "/mnt/sandbox1/alex.li/introspection/25080_alleyson/halo_rgb_stereo_test_v6_2/results.txt\n",
      "\n",
      "General metrics. Note TPs and FNs are based on gt_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']                 and pred_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']:\n",
      "true_positive: 17798\n",
      "true_negative: 43890\n",
      "false_positive: 858\n",
      "false_negative: 2506\n",
      "precision_image: 0.9540094339622641\n",
      "recall_image: 0.8765760441292356\n",
      "f1_image: 0.9136550308008213\n",
      "productivity_image: 0.9808259587020649\n",
      "\n",
      "Strict metrics on humans:\n",
      "human_true_positive: 10668\n",
      "human_true_negative: 52305\n",
      "human_false_positive: 1336\n",
      "human_false_negative: 743\n",
      "human_precision_image: 0.8887037654115295\n",
      "human_recall_image: 0.9348873893611428\n",
      "human_f1_image: 0.9112107623318386\n",
      "human_productivity_image: 0.9750936783430585\n",
      "\n",
      "Strict metrics on vehicles:\n",
      "vehicle_true_positive: 2067\n",
      "vehicle_true_negative: 61041\n",
      "vehicle_false_positive: 1804\n",
      "vehicle_false_negative: 140\n",
      "vehicle_precision_image: 0.5339705502454146\n",
      "vehicle_recall_image: 0.93656547349343\n",
      "vehicle_f1_image: 0.6801579466929911\n",
      "vehicle_productivity_image: 0.9712944546105498\n",
      "\n",
      "General metrics per operation time and camera pod:\n",
      "Some nan or bad values found in operation_time or camera_location columns. Below results are not accurate.\n",
      "day_safety: 0.8746748482625225\n",
      "night_safety: 0.8819431368857089\n",
      "front_safety: nan\n",
      "rear_safety: 0.8765760441292356\n",
      "day_front_safety: nan\n",
      "day_rear_safety: 0.8746748482625225\n",
      "night_front_safety: nan\n",
      "night_rear_safety: 0.8819431368857089\n",
      "\n",
      "/mnt/sandbox1/alex.li/introspection/25080_alleyson/on_path_aft_humans_day_2024_rev2_v2/results.txt\n",
      "\n",
      "General metrics. Note TPs and FNs are based on gt_classes ['Humans']                 and pred_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']:\n",
      "true_positive: 1308\n",
      "true_negative: 130\n",
      "false_positive: 33\n",
      "false_negative: 15\n",
      "precision_image: 0.9753914988814317\n",
      "recall_image: 0.9886621315192744\n",
      "f1_image: 0.9819819819819819\n",
      "productivity_image: 0.7975460122699386\n",
      "\n",
      "Strict metrics on humans:\n",
      "human_true_positive: 1270\n",
      "human_true_negative: 157\n",
      "human_false_positive: 6\n",
      "human_false_negative: 53\n",
      "human_precision_image: 0.9952978056426333\n",
      "human_recall_image: 0.9599395313681028\n",
      "human_f1_image: 0.9772989611388996\n",
      "human_productivity_image: 0.9631901840490797\n",
      "\n",
      "General metrics per operation time and camera pod:\n",
      "day_safety: 0.9886621315192744\n",
      "night_safety: nan\n",
      "front_safety: nan\n",
      "rear_safety: 0.9886621315192744\n",
      "day_front_safety: nan\n",
      "day_rear_safety: 0.9886621315192744\n",
      "night_front_safety: nan\n",
      "night_rear_safety: nan\n",
      "\n",
      "/mnt/sandbox1/alex.li/introspection/25080_alleyson/halo_productivity_combined/results.txt\n",
      "\n",
      "General metrics. Note TPs and FNs are based on gt_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']                 and pred_classes ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']:\n",
      "true_positive: 0\n",
      "true_negative: 238324\n",
      "false_positive: 3141\n",
      "false_negative: 0\n",
      "precision_image: 0.0\n",
      "recall_image: nan\n",
      "f1_image: 0.0\n",
      "productivity_image: 0.9869919035885117\n",
      "\n",
      "Strict metrics on humans:\n",
      "human_true_positive: 0\n",
      "human_true_negative: 238831\n",
      "human_false_positive: 2634\n",
      "human_false_negative: 0\n",
      "human_precision_image: 0.0\n",
      "human_recall_image: nan\n",
      "human_f1_image: 0.0\n",
      "human_productivity_image: 0.98909158677241\n",
      "\n",
      "Strict metrics on vehicles:\n",
      "vehicle_true_positive: 0\n",
      "vehicle_true_negative: 241058\n",
      "vehicle_false_positive: 407\n",
      "vehicle_false_negative: 0\n",
      "vehicle_precision_image: 0.0\n",
      "vehicle_recall_image: nan\n",
      "vehicle_f1_image: 0.0\n",
      "vehicle_productivity_image: 0.9983144555111507\n",
      "\n",
      "General metrics per operation time and camera pod:\n",
      "Some nan or bad values found in operation_time or camera_location columns. Below results are not accurate.\n",
      "day_fp: 1421\n",
      "night_fp: 1720\n",
      "front_fp: 0\n",
      "rear_fp: 3141\n",
      "day_front_fp: 0\n",
      "day_rear_fp: 1421\n",
      "night_front_fp: 0\n",
      "night_rear_fp: 1720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_csvs = defaultdict(lambda:{})\n",
    "for model_dir in model_output_dirs:\n",
    "    dsets = os.listdir(model_dir)\n",
    "    for dset in dsets:\n",
    "        path = model_dir / dset / 'results.txt'\n",
    "        if os.path.exists(path):\n",
    "            print(path)\n",
    "            with open(path, 'r') as f:\n",
    "                print(''.join(f.readlines()))\n",
    "        if os.path.exists(model_dir / dset / 'output.csv'):\n",
    "            out_csvs[model_dir.name][dset] = pd.read_csv(model_dir / dset / 'output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'25079_alleyson': ['halo_productivity_combined_no_mislocalization_alleyson', 'halo_rgb_stereo_test_v6_2_alleysson', 'halo_humans_on_path_test_v6_2_8_mainline_alleysson'], '25080_alleyson': ['labelbox_import_tire_tracks_100k_diverse', 'halo_humans_on_path_test_v6_2_8_mainline', 'halo_rgb_stereo_test_v6_2', 'on_path_aft_humans_day_2024_rev2_v2', 'halo_productivity_combined']}\n"
     ]
    }
   ],
   "source": [
    "print({k: list(v.keys()) for (k, v) in out_csvs.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df):\n",
    "    fp = sum(df['human_state'] == 'false_positive')\n",
    "    tn = sum(df['human_state'] == 'true_negative')\n",
    "    tp_thresh = sum(df['human_state'] == 'true_positive')\n",
    "    fn_thresh = sum(df['human_state'] == 'false_negative')\n",
    "    try:\n",
    "        tp = sum(df['n_pred_human_pixels'] >= df['min_pixels_threshold'])\n",
    "        fn = sum((df['n_gt_human_pixels'] >= df['min_pixels_threshold']) & \n",
    "                  (df['n_pred_human_pixels'] < df['min_pixels_threshold']))\n",
    "    except KeyError:\n",
    "        tp = tp_thresh\n",
    "        fn = fn_thresh\n",
    "\n",
    "    if tp + fn < 20:\n",
    "        # not enough data to give a meaningful number\n",
    "        recall = float('nan')\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    if tp_thresh + fn_thresh < 20:\n",
    "        recall_thresh = float('nan')\n",
    "    else:\n",
    "        recall_thresh = tp_thresh / (tp_thresh + fn_thresh)\n",
    "    if fp + tn < 20:\n",
    "        prod = float('nan')\n",
    "    else:\n",
    "        prod = tn / (fp + tn)\n",
    "    return {'recall': recall, 'recall_thresh': recall_thresh, 'n': len(df), 'productivity': prod}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(a):\n",
    "    it = iter(a)\n",
    "    last = next(it)\n",
    "    for cur in it:\n",
    "        yield (last, cur)\n",
    "        last = cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_plot(df):\n",
    "    depth_barriers = [0, .2, .4, 1.01]\n",
    "    size_barriers = [72, 200, 400, 99999]\n",
    "    recall = [[0 for _ in range(len(size_barriers) - 1)] for _ in range(len(depth_barriers) - 1)]\n",
    "    all_metrics = []\n",
    "    for depth_ind, (depth_lo, depth_hi) in enumerate(pairwise(depth_barriers)):\n",
    "        for size_ind, (size_lo, size_hi) in enumerate(pairwise(size_barriers)):\n",
    "            sub_df = df[\n",
    "                (df['gt_human_depth'] >= depth_lo) & \n",
    "                (df['gt_human_depth'] < depth_hi) &         \n",
    "                (df['n_gt_human_pixels'] >= size_lo) &\n",
    "                (df['n_gt_human_pixels'] < size_hi)]\n",
    "            metrics = {**get_metrics(sub_df), \n",
    "                                'gt_human_depth': f\"{depth_ind}_{int(100*depth_lo)}-{int(100*depth_hi)}\",\n",
    "                                'n_gt_human_pixels': f\"{size_ind}_{size_lo}-{size_hi}\"\n",
    "                               }\n",
    "            print(metrics)\n",
    "            all_metrics.append(metrics)\n",
    "    all_metrics = pd.DataFrame(all_metrics)\n",
    "    return all_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = out_csvs['25079_alleyson']['halo_humans_on_path_test_v6_2_8_mainline_alleysson']\n",
    "df_2 = out_csvs['25080_alleyson']['halo_humans_on_path_test_v6_2_8_mainline']\n",
    "df_1 = df_1[df_1['unique_id'].isin(df_2['unique_id'])].copy()\n",
    "df_2 = df_2[df_2['unique_id'].isin(df_1['unique_id'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap_ax(df):\n",
    "    metrics = get_metrics_plot(df)\n",
    "    metrics = metrics.pivot(index='gt_human_depth', columns='n_gt_human_pixels', values='recall')\n",
    "    return seaborn.heatmap(metrics, annot=True, fmt=\".3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLEYSON RECALL METRICS\n",
      "{'recall': nan, 'recall_thresh': nan, 'n': 8, 'productivity': nan, 'gt_human_depth': '0_0-20', 'n_gt_human_pixels': '0_72-200'}\n",
      "{'recall': 0.8, 'recall_thresh': 0.8, 'n': 40, 'productivity': nan, 'gt_human_depth': '0_0-20', 'n_gt_human_pixels': '1_200-400'}\n",
      "{'recall': 0.9823051171688187, 'recall_thresh': 0.9824645305276583, 'n': 6273, 'productivity': nan, 'gt_human_depth': '0_0-20', 'n_gt_human_pixels': '2_400-99999'}\n",
      "{'recall': 0.6264367816091954, 'recall_thresh': nan, 'n': 174, 'productivity': 0.9806451612903225, 'gt_human_depth': '1_20-40', 'n_gt_human_pixels': '0_72-200'}\n",
      "{'recall': 0.7547408343868521, 'recall_thresh': 0.8152173913043478, 'n': 791, 'productivity': 0.9752883031301482, 'gt_human_depth': '1_20-40', 'n_gt_human_pixels': '1_200-400'}\n",
      "{'recall': 0.8284222305110034, 'recall_thresh': 0.9299820466786356, 'n': 2681, 'productivity': 0.98468410976388, 'gt_human_depth': '1_20-40', 'n_gt_human_pixels': '2_400-99999'}\n",
      "{'recall': 0.45454545454545453, 'recall_thresh': nan, 'n': 385, 'productivity': 0.9948051948051948, 'gt_human_depth': '2_40-101', 'n_gt_human_pixels': '0_72-200'}\n",
      "{'recall': 0.41350210970464135, 'recall_thresh': nan, 'n': 237, 'productivity': 1.0, 'gt_human_depth': '2_40-101', 'n_gt_human_pixels': '1_200-400'}\n",
      "{'recall': 0.49122807017543857, 'recall_thresh': nan, 'n': 570, 'productivity': 1.0, 'gt_human_depth': '2_40-101', 'n_gt_human_pixels': '2_400-99999'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall': 0.8669235594587329,\n",
       " 'recall_thresh': 0.9671379942393297,\n",
       " 'n': 11334,\n",
       " 'productivity': 0.9862012987012987}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ALLEYSON RECALL METRICS\")\n",
    "get_heatmap_ax(df_1)\n",
    "get_metrics(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO ALLEYSON RECALL METRICS\n",
      "{'recall': nan, 'recall_thresh': nan, 'n': 7, 'productivity': nan, 'gt_human_depth': '0_0-20', 'n_gt_human_pixels': '0_72-200'}\n",
      "{'recall': 0.6842105263157895, 'recall_thresh': 0.6842105263157895, 'n': 38, 'productivity': nan, 'gt_human_depth': '0_0-20', 'n_gt_human_pixels': '1_200-400'}\n",
      "{'recall': 0.9802138184139142, 'recall_thresh': 0.9813307802776448, 'n': 6267, 'productivity': nan, 'gt_human_depth': '0_0-20', 'n_gt_human_pixels': '2_400-99999'}\n",
      "{'recall': 0.603448275862069, 'recall_thresh': nan, 'n': 174, 'productivity': 0.9743589743589743, 'gt_human_depth': '1_20-40', 'n_gt_human_pixels': '0_72-200'}\n",
      "{'recall': 0.772554002541296, 'recall_thresh': 0.8430232558139535, 'n': 787, 'productivity': 0.975609756097561, 'gt_human_depth': '1_20-40', 'n_gt_human_pixels': '1_200-400'}\n",
      "{'recall': 0.8323721645520954, 'recall_thresh': 0.9343525179856115, 'n': 2601, 'productivity': 0.9838817998656817, 'gt_human_depth': '1_20-40', 'n_gt_human_pixels': '2_400-99999'}\n",
      "{'recall': 0.4536082474226804, 'recall_thresh': nan, 'n': 388, 'productivity': 0.9974226804123711, 'gt_human_depth': '2_40-101', 'n_gt_human_pixels': '0_72-200'}\n",
      "{'recall': 0.3991769547325103, 'recall_thresh': nan, 'n': 243, 'productivity': 1.0, 'gt_human_depth': '2_40-101', 'n_gt_human_pixels': '1_200-400'}\n",
      "{'recall': 0.5030581039755352, 'recall_thresh': nan, 'n': 654, 'productivity': 1.0, 'gt_human_depth': '2_40-101', 'n_gt_human_pixels': '2_400-99999'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall': 0.8646832153418765,\n",
       " 'recall_thresh': 0.9672970843183609,\n",
       " 'n': 11334,\n",
       " 'productivity': 0.9865591397849462}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"NO ALLEYSON RECALL METRICS\")\n",
    "get_heatmap_ax(df_2)\n",
    "get_metrics(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = out_csvs['25079_alleyson']['halo_rgb_stereo_test_v6_2_alleysson']\n",
    "df_2 = out_csvs['25080_alleyson']['halo_rgb_stereo_test_v6_2']\n",
    "df_1 = df_1[df_1['unique_id'].isin(df_2['unique_id'])].copy()\n",
    "df_2 = df_2[df_2['unique_id'].isin(df_1['unique_id'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.8662271373883453,\n",
       " 'recall_thresh': 0.9406270847231488,\n",
       " 'n': 59170,\n",
       " 'productivity': 0.9773404277174025}"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.8622474299893654,\n",
       " 'recall_thresh': 0.9351109453663994,\n",
       " 'n': 59170,\n",
       " 'productivity': 0.9750433490215507}"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = out_csvs['25079_alleyson']['halo_productivity_combined_no_mislocalization_alleyson']\n",
    "df_2 = out_csvs['25080_alleyson']['halo_productivity_combined']\n",
    "df_1 = df_1[df_1['unique_id'].isin(df_2['unique_id'])].copy()\n",
    "df_2 = df_2[df_2['unique_id'].isin(df_1['unique_id'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': nan,\n",
       " 'recall_thresh': nan,\n",
       " 'n': 182352,\n",
       " 'productivity': 0.9854512152320786}"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': nan,\n",
       " 'recall_thresh': nan,\n",
       " 'n': 182352,\n",
       " 'productivity': 0.9896189786785996}"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAINLINE RECALL 0.9889234598630989\n",
    "# MAINLINE ALLEYSON RECALL 0.9888404309902514\n",
    "\n",
    "# STEREO TEST PRODUCITIVITY 0.7121072372870934\n",
    "# STEREO TEST ALLEYSON PRODUCTIVITY 0.7014358038011453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.read_csv(output_dir_prod + \"/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_dset = '/data2/jupiter/datasets/halo_rgb_stereo_test_v6_0/'\n",
    "master_df = pd.read_csv(prod_dset + \"master_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df = out_df[out_df['state'] == 'false_positive']\n",
    "row = master_df[master_df['id'] == '64dea8faae8b0f37b46e05f7'].iloc[0]\n",
    "# /mnt/sandbox1/alex.li/results/pmehta_2023_val_bestmodel/halo_rgb_stereo_test_v6_0/human_false_positive/64de93970bf522829d4cd6d8_T13_T15.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_artifacts = rec.get_artifacts(row)\n",
    "label_converter = LabelConversion(label_map_helper)\n",
    "rec_label = label_converter.convert_label_for_driveable_terrain(rec_artifacts['label'], json.loads(row['label_map']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "dataset_path = '/mnt/sandbox1/alex.li/introspection/pmehta_2023_val_bestmodel/halo_rgb_stereo_test_v6_0/'\n",
    "files = os.listdir(dataset_path + 'false_positive/')\n",
    "os.mkdir(dataset_path + 'fp_subset_2/')\n",
    "random.shuffle(files)\n",
    "for f in files[:50]:\n",
    "    os.symlink(dataset_path + 'false_positive/' + f, dataset_path + 'fp_subset_2/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "dataset_path = '/mnt/sandbox1/alex.li/introspection/pmehta_2023_val_bestmodel/halo_humans_on_path_v3/'\n",
    "files = os.listdir(dataset_path + 'human_false_negative/')\n",
    "os.mkdir(dataset_path + 'fn_subset/')\n",
    "random.shuffle(files)\n",
    "for f in files[:50]:\n",
    "    os.symlink(dataset_path + 'human_false_negative/' + f, dataset_path + 'fn_subset/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_is_cutoff = []\n",
    "label_is_humanonly = []\n",
    "label_file = \"/home/alex.li/git/JupiterCVML/europa/base/src/europa/dl/config/label_maps/eight_class_train_dust_light_as_sky_birds_as_driveable.csv\"\n",
    "label_map_helper = LabelMapHelper(label_file)\n",
    "rec = rectifiedrgb.RectifiedRGBNPZ(prod_dset)\n",
    "deb = debayeredrgb.DebayeredRGBNPZ(prod_dset)\n",
    "label_converter = LabelConversion(label_map_helper)\n",
    "\n",
    "for _, row in tqdm(master_df.iterrows(), total=len(master_df)):\n",
    "    rec_artifacts = rec.get_artifacts(row)\n",
    "    rec_label = label_converter.convert_label_for_driveable_terrain(rec_artifacts['label'], json.loads(row['label_map']))\n",
    "\n",
    "    # for id in tqdm(master_df['id']):\n",
    "    #     row = master_df[master_df['id'] == id].iloc[0]\n",
    "    # deb_artifacts = deb.get_artifacts(row)\n",
    "    # deb_label = label_converter.convert_label_for_driveable_terrain(deb_artifacts['label'], json.loads(row['label_map']))\n",
    "    # rec_human = np.sum(rec_label == 5)\n",
    "    # center_human = np.sum(rec_label[15:-15,15:-15] == 5)\n",
    "    # edge_human = rec_human - center_human\n",
    "    # deb_human = np.sum(deb_label == 5)\n",
    "    # # Human is on edge only and more present in the debayered image\n",
    "    # if edge_human > center_human and deb_human > rec_human * 8:\n",
    "    #     #occluded human\n",
    "    #     label_is_cutoff.append(True)\n",
    "    # else:\n",
    "    #     label_is_cutoff.append(False)\n",
    "    label_is_humanonly.append(set(np.unique(rec_label)) <= set({5, 255}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(label_is_humanonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_full_label = master_df[~np.array(label_is_humanonly)]\n",
    "master_df_full_label.to_csv(prod_dset + \"master_annotations_full_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_full_label = pd.read_csv(prod_dset + \"master_annotations_full_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uid = master_df['unique_id']\n",
    "other_uid = master_df_full_label['unique_id']\n",
    "diff_id = set(all_uid) - set(other_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humanonly_df = master_df[master_df['unique_id'].isin(diff_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(humanonly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = pd.read_csv(prod_dset + \"master_annotations_human_label.csv\")\n",
    "pawan = pd.read_csv(\"/home/alex.li/logs/only_humans_labeled_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me['annotation_pixelwise_0_labeled_objects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pawan['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pawan_uid = pawan['id']\n",
    "me_uid = me['id']\n",
    "in_pawan_only = list(set(pawan_uid) - set(me_uid))\n",
    "in_me_only = list(set(me_uid) - set(pawan_uid))\n",
    "\n",
    "print(in_pawan_only[:4])\n",
    "print(in_me_only[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(in_me_only))\n",
    "print(len(in_pawan_only))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
