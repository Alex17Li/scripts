{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dl.dataset.datamodes.npz import rectifiedrgb, debayeredrgb\n",
    "from dl.config.label_map_helper import LabelMapHelper, LabelConversion\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_prod = '/mnt/sandbox1/alex.li/introspection/pmehta_2023_val_bestmodel/halo_rgb_stereo_test_v6_0'\n",
    "output_dir_safety = '/mnt/sandbox1/alex.li/introspection/pmehta_2023_val_bestmodel/halo_humans_on_path_v3'\n",
    "# output_dir_prod = '/mnt/sandbox1/alex.li/results/17902/halo_rgb_stereo_test_v6_0'\n",
    "# output_dir_safety = '/mnt/sandbox1/alex.li/results/17902/halo_humans_on_path_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General metrics. Note TPs and FNs are based on ['Non-driveable', 'Trees_Weeds', 'Humans', 'Vehicles']:\n",
      "true_positive: 10881\n",
      "true_negative: 31499\n",
      "false_positive: 855\n",
      "false_negative: 961\n",
      "precision_image: 0.9271472392638037\n",
      "recall_image: 0.918848167539267\n",
      "f1_image: 0.9229790482653321\n",
      "productivity_image: 0.9735735921369846\n",
      "\n",
      "General metrics on large objects:\n",
      "large_object_true_positive: 0\n",
      "large_object_false_negative: 0\n",
      "\n",
      "Strict metrics on humans:\n",
      "human_true_positive: 5454\n",
      "human_true_negative: 37694\n",
      "human_false_positive: 523\n",
      "human_false_negative: 525\n",
      "human_precision_image: 0.9124979086498243\n",
      "human_recall_image: 0.9121926743602609\n",
      "human_f1_image: 0.9123452659752426\n",
      "human_productivity_image: 0.9863149907109402\n",
      "\n",
      "Strict metrics on vehicles:\n",
      "vehicle_true_positive: 1612\n",
      "vehicle_true_negative: 41442\n",
      "vehicle_false_positive: 1033\n",
      "vehicle_false_negative: 109\n",
      "vehicle_precision_image: 0.6094517958412098\n",
      "vehicle_recall_image: 0.936664729808251\n",
      "vehicle_f1_image: 0.7384333486028402\n",
      "vehicle_productivity_image: 0.975679811653914\n",
      "\n",
      "General metrics per operation time and camera pod:\n",
      "day_safety: 0.9290527531767424\n",
      "night_safety: 0.8459422283356258\n",
      "front_safety: nan\n",
      "rear_safety: 0.918848167539267\n",
      "day_front_safety: nan\n",
      "day_rear_safety: 0.9290527531767424\n",
      "night_front_safety: nan\n",
      "night_rear_safety: 0.8459422283356258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(output_dir_prod + \"/results.txt\", 'r') as f:\n",
    "    print(''.join(f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General metrics. Note TPs and FNs are based on ['Humans']:\n",
      "true_positive: 5685\n",
      "true_negative: 4799\n",
      "false_positive: 555\n",
      "false_negative: 290\n",
      "precision_image: 0.9110576923076923\n",
      "recall_image: 0.9514644351464435\n",
      "f1_image: 0.9308227589029882\n",
      "productivity_image: 0.8963391856555846\n",
      "\n",
      "General metrics on large objects:\n",
      "large_object_true_positive: 166\n",
      "large_object_false_negative: 30\n",
      "\n",
      "Strict metrics on humans:\n",
      "human_true_positive: 5459\n",
      "human_true_negative: 5413\n",
      "human_false_positive: 137\n",
      "human_false_negative: 516\n",
      "human_precision_image: 0.975518227305218\n",
      "human_recall_image: 0.9136401673640168\n",
      "human_f1_image: 0.9435658110794227\n",
      "human_productivity_image: 0.9753153153153153\n",
      "\n",
      "General metrics per operation time and camera pod:\n",
      "day_safety: 0.9523724580806279\n",
      "night_safety: 0.9376693766937669\n",
      "front_safety: nan\n",
      "rear_safety: 0.9514644351464435\n",
      "day_front_safety: nan\n",
      "day_rear_safety: 0.9523724580806279\n",
      "night_front_safety: nan\n",
      "night_rear_safety: 0.9376693766937669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(output_dir_safety + \"/results.txt\", 'r') as f:\n",
    "    print(''.join(f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.read_csv(output_dir_prod + \"/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex.li/miniconda3/envs/cvml/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3508: DtypeWarning: Columns (0,1,22,79,90,91,92,93,94,96,97,99,100,101,102,103,104,105,106,107,117,150,154,155,160,171,174,196,197,199,200,201,202,227,228,235,236,250,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,271,275,276,277,280,284) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "prod_dset = '/data2/jupiter/datasets/halo_rgb_stereo_test_v6_0/'\n",
    "master_df = pd.read_csv(prod_dset + \"master_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df = out_df[out_df['state'] == 'false_positive']\n",
    "row = master_df[master_df['id'] == '64dea8faae8b0f37b46e05f7'].iloc[0]\n",
    "# /mnt/sandbox1/alex.li/results/pmehta_2023_val_bestmodel/halo_rgb_stereo_test_v6_0/human_false_positive/64de93970bf522829d4cd6d8_T13_T15.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_artifacts = rec.get_artifacts(row)\n",
    "label_converter = LabelConversion(label_map_helper)\n",
    "rec_label = label_converter.convert_label_for_driveable_terrain(rec_artifacts['label'], json.loads(row['label_map']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "dataset_path = '/mnt/sandbox1/alex.li/introspection/pmehta_2023_val_bestmodel/halo_rgb_stereo_test_v6_0/'\n",
    "files = os.listdir(dataset_path + 'false_positive/')\n",
    "os.mkdir(dataset_path + 'fp_subset_2/')\n",
    "random.shuffle(files)\n",
    "for f in files[:50]:\n",
    "    os.symlink(dataset_path + 'false_positive/' + f, dataset_path + 'fp_subset_2/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "dataset_path = '/mnt/sandbox1/alex.li/introspection/pmehta_2023_val_bestmodel/halo_humans_on_path_v3/'\n",
    "files = os.listdir(dataset_path + 'human_false_negative/')\n",
    "os.mkdir(dataset_path + 'fn_subset/')\n",
    "random.shuffle(files)\n",
    "for f in files[:50]:\n",
    "    os.symlink(dataset_path + 'human_false_negative/' + f, dataset_path + 'fn_subset/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelMapHelper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m label_is_humanonly \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m label_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/alex.li/git/JupiterCVML/europa/base/src/europa/dl/config/label_maps/eight_class_train_dust_light_as_sky_birds_as_driveable.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m label_map_helper \u001b[38;5;241m=\u001b[39m \u001b[43mLabelMapHelper\u001b[49m(label_file)\n\u001b[1;32m      5\u001b[0m rec \u001b[38;5;241m=\u001b[39m rectifiedrgb\u001b[38;5;241m.\u001b[39mRectifiedRGBNPZ(prod_dset)\n\u001b[1;32m      6\u001b[0m deb \u001b[38;5;241m=\u001b[39m debayeredrgb\u001b[38;5;241m.\u001b[39mDebayeredRGBNPZ(prod_dset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LabelMapHelper' is not defined"
     ]
    }
   ],
   "source": [
    "label_is_cutoff = []\n",
    "label_is_humanonly = []\n",
    "label_file = \"/home/alex.li/git/JupiterCVML/europa/base/src/europa/dl/config/label_maps/eight_class_train_dust_light_as_sky_birds_as_driveable.csv\"\n",
    "label_map_helper = LabelMapHelper(label_file)\n",
    "rec = rectifiedrgb.RectifiedRGBNPZ(prod_dset)\n",
    "deb = debayeredrgb.DebayeredRGBNPZ(prod_dset)\n",
    "label_converter = LabelConversion(label_map_helper)\n",
    "\n",
    "for _, row in tqdm(master_df.iterrows(), total=len(master_df)):\n",
    "    rec_artifacts = rec.get_artifacts(row)\n",
    "    rec_label = label_converter.convert_label_for_driveable_terrain(rec_artifacts['label'], json.loads(row['label_map']))\n",
    "\n",
    "    for id in tqdm(master_df['id']):\n",
    "        row = master_df[master_df['id'] == id].iloc[0]\n",
    "    deb_artifacts = deb.get_artifacts(row)\n",
    "    deb_label = label_converter.convert_label_for_driveable_terrain(deb_artifacts['label'], json.loads(row['label_map']))\n",
    "    rec_human = np.sum(rec_label == 5)\n",
    "    center_human = np.sum(rec_label[15:-15,15:-15] == 5)\n",
    "    edge_human = rec_human - center_human\n",
    "    deb_human = np.sum(deb_label == 5)\n",
    "    # Human is on edge only and more present in the debayered image\n",
    "    if edge_human > center_human and deb_human > rec_human * 8:\n",
    "        #occluded human\n",
    "        label_is_cutoff.append(True)\n",
    "    else:\n",
    "        label_is_cutoff.append(False)\n",
    "    label_is_humanonly.append(set(np.unique(rec_label)) <= set({5, 255}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3544"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(label_is_humanonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_full_label = master_df[~np.array(label_is_humanonly)]\n",
    "master_df_full_label.to_csv(prod_dset + \"master_annotations_full_label.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
