ADAPTIVE TRUE RHO GRID SEARCH
[21:10:19] INFO     Created a temporary directory at /tmp/tmp_gwc63ef                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmp_gwc63ef/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
           INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
[21:10:20] INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
           INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
           INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
           INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
[21:10:21] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.0006, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.1, adaptive=True)
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.08830467708408833 Acc 0.9660328352451324 Perturbed Loss 0.11022206045687198
[21:10:51] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.07575515072792768 Acc 0.9716252875328064 Perturbed Loss 0.08999255873262882
Loss 0.0853738123178482 Acc 0.9764247918128968 Perturbed Loss 0.09923054788261652
Loss 0.08293145016767084 Acc 0.9745581841468811 Perturbed Loss 0.0954678220115602
Loss 0.08106106460094452 Acc 0.9762786269187927 Perturbed Loss 0.09748280480504036
Loss 0.09456278558820486 Acc 0.9670095276832581 Perturbed Loss 0.11152116559445859
Loss 0.08338467199355364 Acc 0.9714029049873352 Perturbed Loss 0.09585922524333
Loss 0.08287646872922778 Acc 0.9777586853504181 Perturbed Loss 0.09984238186851144
Loss 0.08985572800040245 Acc 0.9729187309741973 Perturbed Loss 0.1009111699461937
Loss 0.08598194679245352 Acc 0.9707742798328399 Perturbed Loss 0.0996119962260127
Loss 0.07686617940664292 Acc 0.9770312213897705 Perturbed Loss 0.08963864203542471
Loss 0.08766064699739218 Acc 0.975867600440979 Perturbed Loss 0.10414986073970794
Loss 0.08283789506182075 Acc 0.9775296974182129 Perturbed Loss 0.10075518291443586
Loss 0.069904108569026 Acc 0.9826710975170135 Perturbed Loss 0.0838960487022996
Loss 0.08393358362838627 Acc 0.9751680839061737 Perturbed Loss 0.09581852862611413
Epoch 0.0 val loss 0.058471567928791046 val acc 0.9788916110992432
Loss 0.08298667553812265 Acc 0.9730797731876373 Perturbed Loss 0.09648816131055354
Loss 0.07881113726645708 Acc 0.9726876020431519 Perturbed Loss 0.09127735402435064
Loss 0.07869136992841959 Acc 0.9691168248653412 Perturbed Loss 0.09221402812749148
Loss 0.07609492000192404 Acc 0.973776683807373 Perturbed Loss 0.08593821413815021
Loss 0.07947657519951462 Acc 0.9752526092529297 Perturbed Loss 0.08973024278879166
Loss 0.07366595588624478 Acc 0.9781843817234039 Perturbed Loss 0.08541163332760333
Loss 0.0864349140971899 Acc 0.9759581017494202 Perturbed Loss 0.09684640157967805
Loss 0.07189067292958498 Acc 0.9785959100723267 Perturbed Loss 0.0783692818135023
Loss 0.07263684760779142 Acc 0.9785834777355195 Perturbed Loss 0.08322880234569312
Loss 0.07561608832329511 Acc 0.9767377364635468 Perturbed Loss 0.09138641519472003
Loss 0.07668629320338369 Acc 0.9705207848548889 Perturbed Loss 0.08896584752947093
Loss 0.09544731318950653 Acc 0.9704244017601014 Perturbed Loss 0.11008617874234915
Loss 0.08068182788789273 Acc 0.9786971497535706 Perturbed Loss 0.09414081908762455
Loss 0.09704174939543009 Acc 0.9720639550685882 Perturbed Loss 0.10820070050656795
Loss 0.08214552514255047 Acc 0.976918889284134 Perturbed Loss 0.09506443198770284
Epoch 1.0 val loss 0.0569862462580204 val acc 0.9791980385780334
Loss 0.0741568580083549 Acc 0.9750589442253113 Perturbed Loss 0.08253078665584326
Loss 0.08610911000519991 Acc 0.9786143207550049 Perturbed Loss 0.09456099461764098
Loss 0.07572654038667678 Acc 0.9793140077590943 Perturbed Loss 0.08779853232204914
Loss 0.07117844037711621 Acc 0.9817676234245301 Perturbed Loss 0.08171910267323255
Loss 0.0736136933043599 Acc 0.9807348942756653 Perturbed Loss 0.08416913002729416
Loss 0.0705724485963583 Acc 0.977609531879425 Perturbed Loss 0.08060936532914638
Loss 0.07788053046911955 Acc 0.9794697654247284 Perturbed Loss 0.08792241737246513
Loss 0.0728945992514491 Acc 0.982247005701065 Perturbed Loss 0.08483980685472488
Loss 0.08495603591203689 Acc 0.9748220932483673 Perturbed Loss 0.09803729131817818
Loss 0.07582334045320749 Acc 0.9800695586204529 Perturbed Loss 0.0859033290669322
Loss 0.0770236400142312 Acc 0.9788911271095276 Perturbed Loss 0.08968998774886132
Loss 0.08019296173006296 Acc 0.975686126947403 Perturbed Loss 0.09027918044477701
Loss 0.07750750795006751 Acc 0.9724168407917023 Perturbed Loss 0.09074431162327529
Loss 0.09963828667998315 Acc 0.9675977575778961 Perturbed Loss 0.10993447590619326
Loss 0.07853072118014097 Acc 0.9776410007476807 Perturbed Loss 0.08867444179952144
Epoch 2.0 val loss 0.05728607624769211 val acc 0.9797121286392212
Loss 0.07294812448322772 Acc 0.9766247081756592 Perturbed Loss 0.0826505183801055
Loss 0.06472393359988927 Acc 0.9797817397117615 Perturbed Loss 0.07510333355516195
Loss 0.07105410996824503 Acc 0.9800910592079163 Perturbed Loss 0.08280951350927353
Loss 0.0772049256041646 Acc 0.9805763781070709 Perturbed Loss 0.08875540498644113
Loss 0.08724285591393709 Acc 0.9773733985424041 Perturbed Loss 0.10152291655540466
Loss 0.08321884978562594 Acc 0.9752099096775055 Perturbed Loss 0.09509169328957796
Loss 0.07019304357469082 Acc 0.9827225077152252 Perturbed Loss 0.08110019486397504
Loss 0.07897856917232275 Acc 0.9767825746536255 Perturbed Loss 0.08816206600517035
Loss 0.08840762883424759 Acc 0.9775730168819428 Perturbed Loss 0.10016190163791179
Loss 0.07453113771975041 Acc 0.9769581353664398 Perturbed Loss 0.08313527081161737
Loss 0.06707289343699813 Acc 0.9780593001842499 Perturbed Loss 0.07697286188602448
Loss 0.08469835750758647 Acc 0.9752417802810669 Perturbed Loss 0.0947387145087123
Loss 0.09061724416911603 Acc 0.9753448987007141 Perturbed Loss 0.10379919491708278
Loss 0.07630120215937496 Acc 0.9719437801837921 Perturbed Loss 0.08626190505921841
Loss 0.08157692145556211 Acc 0.9762464785575866 Perturbed Loss 0.0889629215747118
Epoch 3.0 val loss 0.05931330472230911 val acc 0.9788283705711365
Loss 0.06780442859977484 Acc 0.9808072197437286 Perturbed Loss 0.07699499879032373
Loss 0.07562324479222297 Acc 0.9820720148086548 Perturbed Loss 0.08498009279370308
Loss 0.06575710289180278 Acc 0.974641979932785 Perturbed Loss 0.07586646590381861
Loss 0.08782530665397643 Acc 0.9793437159061432 Perturbed Loss 0.09919027989730239
Loss 0.0754130301438272 Acc 0.9755445230007171 Perturbed Loss 0.08506486181169748
Loss 0.07506329456344246 Acc 0.9781847989559174 Perturbed Loss 0.08602172518149018
Loss 0.07203784231096506 Acc 0.9785358607769012 Perturbed Loss 0.08402122285217047
Loss 0.07643310178071261 Acc 0.9782315015792846 Perturbed Loss 0.08541004460304975
Loss 0.07500990439206362 Acc 0.975520281791687 Perturbed Loss 0.08331684030592441
Loss 0.06669964242726564 Acc 0.9776396465301513 Perturbed Loss 0.07710487347096205
Loss 0.079573241956532 Acc 0.9793678951263428 Perturbed Loss 0.0941820115596056
Loss 0.0799729111790657 Acc 0.9754379510879516 Perturbed Loss 0.08956831376999616
Loss 0.08033160980790853 Acc 0.975893622636795 Perturbed Loss 0.09089536901563405
Loss 0.07577240750193596 Acc 0.9797966980934143 Perturbed Loss 0.08398917194455863
Loss 0.07420072820037603 Acc 0.9791773140430451 Perturbed Loss 0.08484664332121611
Epoch 4.0 val loss 0.057499393820762634 val acc 0.9794626832008362
Loss 0.06998014207929373 Acc 0.9788228237628936 Perturbed Loss 0.07844026450067759
Loss 0.08128760289400816 Acc 0.9796055352687836 Perturbed Loss 0.09037654180079699
Loss 0.08320713851600886 Acc 0.9772560513019561 Perturbed Loss 0.0915121241286397
Loss 0.08260852677747607 Acc 0.9739594793319702 Perturbed Loss 0.09097927886992693
Loss 0.07128820922225713 Acc 0.9787804186344147 Perturbed Loss 0.08043534986674786
Loss 0.08456164261326193 Acc 0.9748234617710113 Perturbed Loss 0.09664751522243023
Loss 0.06844265941530465 Acc 0.9802555620670319 Perturbed Loss 0.0754957165941596
Loss 0.06656408432871103 Acc 0.9778083026409149 Perturbed Loss 0.07630630731582641
Loss 0.07458039037883282 Acc 0.9795770728588105 Perturbed Loss 0.08422443754971028
Loss 0.0741365860030055 Acc 0.9773378312587738 Perturbed Loss 0.08499152399599552
Loss 0.07730133030563593 Acc 0.9775875639915467 Perturbed Loss 0.08466435786336661
Loss 0.08064605452120305 Acc 0.9750464594364167 Perturbed Loss 0.08901603352278471
Loss 0.0805725272372365 Acc 0.9795128345489502 Perturbed Loss 0.09095423083752394
Loss 0.08006698712706566 Acc 0.9780880796909333 Perturbed Loss 0.09175837207585573
Loss 0.07345893908292055 Acc 0.9773538625240326 Perturbed Loss 0.08384879313409328
Epoch 5.0 val loss 0.06080252677202225 val acc 0.9784984588623047
Loss 0.07652682404965162 Acc 0.9770800077915192 Perturbed Loss 0.08489688660949468
Loss 0.07575877202674747 Acc 0.9780321085453033 Perturbed Loss 0.08454536637291313
Loss 0.0686370150372386 Acc 0.9796568095684052 Perturbed Loss 0.0768729280680418
Loss 0.08327554672956466 Acc 0.9764424252510071 Perturbed Loss 0.09098307840526104
Loss 0.07465455338358878 Acc 0.9819161164760589 Perturbed Loss 0.08181788178160787
Loss 0.07621171291917563 Acc 0.9759476613998413 Perturbed Loss 0.08499169658869504
Loss 0.07245933249592781 Acc 0.976832834482193 Perturbed Loss 0.08090801060199737
Loss 0.07399602655321359 Acc 0.9815274059772492 Perturbed Loss 0.08092488899827004
Loss 0.0695839238539338 Acc 0.9801173615455627 Perturbed Loss 0.07719865098595619
Loss 0.08033784467726945 Acc 0.9769164574146271 Perturbed Loss 0.08995129603892565
Loss 0.07450920714065433 Acc 0.9776217854022979 Perturbed Loss 0.0819510855525732
Loss 0.072817264162004 Acc 0.9787617254257203 Perturbed Loss 0.0816242522187531
Loss 0.0737021315190941 Acc 0.9761497986316681 Perturbed Loss 0.08228625595569611
Loss 0.07502201054245233 Acc 0.9810731220245361 Perturbed Loss 0.08414275981485844
Loss 0.07670743849128485 Acc 0.973948894739151 Perturbed Loss 0.08520932916551828
Epoch 6.0 val loss 0.05799157917499542 val acc 0.9791624546051025
Loss 0.08271664559841156 Acc 0.9761262822151184 Perturbed Loss 0.09288065826520324
Loss 0.08544597251340746 Acc 0.9775481486320495 Perturbed Loss 0.09581114247441291
Loss 0.0727222852781415 Acc 0.9776480543613434 Perturbed Loss 0.08062619984149932
Loss 0.06619192508980631 Acc 0.9825816178321838 Perturbed Loss 0.07547353206202388
Loss 0.06865911558270454 Acc 0.9773338937759399 Perturbed Loss 0.07632066069170833
Loss 0.07659856799989939 Acc 0.9779300737380981 Perturbed Loss 0.0834462796524167
Loss 0.07741872791200877 Acc 0.9756269264221191 Perturbed Loss 0.08525303035974502
Loss 0.06514716923236846 Acc 0.9807868480682373 Perturbed Loss 0.07209877006709575
Loss 0.07273882303386926 Acc 0.9786023592948914 Perturbed Loss 0.08301750686019659
Loss 0.0788643928989768 Acc 0.977923219203949 Perturbed Loss 0.08848798453807831
Loss 0.07518540676683187 Acc 0.9815658032894135 Perturbed Loss 0.08909387864172459
Loss 0.07212250716984273 Acc 0.9793287944793702 Perturbed Loss 0.07926120970398187
Loss 0.06764470301568508 Acc 0.97816188454628 Perturbed Loss 0.07502479150891304
Loss 0.06935186091810465 Acc 0.9815474700927734 Perturbed Loss 0.07684337235987186
Loss 0.07622335217893124 Acc 0.9779146766662598 Perturbed Loss 0.08369518466293811
Epoch 7.0 val loss 0.056547634303569794 val acc 0.9789987206459045
Loss 0.06912086430937052 Acc 0.977159411907196 Perturbed Loss 0.08117906462401152
Loss 0.0705955379921943 Acc 0.9734677529335022 Perturbed Loss 0.07935128526762128
Loss 0.06583143893629312 Acc 0.9784739243984223 Perturbed Loss 0.07434777395799756
Loss 0.07538865022361278 Acc 0.976903246641159 Perturbed Loss 0.0828390346467495
Loss 0.06720010321587325 Acc 0.9796125090122223 Perturbed Loss 0.07558636052533985
Loss 0.07299001394771039 Acc 0.9781351745128631 Perturbed Loss 0.07999990053474904
Loss 0.06412539090961218 Acc 0.9779982936382293 Perturbed Loss 0.07260537609457969
Loss 0.06948989737778902 Acc 0.9780293238162995 Perturbed Loss 0.07594011835753918
Loss 0.07057495076209307 Acc 0.9766488134860992 Perturbed Loss 0.08197983652353287
Loss 0.0671542322449386 Acc 0.9765027737617493 Perturbed Loss 0.07647152327001094
Loss 0.07421874430030584 Acc 0.9792078018188477 Perturbed Loss 0.08455363608896732
Loss 0.07043765431270003 Acc 0.9801145339012146 Perturbed Loss 0.07862699525430798
Loss 0.06911502726376056 Acc 0.9789432382583618 Perturbed Loss 0.07772775985300541
Loss 0.07664824465289712 Acc 0.9782163226604461 Perturbed Loss 0.08573231061920523
Loss 0.07448191002011299 Acc 0.9810336124897003 Perturbed Loss 0.082427728921175
Epoch 8.0 val loss 0.05811268091201782 val acc 0.9794604778289795
Loss 0.07423976533114911 Acc 0.9751741242408752 Perturbed Loss 0.0840112728625536
Loss 0.06969344720244408 Acc 0.9787336266040803 Perturbed Loss 0.07794244125485421
Loss 0.07139449663460255 Acc 0.978187735080719 Perturbed Loss 0.07805106192827224
Loss 0.06106591437011957 Acc 0.9800312650203705 Perturbed Loss 0.06687588103115559
Loss 0.06953804202377796 Acc 0.9779843378067017 Perturbed Loss 0.08012476928532124
Loss 0.06918740212917328 Acc 0.9778048467636108 Perturbed Loss 0.07961115151643754
Loss 0.06314401248469949 Acc 0.9806785011291503 Perturbed Loss 0.06997200900688767
Loss 0.07821458950638771 Acc 0.9786326253414154 Perturbed Loss 0.08610149011015893
Loss 0.0681107460707426 Acc 0.9796957397460937 Perturbed Loss 0.07515328321605921
Loss 0.06692650984972716 Acc 0.9823634493350982 Perturbed Loss 0.07361140452325345
Loss 0.06640440199524164 Acc 0.9806148564815521 Perturbed Loss 0.07442948084324598
Loss 0.07081101236864924 Acc 0.9785687792301178 Perturbed Loss 0.07703570645302533
Loss 0.07272358503192664 Acc 0.9778778719902038 Perturbed Loss 0.08049079447984696
Loss 0.07940910063683987 Acc 0.9768150949478149 Perturbed Loss 0.08812948606908322
Loss 0.0747657860815525 Acc 0.977824239730835 Perturbed Loss 0.08247056253254413
Epoch 9.0 val loss 0.055320657789707184 val acc 0.9797329306602478
Loss 0.07115506302565336 Acc 0.9825234854221344 Perturbed Loss 0.07730354111641645
Loss 0.0725779626891017 Acc 0.9768938148021697 Perturbed Loss 0.07918389208614826
Loss 0.06532627778127789 Acc 0.9812307298183441 Perturbed Loss 0.07218397535383701
Loss 0.08151333875954152 Acc 0.9748017585277557 Perturbed Loss 0.09135072296485305
Loss 0.06352989748120308 Acc 0.9823073506355285 Perturbed Loss 0.06947894729673862
Loss 0.06835930086672307 Acc 0.9790796852111816 Perturbed Loss 0.07923827514052391
Loss 0.06970282230526209 Acc 0.978559353351593 Perturbed Loss 0.08057720821350813
Loss 0.06310826688073576 Acc 0.983144098520279 Perturbed Loss 0.06942390656098724
Loss 0.06363282728940249 Acc 0.9788525319099426 Perturbed Loss 0.06934872932732106
Loss 0.06562228396534919 Acc 0.9780125713348389 Perturbed Loss 0.07485050255432725
Loss 0.06638472147285938 Acc 0.9784951424598693 Perturbed Loss 0.0751730740070343
Loss 0.07622650031000376 Acc 0.9776382458209991 Perturbed Loss 0.08395151656121015
Loss 0.06762705703265964 Acc 0.979905617237091 Perturbed Loss 0.07513428684324026
Loss 0.06658059868961573 Acc 0.9769915854930877 Perturbed Loss 0.0768637889996171
Loss 0.06718479011207819 Acc 0.9784533715248108 Perturbed Loss 0.07614424269646407
Epoch 10.0 val loss 0.056808602064847946 val acc 0.9796569347381592
Loss 0.0690200209710747 Acc 0.9797746610641479 Perturbed Loss 0.07708453498780728
Loss 0.07102872070856392 Acc 0.9812139511108399 Perturbed Loss 0.07748063595965504
Loss 0.06530576448887587 Acc 0.9801472556591034 Perturbed Loss 0.07184856818988919
Loss 0.06157284121960402 Acc 0.9794364631175995 Perturbed Loss 0.06875665441155433
Loss 0.0689981302805245 Acc 0.9778690016269684 Perturbed Loss 0.07642330784350633
Loss 0.06349537942558527 Acc 0.9781920337677001 Perturbed Loss 0.0713568078354001
Loss 0.07150362862274051 Acc 0.9793838715553284 Perturbed Loss 0.08008112378418446
Loss 0.07683845836669206 Acc 0.9782499563694 Perturbed Loss 0.08597830530256033
Loss 0.0619747387804091 Acc 0.9799225640296936 Perturbed Loss 0.06960013248026371
Loss 0.06535386510193347 Acc 0.9817632102966308 Perturbed Loss 0.07341578152030706
Loss 0.07558113053441047 Acc 0.9777389323711395 Perturbed Loss 0.0860779995471239
Loss 0.07067779403179884 Acc 0.9800929880142212 Perturbed Loss 0.07781997215002776
Loss 0.07841278966516256 Acc 0.9762671232223511 Perturbed Loss 0.086405793055892
Loss 0.06389421530067921 Acc 0.981028436422348 Perturbed Loss 0.0721643739938736
Loss 0.06294133512303234 Acc 0.98076007604599 Perturbed Loss 0.07053313631564379
Epoch 11.0 val loss 0.05649663135409355 val acc 0.9792025685310364
Loss 0.07860356908291578 Acc 0.9787663006782532 Perturbed Loss 0.08584795091301203
Loss 0.07265502613037825 Acc 0.9771279513835907 Perturbed Loss 0.08172500353306532
Loss 0.06958580575883389 Acc 0.9821190083026886 Perturbed Loss 0.07772209990769624
Loss 0.06171941483393312 Acc 0.9800010883808136 Perturbed Loss 0.07031919464468955
Loss 0.06317612960934639 Acc 0.9844251728057861 Perturbed Loss 0.06932989999651909
Loss 0.06230838365852833 Acc 0.9799604678153991 Perturbed Loss 0.07116290049627423
Loss 0.06802707582712174 Acc 0.9797089982032776 Perturbed Loss 0.07270938677713275
Loss 0.06316612467169762 Acc 0.9803184342384338 Perturbed Loss 0.07055765260010957
Loss 0.06281820237636566 Acc 0.978331310749054 Perturbed Loss 0.0705591619759798
Loss 0.06417614864185453 Acc 0.9814262676239014 Perturbed Loss 0.07160777965560555
Loss 0.07119258978404104 Acc 0.979347540140152 Perturbed Loss 0.08041203157976269
Loss 0.061818833313882354 Acc 0.9768448376655579 Perturbed Loss 0.06748164489865303
Loss 0.07899633915163577 Acc 0.9816540598869323 Perturbed Loss 0.08867355335503817
Loss 0.06453436274081469 Acc 0.9807102513313294 Perturbed Loss 0.07244283396750689
Loss 0.0691945862956345 Acc 0.9749111545085907 Perturbed Loss 0.07641877185553313
Epoch 12.0 val loss 0.05611294507980347 val acc 0.97967129945755
Loss 0.07220953652635216 Acc 0.9781260645389557 Perturbed Loss 0.08150432309135795
Loss 0.07618055146187544 Acc 0.9775898838043213 Perturbed Loss 0.08501122150570155
Loss 0.07460338328033686 Acc 0.9779490494728088 Perturbed Loss 0.08280056565999985
Loss 0.06421752218157054 Acc 0.9824040925502777 Perturbed Loss 0.0717431053891778
Loss 0.06466141629964113 Acc 0.9800184416770935 Perturbed Loss 0.07340687930583954
Loss 0.07070185575634241 Acc 0.9809593391418457 Perturbed Loss 0.0774605355411768
Loss 0.07276077516376972 Acc 0.976034814119339 Perturbed Loss 0.07905414011329412
Loss 0.06921865448355674 Acc 0.9786138415336609 Perturbed Loss 0.07734744776040316
Loss 0.06886612731963396 Acc 0.9791330564022064 Perturbed Loss 0.07649109425023198
Loss 0.06743082476779819 Acc 0.9804543375968933 Perturbed Loss 0.0747297284565866
Loss 0.07439217142760754 Acc 0.9787887167930603 Perturbed Loss 0.08071727450937033
Loss 0.0708160499483347 Acc 0.9814314591884613 Perturbed Loss 0.07766030464321375
Loss 0.060294814333319666 Acc 0.9784980976581573 Perturbed Loss 0.06746701573953033
Loss 0.06123996939510107 Acc 0.9812276661396027 Perturbed Loss 0.06758498705923557
Loss 0.06910965234041214 Acc 0.98199676156044 Perturbed Loss 0.07555041156709194
Epoch 13.0 val loss 0.05655680224299431 val acc 0.979793906211853
Loss 0.06355306416749955 Acc 0.980566463470459 Perturbed Loss 0.06913743441924453
Loss 0.07458863276988267 Acc 0.9772825014591217 Perturbed Loss 0.08240281093865633
Loss 0.06786872588098049 Acc 0.9798618972301483 Perturbed Loss 0.07373998250812291
Loss 0.07080572366714477 Acc 0.9777574563026428 Perturbed Loss 0.0785582328028977
Loss 0.07107062388211488 Acc 0.9787913429737091 Perturbed Loss 0.07817858453840017
Loss 0.05957809397950768 Acc 0.9814094924926757 Perturbed Loss 0.06630017889663577
Loss 0.06267143443226814 Acc 0.9816618335247039 Perturbed Loss 0.06929701831191779
Loss 0.05684802956879139 Acc 0.9805982899665833 Perturbed Loss 0.0627679480984807
Loss 0.06432877046987415 Acc 0.9817068064212799 Perturbed Loss 0.0702962264046073
Loss 0.06675034254789353 Acc 0.9748665714263915 Perturbed Loss 0.07718803007155657
Loss 0.07000884875655174 Acc 0.9792846059799194 Perturbed Loss 0.0772057992592454
Loss 0.06909567963331938 Acc 0.976974790096283 Perturbed Loss 0.07686489578336478
Loss 0.07110854403115809 Acc 0.980504629611969 Perturbed Loss 0.07892194231972098
Loss 0.07536203837022186 Acc 0.9745235431194306 Perturbed Loss 0.08619713362306357
Loss 0.0649163488484919 Acc 0.9801106894016266 Perturbed Loss 0.0710561304166913
Epoch 14.0 val loss 0.05565012991428375 val acc 0.9799632430076599
Loss 0.06907709244638681 Acc 0.9755647623538971 Perturbed Loss 0.07673579391092061
Loss 0.06966516140848399 Acc 0.9798084557056427 Perturbed Loss 0.07858047418296338
Loss 0.07508537633344531 Acc 0.973814709186554 Perturbed Loss 0.08298583952710033
Loss 0.07228420082479715 Acc 0.979350358247757 Perturbed Loss 0.07947284385561942
Loss 0.05812877139076591 Acc 0.9810254299640655 Perturbed Loss 0.06377543970942497
Loss 0.058293385244905946 Acc 0.9818032681941986 Perturbed Loss 0.06348219383507966
Loss 0.06482471387833356 Acc 0.9802622210979461 Perturbed Loss 0.07112671732902527
Loss 0.08825242487713694 Acc 0.9788491034507751 Perturbed Loss 0.09733390767127276
Loss 0.0753420739993453 Acc 0.97969153881073 Perturbed Loss 0.08225457660853863
Loss 0.07176285097375512 Acc 0.980229731798172 Perturbed Loss 0.08021150223910808
Loss 0.06356941720470786 Acc 0.9838102126121521 Perturbed Loss 0.07010215532034636
Loss 0.06925573039799929 Acc 0.9778416800498962 Perturbed Loss 0.07809706140309572
Loss 0.0646693611703813 Acc 0.9817899858951569 Perturbed Loss 0.07184375539422035
Loss 0.06259296663105487 Acc 0.9820671808719635 Perturbed Loss 0.06990826714783907
Loss 0.07675121665000915 Acc 0.9782752847671509 Perturbed Loss 0.08538949120789767
Epoch 15.0 val loss 0.056498050689697266 val acc 0.979738175868988
Loss 0.06723887766711414 Acc 0.9782006919384003 Perturbed Loss 0.07333825824782253
Loss 0.06704362194985151 Acc 0.9777317154407501 Perturbed Loss 0.07522719375789165
Loss 0.072900699544698 Acc 0.9800274360179901 Perturbed Loss 0.07954071123152971
Loss 0.06311198960989714 Acc 0.980038652420044 Perturbed Loss 0.07001225210726261
Loss 0.06218805134296417 Acc 0.9798509585857391 Perturbed Loss 0.07018583791330457
Loss 0.07169878209009767 Acc 0.9803992211818695 Perturbed Loss 0.07858836486935615
Loss 0.07434641163796187 Acc 0.9808812785148621 Perturbed Loss 0.08040690809488296
Loss 0.0750870631635189 Acc 0.97895845413208 Perturbed Loss 0.08210896946489811
Loss 0.06347058909013867 Acc 0.981003828048706 Perturbed Loss 0.07193857308477164
Loss 0.057105039935559036 Acc 0.9845837688446045 Perturbed Loss 0.06381368214264511
Loss 0.0675697099044919 Acc 0.9789625608921051 Perturbed Loss 0.0740287297591567
Loss 0.06459491205401718 Acc 0.9815756559371949 Perturbed Loss 0.0716696215607226
Loss 0.06206650175154209 Acc 0.9807046937942505 Perturbed Loss 0.06974524032324553
Loss 0.06748397806659341 Acc 0.9815287125110627 Perturbed Loss 0.07299463242292405
Loss 0.05917819164693355 Acc 0.9837789928913117 Perturbed Loss 0.06528427038341761
Epoch 16.0 val loss 0.05549996346235275 val acc 0.9799788594245911
Loss 0.07056321278214454 Acc 0.979372044801712 Perturbed Loss 0.08181031588464975
Loss 0.07113012295216321 Acc 0.982200618982315 Perturbed Loss 0.07789417818188667
Loss 0.059277073070406916 Acc 0.980071804523468 Perturbed Loss 0.0652094380557537
Loss 0.06940057080239058 Acc 0.9795219719409942 Perturbed Loss 0.07675003098323942
Loss 0.06302497554570437 Acc 0.9808542239665985 Perturbed Loss 0.07055899053812027
Loss 0.05807231742888689 Acc 0.9802059578895569 Perturbed Loss 0.06469605598598718
Loss 0.07159346647560597 Acc 0.9764866876602173 Perturbed Loss 0.0808565216884017
Loss 0.06625632731243968 Acc 0.9814332354068757 Perturbed Loss 0.07234212819486857
Loss 0.05500241432338953 Acc 0.9832337570190429 Perturbed Loss 0.06139631099998951
Loss 0.077729762904346 Acc 0.9775231444835663 Perturbed Loss 0.08393696345388889
Loss 0.0639291388168931 Acc 0.9794207406044007 Perturbed Loss 0.06969020860269666
Loss 0.06820338647812604 Acc 0.9782380139827729 Perturbed Loss 0.0755011509731412
Loss 0.06484792863950134 Acc 0.9750488710403442 Perturbed Loss 0.07101731445640326
Loss 0.0653127446398139 Acc 0.9792046391963959 Perturbed Loss 0.07206260673701763
Loss 0.06450146602466703 Acc 0.9833274936676025 Perturbed Loss 0.07061253091320395
Epoch 17.0 val loss 0.055720046162605286 val acc 0.9800580739974976
Loss 0.06706725345924497 Acc 0.9803131282329559 Perturbed Loss 0.07410755824297667
Loss 0.06991125140339136 Acc 0.980182363986969 Perturbed Loss 0.07695568226277828
Loss 0.06564494067803026 Acc 0.9774990677833557 Perturbed Loss 0.07106867358088494
Loss 0.06282563028857112 Acc 0.9822798764705658 Perturbed Loss 0.06844043664634228
Loss 0.06464932672679424 Acc 0.981372435092926 Perturbed Loss 0.07132823488675058
Loss 0.0561346057895571 Acc 0.9826094007492066 Perturbed Loss 0.06297873411327601
Loss 0.05939938813447952 Acc 0.9796369278430939 Perturbed Loss 0.06583007410168648
Loss 0.06098136730492115 Acc 0.9813546979427338 Perturbed Loss 0.07077428906224668
Loss 0.0673982355557382 Acc 0.9797570061683655 Perturbed Loss 0.07323851112276315
Loss 0.06397941458970308 Acc 0.9792065358161927 Perturbed Loss 0.07058483529835939
Loss 0.06248551469296217 Acc 0.9786098968982696 Perturbed Loss 0.06965994387865067
Loss 0.07485398629680276 Acc 0.9753738474845887 Perturbed Loss 0.08179992701858282
Loss 0.059859260208904745 Acc 0.979704020023346 Perturbed Loss 0.06743767641484738
Loss 0.07583682116121054 Acc 0.978673255443573 Perturbed Loss 0.08163891322910785
Loss 0.059230227377265694 Acc 0.9787144327163696 Perturbed Loss 0.06445208894088865
Epoch 18.0 val loss 0.05480162426829338 val acc 0.9802005887031555
Loss 0.06612740624696016 Acc 0.9771767210960388 Perturbed Loss 0.07300645921379328
Loss 0.06920334381982685 Acc 0.9787633371353149 Perturbed Loss 0.07539099302142858
Loss 0.06852056428790093 Acc 0.9795074880123138 Perturbed Loss 0.07366444315761328
Loss 0.05536171518266201 Acc 0.9797320854663849 Perturbed Loss 0.06086079545319081
Loss 0.061669382099062205 Acc 0.982370058298111 Perturbed Loss 0.06639390673488378
Loss 0.06491726418957114 Acc 0.9780479526519775 Perturbed Loss 0.07199195204302669
Loss 0.08326162155717612 Acc 0.976290978193283 Perturbed Loss 0.09071241430938244
Loss 0.06389885798096656 Acc 0.9798155808448792 Perturbed Loss 0.07045893844217062
Loss 0.06070592502132058 Acc 0.9812614774703979 Perturbed Loss 0.06622177615761757
Loss 0.06273614939302206 Acc 0.9803866267204284 Perturbed Loss 0.06919418059289456
Loss 0.06989919109269976 Acc 0.9785200607776642 Perturbed Loss 0.07618954235687853
Loss 0.06243182126432657 Acc 0.9785569620132446 Perturbed Loss 0.06844460114836692
Loss 0.064617642108351 Acc 0.9799193012714386 Perturbed Loss 0.06921966765075922
Loss 0.07607916161417962 Acc 0.9804096174240112 Perturbed Loss 0.08664088632911443
Loss 0.05941251911222935 Acc 0.9831753325462341 Perturbed Loss 0.064766088668257
Epoch 19.0 val loss 0.055355992168188095 val acc 0.9801313281059265
[22:34:08] INFO     `Trainer.fit` stopped: `max_epochs=20` reached.                                                                                                                         rank_zero.py:53
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750/750 0:03:45 • 0:00:00 3.35it/s train/loss: 0.059 val_loss: 0.055
[22:34:11] INFO     Created a temporary directory at /tmp/tmpi_so6ee4                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmpi_so6ee4/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
           INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
           INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
           INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
[22:34:12] INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
           INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
[22:34:13] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.0006, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.02, adaptive=True)
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.08797202367335558 Acc 0.9658514881134033 Perturbed Loss 0.09365212298929691
[22:34:43] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.07547598466277122 Acc 0.9716875922679901 Perturbed Loss 0.07958985980600118
Loss 0.08511378088966012 Acc 0.9773876893520356 Perturbed Loss 0.09030330877751112
Loss 0.08472050532698631 Acc 0.9737226569652557 Perturbed Loss 0.08766495619900525
Loss 0.08133625699207186 Acc 0.975766007900238 Perturbed Loss 0.08504676302894949
Loss 0.09579846240580082 Acc 0.9657593584060669 Perturbed Loss 0.09963304363191128
Loss 0.08257905893027782 Acc 0.9700361740589142 Perturbed Loss 0.08626656528562307
Loss 0.07993078138679266 Acc 0.9766196119785309 Perturbed Loss 0.08333994798362256
Loss 0.09043845158070325 Acc 0.9737313759326934 Perturbed Loss 0.09298527337610722
Loss 0.0845246266014874 Acc 0.9717356431484222 Perturbed Loss 0.08781411092728376
Loss 0.07608671378344298 Acc 0.9769769608974457 Perturbed Loss 0.07857557442039251
Loss 0.08470952557399869 Acc 0.9774600458145142 Perturbed Loss 0.08853188954293728
Loss 0.08337294328957796 Acc 0.9767824065685272 Perturbed Loss 0.08723870636895299
Loss 0.07583834066987037 Acc 0.9809572041034699 Perturbed Loss 0.08137473970651626
Loss 0.09282204031944274 Acc 0.9718888914585113 Perturbed Loss 0.0966986140422523
Epoch 0.0 val loss 0.058609865605831146 val acc 0.9781988859176636
Loss 0.08362779408693313 Acc 0.9723083472251892 Perturbed Loss 0.08686169993132353
Loss 0.07632556207478046 Acc 0.972997989654541 Perturbed Loss 0.079107116907835
Loss 0.0812204948067665 Acc 0.9669380784034729 Perturbed Loss 0.08376067195087672
Loss 0.07802255343645811 Acc 0.9716585719585419 Perturbed Loss 0.08089415624737739
Loss 0.08373389659449458 Acc 0.9755498170852661 Perturbed Loss 0.08619009166955947
Loss 0.07756422953680157 Acc 0.9776787209510803 Perturbed Loss 0.08053711293265224
Loss 0.08629875242710114 Acc 0.9748905110359192 Perturbed Loss 0.08851315144449473
Loss 0.0729949464276433 Acc 0.9782900726795196 Perturbed Loss 0.07483420632779599
Loss 0.0777046705968678 Acc 0.9761896872520447 Perturbed Loss 0.0804786329343915
Loss 0.07934064064174891 Acc 0.9772192990779877 Perturbed Loss 0.08173031777143479
Loss 0.07519603338092566 Acc 0.9697967720031738 Perturbed Loss 0.0779821327701211
Loss 0.09205952182412147 Acc 0.9710876882076264 Perturbed Loss 0.09635731175541878
Loss 0.07943702809512615 Acc 0.9798053693771362 Perturbed Loss 0.08147396109998226
Loss 0.09182439209893346 Acc 0.9721929907798768 Perturbed Loss 0.09558154815807939
Loss 0.08115171547979116 Acc 0.9763813233375549 Perturbed Loss 0.08413214441388846
Epoch 1.0 val loss 0.058030255138874054 val acc 0.9791507720947266
Loss 0.0741098841279745 Acc 0.9737739932537078 Perturbed Loss 0.07591825729236007
Loss 0.08471141748130322 Acc 0.9785112428665161 Perturbed Loss 0.0876152029260993
Loss 0.07731307961046696 Acc 0.9769698238372803 Perturbed Loss 0.08035073779523373
Loss 0.07469980120658874 Acc 0.9803439557552338 Perturbed Loss 0.07722071278840303
Loss 0.07248395379632712 Acc 0.9808743059635162 Perturbed Loss 0.0753655669093132
Loss 0.0717528998106718 Acc 0.9765988051891327 Perturbed Loss 0.0739814567938447
Loss 0.07959717892110348 Acc 0.9790282583236695 Perturbed Loss 0.08308689631521701
Loss 0.07890550155192613 Acc 0.9797651469707489 Perturbed Loss 0.08155772592872382
Loss 0.07870855275541544 Acc 0.9770544850826264 Perturbed Loss 0.08087269108742476
Loss 0.07654633095487952 Acc 0.9788071620464325 Perturbed Loss 0.07918240690603852
Loss 0.07391798228025437 Acc 0.9786717939376831 Perturbed Loss 0.07652207542210818
Loss 0.08543824344873428 Acc 0.9740773248672485 Perturbed Loss 0.08885456524789333
Loss 0.08387329135090113 Acc 0.9712300014495849 Perturbed Loss 0.08766657046973705
Loss 0.1020043184235692 Acc 0.9673039495944977 Perturbed Loss 0.10584814678877592
Loss 0.08194378156214953 Acc 0.9761958873271942 Perturbed Loss 0.08482212744653225
Epoch 2.0 val loss 0.05864257737994194 val acc 0.9789412021636963
Loss 0.07720766324549913 Acc 0.9765830326080323 Perturbed Loss 0.07948098003864289
Loss 0.07000536177307368 Acc 0.9795418334007263 Perturbed Loss 0.07193754382431507
Loss 0.07418633591383696 Acc 0.976919264793396 Perturbed Loss 0.07807917404919863
Loss 0.07716515608131885 Acc 0.9778718066215515 Perturbed Loss 0.08014159593731165
Loss 0.09316452950239182 Acc 0.9751017212867736 Perturbed Loss 0.09576683316379786
Loss 0.08421116948127746 Acc 0.9750691103935242 Perturbed Loss 0.08634040012955665
Loss 0.07113581322133541 Acc 0.9820942556858063 Perturbed Loss 0.07385830469429493
Loss 0.08085175223648548 Acc 0.9753518652915955 Perturbed Loss 0.08318795811384916
Loss 0.08581763222813606 Acc 0.9772072255611419 Perturbed Loss 0.08780250910669565
Loss 0.07781040344387292 Acc 0.976734344959259 Perturbed Loss 0.0795003080740571
Loss 0.06553067313507199 Acc 0.9776972937583923 Perturbed Loss 0.0680571074411273
Loss 0.08678668033331632 Acc 0.9740469861030578 Perturbed Loss 0.08862201146781444
Loss 0.08950726360082627 Acc 0.9759004247188569 Perturbed Loss 0.09189147248864174
Loss 0.07391681656241417 Acc 0.9721276044845581 Perturbed Loss 0.07604934830218553
Loss 0.07567384399473667 Acc 0.977350059747696 Perturbed Loss 0.0771072331443429
Epoch 3.0 val loss 0.05795901641249657 val acc 0.9791201949119568
Loss 0.06397506615146994 Acc 0.9807219755649567 Perturbed Loss 0.06590341622009874
Loss 0.07512985579669476 Acc 0.9815709042549133 Perturbed Loss 0.07729606498032808
Loss 0.06805095247924328 Acc 0.9749709343910218 Perturbed Loss 0.0704119673371315
Loss 0.09123392052948474 Acc 0.9775976383686066 Perturbed Loss 0.09328472862020135
Loss 0.07948423294350505 Acc 0.9746418368816375 Perturbed Loss 0.08115527287125587
Loss 0.0757312298938632 Acc 0.9773175275325775 Perturbed Loss 0.07777273312211036
Loss 0.0663952873274684 Acc 0.9796565818786621 Perturbed Loss 0.06813214987516403
Loss 0.07061304528266192 Acc 0.9767607593536377 Perturbed Loss 0.07297545038163662
Loss 0.0749189942330122 Acc 0.9761357414722442 Perturbed Loss 0.07721750382333994
Loss 0.07007728051394224 Acc 0.9760165274143219 Perturbed Loss 0.0728968540392816
Loss 0.08737875059247018 Acc 0.9769730699062348 Perturbed Loss 0.09094371180981398
Loss 0.08771679155528546 Acc 0.9741222023963928 Perturbed Loss 0.08999981384724379
Loss 0.07863315282389521 Acc 0.9767813885211944 Perturbed Loss 0.08035249272361397
Loss 0.07421995397657156 Acc 0.9797691631317139 Perturbed Loss 0.07627965439110994
Loss 0.07601540848612785 Acc 0.9801394832134247 Perturbed Loss 0.07888923849910498
Epoch 4.0 val loss 0.05889197811484337 val acc 0.9789156317710876
Loss 0.07125661380589009 Acc 0.9772039520740509 Perturbed Loss 0.07325740396976471
Loss 0.07915686182677746 Acc 0.9792410516738892 Perturbed Loss 0.08172393210232258
Loss 0.0824894329532981 Acc 0.9775669014453888 Perturbed Loss 0.08485934268683196
Loss 0.08206464281305671 Acc 0.9731649363040924 Perturbed Loss 0.08464691365137696
Loss 0.07265008226037026 Acc 0.9780242538452149 Perturbed Loss 0.07550054363906383
Loss 0.08213693108409643 Acc 0.9743430089950561 Perturbed Loss 0.08477582957595586
Loss 0.06858760986477136 Acc 0.9795331847667694 Perturbed Loss 0.07009881220757962
Loss 0.07143747832626104 Acc 0.9777882814407348 Perturbed Loss 0.07373078286647797
Loss 0.07374551437795163 Acc 0.9794140875339508 Perturbed Loss 0.07582423344254494
Loss 0.07496357087045907 Acc 0.9773624229431153 Perturbed Loss 0.07733182609081268
Loss 0.07504300687462091 Acc 0.9766491174697876 Perturbed Loss 0.07689339499920607
Loss 0.0807869566231966 Acc 0.9739633691310883 Perturbed Loss 0.08314291276037693
Loss 0.07615964226424694 Acc 0.9797300422191619 Perturbed Loss 0.07936912871897221
Loss 0.07834251552820205 Acc 0.9775688862800598 Perturbed Loss 0.08110336847603321
Loss 0.07009984942153097 Acc 0.9767006957530975 Perturbed Loss 0.07289701737463475
Epoch 5.0 val loss 0.06285503506660461 val acc 0.9777820110321045
Loss 0.0765544393658638 Acc 0.9774954128265381 Perturbed Loss 0.07840313851833343
Loss 0.07581464761868119 Acc 0.9790268194675446 Perturbed Loss 0.07900629606097936
Loss 0.0720428666099906 Acc 0.978671088218689 Perturbed Loss 0.07430748660117388
Loss 0.08516276460140944 Acc 0.9751195621490478 Perturbed Loss 0.08717690229415893
Loss 0.07159269327297807 Acc 0.9816903913021088 Perturbed Loss 0.07302414746955037
Loss 0.07654219904914498 Acc 0.9755421733856201 Perturbed Loss 0.07883093766868114
Loss 0.07177495449781418 Acc 0.9754933059215546 Perturbed Loss 0.07362227287143469
Loss 0.0704680772125721 Acc 0.9813378024101257 Perturbed Loss 0.07255274914205075
Loss 0.0721275807917118 Acc 0.9778301775455475 Perturbed Loss 0.07412388805299998
Loss 0.08246409008279443 Acc 0.9761550271511078 Perturbed Loss 0.08476373784244061
Loss 0.07628116020932793 Acc 0.9775946629047394 Perturbed Loss 0.07836427310481668
Loss 0.07466024119406939 Acc 0.9787374866008759 Perturbed Loss 0.07687989899888635
Loss 0.07538144637830556 Acc 0.9761197030544281 Perturbed Loss 0.07819063860923052
Loss 0.0780960326269269 Acc 0.9815102064609528 Perturbed Loss 0.08043636873364449
Loss 0.07882643219083547 Acc 0.9735422492027282 Perturbed Loss 0.08126920316368341
Epoch 6.0 val loss 0.060261208564043045 val acc 0.9787406921386719
Loss 0.08401272382587194 Acc 0.9748510456085205 Perturbed Loss 0.08739039095118642
Loss 0.08718693507835269 Acc 0.9764906167984009 Perturbed Loss 0.0899536170065403
Loss 0.07236393958330155 Acc 0.9779417800903321 Perturbed Loss 0.07401980474591255
Loss 0.06595815028995275 Acc 0.981660361289978 Perturbed Loss 0.06766817845404148
Loss 0.06971718376502395 Acc 0.977375715970993 Perturbed Loss 0.07128691187128425
Loss 0.08223705876618624 Acc 0.9779805827140808 Perturbed Loss 0.08448472268879413
Loss 0.08058138024061919 Acc 0.9753736770153045 Perturbed Loss 0.082944032587111
Loss 0.06497653087601066 Acc 0.9807215321063996 Perturbed Loss 0.06690448462963104
Loss 0.07488361082971096 Acc 0.9778609907627106 Perturbed Loss 0.0767079521715641
Loss 0.07656608615070581 Acc 0.9789270853996277 Perturbed Loss 0.07882405068725347
Loss 0.07482758279889822 Acc 0.9818722784519196 Perturbed Loss 0.07787248510867358
Loss 0.07134519109502435 Acc 0.9791561031341552 Perturbed Loss 0.07330506632104516
Loss 0.06728343043476342 Acc 0.9778899490833283 Perturbed Loss 0.07014712385833263
Loss 0.07302303425967693 Acc 0.9802961671352386 Perturbed Loss 0.07580231625586747
Loss 0.0795590989291668 Acc 0.9763397240638733 Perturbed Loss 0.08157460115849972
Epoch 7.0 val loss 0.05891433730721474 val acc 0.9785950183868408
Loss 0.0714215150475502 Acc 0.9774639403820038 Perturbed Loss 0.07368888691067696
Loss 0.07173710065893829 Acc 0.974412418603897 Perturbed Loss 0.0744111279770732
Loss 0.0665833625011146 Acc 0.9784251713752746 Perturbed Loss 0.06842361573129892
Loss 0.07516107186675072 Acc 0.9760929644107819 Perturbed Loss 0.07775598779320717
Loss 0.06706413567066193 Acc 0.9792043888568878 Perturbed Loss 0.06959903184324504
Loss 0.06869707046076655 Acc 0.9769597220420837 Perturbed Loss 0.07022314300760626
Loss 0.06199860077351332 Acc 0.9788094067573547 Perturbed Loss 0.0639676771312952
Loss 0.06599824275821448 Acc 0.9786890423297883 Perturbed Loss 0.06752519592642785
Loss 0.06855890590697528 Acc 0.9757939970493317 Perturbed Loss 0.07054421288892626
Loss 0.06707744127139449 Acc 0.9772414290904998 Perturbed Loss 0.06896276732906699
Loss 0.07398478128015995 Acc 0.9787096405029296 Perturbed Loss 0.07596433728933334
Loss 0.07269301580265164 Acc 0.9791651630401611 Perturbed Loss 0.07464893113821745
Loss 0.06906019747257233 Acc 0.9792377555370331 Perturbed Loss 0.07111014403402806
Loss 0.0755544825643301 Acc 0.9775195097923279 Perturbed Loss 0.07844039086252451
Loss 0.07394176565110683 Acc 0.9810291135311127 Perturbed Loss 0.07577674547210336
Epoch 8.0 val loss 0.059419576078653336 val acc 0.9792527556419373
Loss 0.07147437501698732 Acc 0.9754006958007813 Perturbed Loss 0.07348184302449226
Loss 0.07047502275556326 Acc 0.9783808493614197 Perturbed Loss 0.0725306799635291
Loss 0.07127544110640884 Acc 0.9775485360622406 Perturbed Loss 0.07320942433550953
Loss 0.06248248342424631 Acc 0.9794124114513397 Perturbed Loss 0.06422659888863563
Loss 0.07088878594338893 Acc 0.977962248325348 Perturbed Loss 0.07244722355157136
Loss 0.07060002107173205 Acc 0.9767782855033874 Perturbed Loss 0.07204773310571909
Loss 0.05985047910362482 Acc 0.9816167187690735 Perturbed Loss 0.06110502764582634
Loss 0.07705434489995241 Acc 0.9800072681903839 Perturbed Loss 0.07867675296962261
Loss 0.06279123473912478 Acc 0.9808033204078674 Perturbed Loss 0.06431282423436642
Loss 0.06468000456690788 Acc 0.9824224507808685 Perturbed Loss 0.06662244629114866
Loss 0.06628386173397302 Acc 0.9808050286769867 Perturbed Loss 0.06816427167505026
Loss 0.0710451669804752 Acc 0.9783197402954101 Perturbed Loss 0.0735162796638906
Loss 0.07089096322655677 Acc 0.9779804456233978 Perturbed Loss 0.07270696215331554
Loss 0.07949315913021565 Acc 0.976489155292511 Perturbed Loss 0.08196241836994886
Loss 0.07521502882242202 Acc 0.9769502580165863 Perturbed Loss 0.07804385421797633
Epoch 9.0 val loss 0.058729641139507294 val acc 0.9784201979637146
Loss 0.07425949102267623 Acc 0.9821483957767486 Perturbed Loss 0.076514143794775
Loss 0.06955711707472802 Acc 0.976801301240921 Perturbed Loss 0.0709493451192975
Loss 0.06614186525344849 Acc 0.980603095293045 Perturbed Loss 0.06821355730295181
Loss 0.07637208873406053 Acc 0.9752770137786865 Perturbed Loss 0.07800698567181825
Loss 0.0621948610059917 Acc 0.982454479932785 Perturbed Loss 0.06380191314965486
Loss 0.06643055694177746 Acc 0.978706443309784 Perturbed Loss 0.06813230874948203
Loss 0.06652234513312578 Acc 0.9780409801006317 Perturbed Loss 0.06830957483500243
Loss 0.06252702744677663 Acc 0.9826502859592438 Perturbed Loss 0.06393876515328883
Loss 0.062194824144244196 Acc 0.9791556179523468 Perturbed Loss 0.06387442264705896
Loss 0.0688042807020247 Acc 0.9771912610530853 Perturbed Loss 0.07079028863459826
Loss 0.06655012559145689 Acc 0.9779794418811798 Perturbed Loss 0.06847343157976865
Loss 0.07515658140182495 Acc 0.9779531776905059 Perturbed Loss 0.07721386928111315
Loss 0.06406118742190302 Acc 0.9805631220340729 Perturbed Loss 0.06636501029133797
Loss 0.06522224508225918 Acc 0.9772613847255707 Perturbed Loss 0.06759715169668197
Loss 0.06563825540244579 Acc 0.9771679997444153 Perturbed Loss 0.06767066549509763
Epoch 10.0 val loss 0.05680899694561958 val acc 0.9793410897254944
Loss 0.06853129548951983 Acc 0.9798816466331481 Perturbed Loss 0.07047726183198393
Loss 0.06998636351898313 Acc 0.9812848424911499 Perturbed Loss 0.07240148102864623
Loss 0.0656461237743497 Acc 0.9796438956260681 Perturbed Loss 0.067192871440202
Loss 0.06251867819577456 Acc 0.9780546855926514 Perturbed Loss 0.06428019359707832
Loss 0.06953401416540146 Acc 0.9781369268894196 Perturbed Loss 0.07188688416033984
Loss 0.06795730158686637 Acc 0.9780286145210266 Perturbed Loss 0.07037990491837263
Loss 0.07115053426474333 Acc 0.9788199150562287 Perturbed Loss 0.07374663911759853
Loss 0.0770059909299016 Acc 0.9775012993812561 Perturbed Loss 0.0786571205407381
Loss 0.06100818835198879 Acc 0.9799560689926148 Perturbed Loss 0.06336424473673105
Loss 0.06471859909594059 Acc 0.981548844575882 Perturbed Loss 0.06654472451657056
Loss 0.06889976872131229 Acc 0.9777392208576202 Perturbed Loss 0.07038777939975262
Loss 0.07090946920216083 Acc 0.9800449419021606 Perturbed Loss 0.0730701757222414
Loss 0.08064570989459753 Acc 0.9758863592147827 Perturbed Loss 0.0832612644508481
Loss 0.0649683666601777 Acc 0.9817945241928101 Perturbed Loss 0.06725990764796734
Loss 0.062405932620167734 Acc 0.9808446991443635 Perturbed Loss 0.06375270787626505
Epoch 11.0 val loss 0.05679066851735115 val acc 0.9789024591445923
Loss 0.08102489154785872 Acc 0.9789800429344178 Perturbed Loss 0.08285440843552351
Loss 0.07047340091317893 Acc 0.9768667078018188 Perturbed Loss 0.07264368802309036
Loss 0.07257726896554231 Acc 0.9815915846824645 Perturbed Loss 0.07502260338515043
Loss 0.06050116803497076 Acc 0.9796746683120727 Perturbed Loss 0.06198197286576033
Loss 0.06379060290753841 Acc 0.9840826439857483 Perturbed Loss 0.06567453077062964
Loss 0.06544523850083352 Acc 0.9793183135986329 Perturbed Loss 0.06788071377202869
Loss 0.06613583514466882 Acc 0.9800887525081634 Perturbed Loss 0.06746714815497398
Loss 0.06162564733996987 Acc 0.9800355505943298 Perturbed Loss 0.06344084786251188
Loss 0.06251182481646538 Acc 0.9783420705795288 Perturbed Loss 0.06388787463307381
Loss 0.06204750768840313 Acc 0.9812244975566864 Perturbed Loss 0.06391493681818247
Loss 0.07268755416385829 Acc 0.9787604343891144 Perturbed Loss 0.07476791095919907
Loss 0.06286777814850211 Acc 0.9763086092472076 Perturbed Loss 0.06430335381999612
Loss 0.0756333929207176 Acc 0.9817562139034272 Perturbed Loss 0.07823833791539073
Loss 0.06662849929183721 Acc 0.9807071542739868 Perturbed Loss 0.06937445871531964
Loss 0.06950606094673276 Acc 0.9749945902824402 Perturbed Loss 0.07115554392337799
Epoch 12.0 val loss 0.0562637597322464 val acc 0.9794967174530029
Loss 0.07162142094224691 Acc 0.978330111503601 Perturbed Loss 0.07358280099928378
Loss 0.07431317269802093 Acc 0.9771225559711456 Perturbed Loss 0.07607469610869884
Loss 0.07443648643791675 Acc 0.9784221875667573 Perturbed Loss 0.07626813668757677
Loss 0.06481197044253349 Acc 0.9825512325763702 Perturbed Loss 0.06632309269160032
Loss 0.06499046597629786 Acc 0.9804486167430878 Perturbed Loss 0.06744836444966495
Loss 0.07102703589946031 Acc 0.9812535524368287 Perturbed Loss 0.07271212209016084
Loss 0.07163735222071409 Acc 0.9755711877346038 Perturbed Loss 0.07319403935223817
Loss 0.06857390774413943 Acc 0.9777993488311768 Perturbed Loss 0.07017156166024506
Loss 0.07088079305365681 Acc 0.9787782025337219 Perturbed Loss 0.07298263741657138
Loss 0.06714368939399719 Acc 0.9793511652946472 Perturbed Loss 0.06882502991706133
Loss 0.0712521605938673 Acc 0.9789378380775452 Perturbed Loss 0.07303504455834627
Loss 0.07029955625534058 Acc 0.981008244752884 Perturbed Loss 0.07225917980074882
Loss 0.06370818186551333 Acc 0.978399943113327 Perturbed Loss 0.06611701361835003
Loss 0.059728159569203854 Acc 0.9813088154792786 Perturbed Loss 0.06128086665645242
Loss 0.07140237033367157 Acc 0.9818432605266572 Perturbed Loss 0.07395444385707378
Epoch 13.0 val loss 0.056163668632507324 val acc 0.9797745943069458
Loss 0.06374785972759128 Acc 0.9792999577522278 Perturbed Loss 0.06550656521692871
Loss 0.07372279491275549 Acc 0.9765797960758209 Perturbed Loss 0.07632944989949465
Loss 0.0686719123274088 Acc 0.9797236573696136 Perturbed Loss 0.0701806041225791
Loss 0.07091112757101654 Acc 0.977098081111908 Perturbed Loss 0.07248156279325485
Loss 0.06929690152406692 Acc 0.9785781407356262 Perturbed Loss 0.07071375090628862
Loss 0.05715439189225435 Acc 0.9817390215396881 Perturbed Loss 0.058806458860635756
Loss 0.06144750989973545 Acc 0.9816811633110046 Perturbed Loss 0.06354954402893781
Loss 0.059291154481470584 Acc 0.9801762330532074 Perturbed Loss 0.06097344540059566
Loss 0.06503281705081462 Acc 0.9818356394767761 Perturbed Loss 0.06637773267924786
Loss 0.06261997256428004 Acc 0.9754575443267822 Perturbed Loss 0.06505057904869319
Loss 0.0722594666481018 Acc 0.979730863571167 Perturbed Loss 0.07411077845841646
Loss 0.06689365614205599 Acc 0.9761425578594207 Perturbed Loss 0.06875992149114608
Loss 0.07293551312759519 Acc 0.9804774296283721 Perturbed Loss 0.07450462644919753
Loss 0.07561710834503174 Acc 0.9747378718852997 Perturbed Loss 0.07803932894021273
Loss 0.0651490713097155 Acc 0.9802519917488098 Perturbed Loss 0.06676536472514272
Epoch 14.0 val loss 0.05479949340224266 val acc 0.9800478219985962
Loss 0.06742151902057231 Acc 0.9756389808654785 Perturbed Loss 0.0692992495931685
Loss 0.06774162430316209 Acc 0.9797991561889648 Perturbed Loss 0.06998305734246969
Loss 0.07452447397634387 Acc 0.9744761538505554 Perturbed Loss 0.07702473560348153
Loss 0.0679914589971304 Acc 0.9785023128986359 Perturbed Loss 0.07032128386199474
Loss 0.053822147455066444 Acc 0.9814650094509125 Perturbed Loss 0.0558858853392303
Loss 0.05924077908974141 Acc 0.9813499760627746 Perturbed Loss 0.060823229500092564
Loss 0.06436195440590381 Acc 0.9800951683521271 Perturbed Loss 0.06580290936864913
Loss 0.08400931937620043 Acc 0.9784544384479523 Perturbed Loss 0.08587720047682523
Loss 0.07078628782182932 Acc 0.9799550628662109 Perturbed Loss 0.07282921269536019
Loss 0.06728042034432292 Acc 0.9803148508071899 Perturbed Loss 0.06891046328470112
Loss 0.06249663357622921 Acc 0.983545194864273 Perturbed Loss 0.06366845238953829
Loss 0.06767798449844122 Acc 0.9775859606266022 Perturbed Loss 0.06924540005624294
Loss 0.0635807878896594 Acc 0.9816617083549499 Perturbed Loss 0.06549931026995182
Loss 0.06192784950137138 Acc 0.9817393028736114 Perturbed Loss 0.06332331206649541
Loss 0.0751572858542204 Acc 0.9777238845825196 Perturbed Loss 0.07717664290219545
Epoch 15.0 val loss 0.05491604283452034 val acc 0.9798459410667419
Loss 0.06558148331940174 Acc 0.9774979937076569 Perturbed Loss 0.0670349758118391
Loss 0.0678650963306427 Acc 0.9777564167976379 Perturbed Loss 0.07002577167004347
Loss 0.07216787835583091 Acc 0.9799694800376892 Perturbed Loss 0.07356185995042325
Loss 0.06324317004531622 Acc 0.9806299304962158 Perturbed Loss 0.06448590129613876
Loss 0.061456492152065036 Acc 0.9804805111885071 Perturbed Loss 0.06292099801823497
Loss 0.0700103491358459 Acc 0.9805129218101502 Perturbed Loss 0.07141262337565422
Loss 0.07134904634207487 Acc 0.9800881600379944 Perturbed Loss 0.07259949889034033
Loss 0.07577092587947845 Acc 0.9789371991157532 Perturbed Loss 0.07765617821365595
Loss 0.06317313253879547 Acc 0.9805342781543732 Perturbed Loss 0.06549211183562875
Loss 0.054730654209852216 Acc 0.9843972480297088 Perturbed Loss 0.055860126502811906
Loss 0.06618221625685691 Acc 0.9787585818767548 Perturbed Loss 0.06807153888046741
Loss 0.0625545503385365 Acc 0.9816122925281525 Perturbed Loss 0.06405875382013619
Loss 0.059681668914854526 Acc 0.9808637380599976 Perturbed Loss 0.0613263588771224
Loss 0.06823188070207835 Acc 0.980908533334732 Perturbed Loss 0.07037257511168718
Loss 0.05894018342718482 Acc 0.9839628326892853 Perturbed Loss 0.060351441614329815
Epoch 16.0 val loss 0.05499042198061943 val acc 0.9798997640609741
Loss 0.0675703190639615 Acc 0.9797466254234314 Perturbed Loss 0.06991351321339608
Loss 0.06960894927382469 Acc 0.9819117796421051 Perturbed Loss 0.07069908898323775
Loss 0.060145810954272745 Acc 0.9794332826137543 Perturbed Loss 0.06161869149655104
Loss 0.06809350244700908 Acc 0.9798282277584076 Perturbed Loss 0.06959904531016946
Loss 0.0618157859519124 Acc 0.9805927217006684 Perturbed Loss 0.06435365905985237
Loss 0.058910154215991495 Acc 0.9803690838813782 Perturbed Loss 0.06083653621375561
Loss 0.06754181619733572 Acc 0.9770147573947906 Perturbed Loss 0.06933653378859163
Loss 0.06488380404189228 Acc 0.9810217320919037 Perturbed Loss 0.06639369079843163
Loss 0.054353980794548985 Acc 0.9830635452270508 Perturbed Loss 0.05627766154706478
Loss 0.07811222022399306 Acc 0.978064421415329 Perturbed Loss 0.0797224735468626
Loss 0.06288448872044683 Acc 0.9793711841106415 Perturbed Loss 0.06401435472071171
Loss 0.06812319744378328 Acc 0.9784059989452362 Perturbed Loss 0.0703089863061905
Loss 0.06289227714762091 Acc 0.9752494812011718 Perturbed Loss 0.06470226470381021
Loss 0.0657162137143314 Acc 0.9785081243515015 Perturbed Loss 0.06767940364778041
Loss 0.06351501613855362 Acc 0.9828602635860443 Perturbed Loss 0.06466025520116091
Epoch 17.0 val loss 0.054928600788116455 val acc 0.9801337122917175
Loss 0.06652550907805561 Acc 0.9801854741573334 Perturbed Loss 0.06826648205518722
Loss 0.0669671742618084 Acc 0.9810162949562072 Perturbed Loss 0.06859651573002339
Loss 0.06701354756951332 Acc 0.9775433206558227 Perturbed Loss 0.06827715648338199
Loss 0.06309043526649476 Acc 0.9821111226081848 Perturbed Loss 0.06471336640417576
Loss 0.0640326423291117 Acc 0.9814253425598145 Perturbed Loss 0.06596207694150508
Loss 0.05475138496607542 Acc 0.9827859222888946 Perturbed Loss 0.05621955342590809
Loss 0.0594366155192256 Acc 0.9794153380393982 Perturbed Loss 0.06077487323433161
Loss 0.058234180584549905 Acc 0.9815332758426666 Perturbed Loss 0.060222757933661344
Loss 0.0662348322197795 Acc 0.9801903736591339 Perturbed Loss 0.06769088501110673
Loss 0.06431273266673088 Acc 0.9795605683326721 Perturbed Loss 0.0655121698230505
Loss 0.06092423919588327 Acc 0.9791693937778473 Perturbed Loss 0.0624993335083127
Loss 0.07542300462722779 Acc 0.9754548847675324 Perturbed Loss 0.07702391371130943
Loss 0.060890026316046716 Acc 0.9790884518623352 Perturbed Loss 0.06331629451364279
Loss 0.07587799359112977 Acc 0.9788929843902587 Perturbed Loss 0.07764002908021211
Loss 0.058995537627488374 Acc 0.9786663186550141 Perturbed Loss 0.060264805406332014
Epoch 18.0 val loss 0.054000843316316605 val acc 0.9801931977272034
Loss 0.06638319607824088 Acc 0.9772337186336517 Perturbed Loss 0.06774587322026492
Loss 0.06900939708575607 Acc 0.978765766620636 Perturbed Loss 0.07069192921742797
Loss 0.06846418526023626 Acc 0.9794776678085327 Perturbed Loss 0.06983962222933769
Loss 0.05487743742763996 Acc 0.9793885421752929 Perturbed Loss 0.0565855360776186
Loss 0.061459459681063894 Acc 0.982285897731781 Perturbed Loss 0.06346041711047291
Loss 0.06462292931973934 Acc 0.9778831291198731 Perturbed Loss 0.06655320888385177
Loss 0.08363263005390763 Acc 0.9766554570198059 Perturbed Loss 0.08552408378571272
Loss 0.06233614837750792 Acc 0.9798589706420898 Perturbed Loss 0.06380548464134335
Loss 0.059886205792427066 Acc 0.9811247789859772 Perturbed Loss 0.06124093292281032
Loss 0.06301934391260147 Acc 0.9801558256149292 Perturbed Loss 0.0648221043869853
Loss 0.06844408063217998 Acc 0.9792937707901 Perturbed Loss 0.0701493202522397
Loss 0.06186732493340969 Acc 0.978969566822052 Perturbed Loss 0.06337590791285037
Loss 0.0664132876507938 Acc 0.9798046779632569 Perturbed Loss 0.06809051109477877
Loss 0.07332383438944817 Acc 0.9802770936489105 Perturbed Loss 0.07490150678902864
Loss 0.059677891694009305 Acc 0.9824968504905701 Perturbed Loss 0.06111119037494064
Epoch 19.0 val loss 0.05473817139863968 val acc 0.9800972938537598
[23:58:01] INFO     `Trainer.fit` stopped: `max_epochs=20` reached.                                                                                                                         rank_zero.py:53
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750/750 0:03:45 • 0:00:00 3.36it/s train/loss: 0.06 val_loss: 0.055
[23:58:04] INFO     Created a temporary directory at /tmp/tmpyipzjxr7                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmpyipzjxr7/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
           INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
           INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
           INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
           INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
[23:58:05] INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
[23:58:06] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.0006, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.005, adaptive=True)
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.0879946968331933 Acc 0.9659458768367767 Perturbed Loss 0.08947982519865036
[23:58:36] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.0753695622459054 Acc 0.9716472125053406 Perturbed Loss 0.07647331066429615
Loss 0.087074831482023 Acc 0.9767410683631897 Perturbed Loss 0.08818889394402504
Loss 0.08253584366291761 Acc 0.9729507827758789 Perturbed Loss 0.08326090209186077
Loss 0.08131254732608795 Acc 0.9765130841732025 Perturbed Loss 0.0821347626298666
Loss 0.0972288752347231 Acc 0.9657244384288788 Perturbed Loss 0.0983830126002431
Loss 0.08249602276831865 Acc 0.9709554970264435 Perturbed Loss 0.08349179759621621
Loss 0.08011723186820746 Acc 0.9771881079673768 Perturbed Loss 0.08090453960001469
Loss 0.0863459076359868 Acc 0.973898754119873 Perturbed Loss 0.0870028255134821
Loss 0.0852442668005824 Acc 0.9709642648696899 Perturbed Loss 0.08604827789589763
Loss 0.07563921332359314 Acc 0.9776821780204773 Perturbed Loss 0.0762336116656661
Loss 0.08583967635408044 Acc 0.9770962464809417 Perturbed Loss 0.08658875795081258
Loss 0.08157002599909902 Acc 0.9771291065216064 Perturbed Loss 0.08267214370891451
Loss 0.0707304059714079 Acc 0.9824459278583526 Perturbed Loss 0.07141015008091926
Loss 0.0841890869103372 Acc 0.9752354335784912 Perturbed Loss 0.08489394433796406
Epoch 0.0 val loss 0.06195337325334549 val acc 0.9786732792854309
Loss 0.08266188967972994 Acc 0.9741541266441345 Perturbed Loss 0.08356173131614923
Loss 0.07830596702173352 Acc 0.9717867851257325 Perturbed Loss 0.07903139253146946
Loss 0.08159516535699368 Acc 0.9673231875896454 Perturbed Loss 0.08236585479229688
Loss 0.07916867643594742 Acc 0.9736497271060943 Perturbed Loss 0.07996572975069284
Loss 0.08127186752855778 Acc 0.9762678718566895 Perturbed Loss 0.08177573746070266
Loss 0.07591715676710009 Acc 0.9768362843990326 Perturbed Loss 0.07663704043254256
Loss 0.0862038829177618 Acc 0.9754633355140686 Perturbed Loss 0.08695950150489808
Loss 0.07539399273693562 Acc 0.9788355803489686 Perturbed Loss 0.0759459500387311
Loss 0.07464604772627353 Acc 0.9764077293872834 Perturbed Loss 0.0752673495747149
Loss 0.07830290546640754 Acc 0.9759247303009033 Perturbed Loss 0.07912236180156469
Loss 0.08349299123510719 Acc 0.970807068347931 Perturbed Loss 0.08423156218603253
Loss 0.09198841083794833 Acc 0.9714850318431855 Perturbed Loss 0.09292907740920782
Loss 0.07740059118717908 Acc 0.9789208245277404 Perturbed Loss 0.07789839547127485
Loss 0.09272426448762416 Acc 0.9726224386692047 Perturbed Loss 0.09359642393887042
Loss 0.07835821889340877 Acc 0.9751580929756165 Perturbed Loss 0.07925548303872347
Epoch 1.0 val loss 0.06100353226065636 val acc 0.9777287244796753
Loss 0.08138134118169546 Acc 0.9736752843856812 Perturbed Loss 0.0820808769389987
Loss 0.08483111158013344 Acc 0.978076936006546 Perturbed Loss 0.08533691104501485
Loss 0.07829820029437543 Acc 0.9766630113124848 Perturbed Loss 0.07915276430547237
Loss 0.07409802261739969 Acc 0.9811051595211029 Perturbed Loss 0.07462651455774903
Loss 0.07636060871183872 Acc 0.9805414760112763 Perturbed Loss 0.07711229253560305
Loss 0.06957243498414754 Acc 0.9772742140293121 Perturbed Loss 0.0701346480473876
Loss 0.07912953618913889 Acc 0.9790717339515687 Perturbed Loss 0.07987433359026909
Loss 0.0821120984479785 Acc 0.9807860445976258 Perturbed Loss 0.08272923074662686
Loss 0.08559713665395975 Acc 0.9749866294860839 Perturbed Loss 0.08640795979648828
Loss 0.08376074185594916 Acc 0.9783320820331574 Perturbed Loss 0.08478524345904588
Loss 0.07456649918109179 Acc 0.978615243434906 Perturbed Loss 0.07518929112702608
Loss 0.09200427427887917 Acc 0.9735988175868988 Perturbed Loss 0.09293945234268904
Loss 0.08598343584686517 Acc 0.9710754704475403 Perturbed Loss 0.0869637592509389
Loss 0.09735799949616193 Acc 0.9671726536750793 Perturbed Loss 0.09795254211872816
Loss 0.08354965969920158 Acc 0.9755986845493316 Perturbed Loss 0.08437191087752581
Epoch 2.0 val loss 0.06032839044928551 val acc 0.9783912301063538
Loss 0.07467943135648966 Acc 0.9758954501152038 Perturbed Loss 0.07558191642165184
Loss 0.06604773376137019 Acc 0.97976167678833 Perturbed Loss 0.06671651262789964
Loss 0.07257948864251375 Acc 0.9791715872287751 Perturbed Loss 0.07340772721916437
Loss 0.0819152258336544 Acc 0.9787792885303497 Perturbed Loss 0.08288658916950226
Loss 0.10038290292024613 Acc 0.9761935865879059 Perturbed Loss 0.10146516315639019
Loss 0.08078216720372439 Acc 0.9765114414691926 Perturbed Loss 0.08150348149240016
Loss 0.06981514021754265 Acc 0.9824554586410522 Perturbed Loss 0.07044393703341484
Loss 0.08041897874325514 Acc 0.9756816518306732 Perturbed Loss 0.08103381581604481
Loss 0.08502190098166466 Acc 0.9780128955841064 Perturbed Loss 0.08567669402807951
Loss 0.08021552024409175 Acc 0.9757287073135376 Perturbed Loss 0.08075031021609902
Loss 0.06867343464866281 Acc 0.976234896183014 Perturbed Loss 0.0693563598766923
Loss 0.08497339710593224 Acc 0.9733569502830506 Perturbed Loss 0.08557945784181356
Loss 0.09114806976169348 Acc 0.9753530347347259 Perturbed Loss 0.09194663882255555
Loss 0.08024897204712034 Acc 0.9709833455085755 Perturbed Loss 0.08099331319332123
Loss 0.08047023639082909 Acc 0.9756934773921967 Perturbed Loss 0.08106455530971289
Epoch 3.0 val loss 0.05898305028676987 val acc 0.9790777564048767
Loss 0.06512322273105382 Acc 0.9808209586143494 Perturbed Loss 0.06567616948857903
Loss 0.07456818073987961 Acc 0.9803543663024903 Perturbed Loss 0.07540205225348473
Loss 0.06753268919885158 Acc 0.9732423913478851 Perturbed Loss 0.06813152022659778
Loss 0.09144043434411288 Acc 0.9778419804573059 Perturbed Loss 0.0918691961467266
Loss 0.07676487628370524 Acc 0.9763897061347961 Perturbed Loss 0.07739620884880423
Loss 0.07144646763801575 Acc 0.9780771374702454 Perturbed Loss 0.07212166622281074
Loss 0.07067602690309287 Acc 0.978743747472763 Perturbed Loss 0.07113065473735332
Loss 0.07165399245917797 Acc 0.9794927060604095 Perturbed Loss 0.07224269941449166
Loss 0.07135442649945617 Acc 0.9754759764671326 Perturbed Loss 0.07201634265482426
Loss 0.07111984893679618 Acc 0.9759532165527344 Perturbed Loss 0.07192424146458506
Loss 0.08305569250136614 Acc 0.9781144976615905 Perturbed Loss 0.08403978973627091
Loss 0.08590946855023503 Acc 0.9745358645915985 Perturbed Loss 0.08651700861752033
Loss 0.07768019948154688 Acc 0.9750843799114227 Perturbed Loss 0.07819651514291763
Loss 0.07282760322093963 Acc 0.9793768036365509 Perturbed Loss 0.07332146793603897
Loss 0.06991695534437894 Acc 0.9790880692005157 Perturbed Loss 0.07055907059460878
Epoch 4.0 val loss 0.05720942094922066 val acc 0.9793497323989868
Loss 0.07278004098683595 Acc 0.976602567434311 Perturbed Loss 0.0735092031210661
Loss 0.07839390441775322 Acc 0.9794812262058258 Perturbed Loss 0.07901137016713619
Loss 0.08238352328538895 Acc 0.9769039702415466 Perturbed Loss 0.08296175140887499
Loss 0.08101453647017479 Acc 0.9725091302394867 Perturbed Loss 0.0816395491734147
Loss 0.07236479371786117 Acc 0.9762227594852447 Perturbed Loss 0.07302938781678676
Loss 0.08717504695057869 Acc 0.9748117876052856 Perturbed Loss 0.08803990352898836
Loss 0.06769712794572115 Acc 0.9790991473197938 Perturbed Loss 0.06815338548272848
Loss 0.06640381030738354 Acc 0.9779537630081176 Perturbed Loss 0.06706327956169844
Loss 0.07357817091047764 Acc 0.9793465518951416 Perturbed Loss 0.07440502010285854
Loss 0.07587430212646723 Acc 0.9766311287879944 Perturbed Loss 0.0766262198239565
Loss 0.07799305826425552 Acc 0.9763617849349976 Perturbed Loss 0.07859594576060772
Loss 0.08475007575005293 Acc 0.9738871932029725 Perturbed Loss 0.0854808197543025
Loss 0.08432572919875383 Acc 0.9783778607845306 Perturbed Loss 0.08518406968563795
Loss 0.08453387707471847 Acc 0.976042456626892 Perturbed Loss 0.0853072565048933
Loss 0.07158433178439737 Acc 0.9768029081821442 Perturbed Loss 0.07220067134127021
Epoch 5.0 val loss 0.05782909318804741 val acc 0.9787800908088684
Loss 0.07484942089766264 Acc 0.9780613148212433 Perturbed Loss 0.07528247587382793
Loss 0.07415835609659553 Acc 0.9793539655208587 Perturbed Loss 0.07465687232092023
Loss 0.07569927854463458 Acc 0.9790953862667083 Perturbed Loss 0.07642071094363928
Loss 0.08642060175538063 Acc 0.9761486446857452 Perturbed Loss 0.08696803353726863
Loss 0.07673602452501654 Acc 0.9820575022697449 Perturbed Loss 0.07717558950185775
Loss 0.07606347359716892 Acc 0.9766767084598541 Perturbed Loss 0.07677661396563053
Loss 0.07303276147693395 Acc 0.9754012477397919 Perturbed Loss 0.07344253655523061
Loss 0.07220139868557453 Acc 0.9811999154090881 Perturbed Loss 0.07271391320973634
Loss 0.06908432718366385 Acc 0.9792709875106812 Perturbed Loss 0.06950430411845446
Loss 0.08192167209461332 Acc 0.9765260457992554 Perturbed Loss 0.08235614102333784
Loss 0.07681796310469508 Acc 0.9787834513187409 Perturbed Loss 0.07739300338551403
Loss 0.07318975604139269 Acc 0.9784366059303283 Perturbed Loss 0.07370514609850944
Loss 0.07792646502144635 Acc 0.9766620743274689 Perturbed Loss 0.0788437194377184
Loss 0.07766887001693248 Acc 0.9811652815341949 Perturbed Loss 0.07827066008001565
Loss 0.07653345383703708 Acc 0.9740487170219422 Perturbed Loss 0.07715871319174766
Epoch 6.0 val loss 0.05790189281105995 val acc 0.9793790578842163
Loss 0.08205189261585474 Acc 0.9753319120407105 Perturbed Loss 0.08262588435783982
Loss 0.08634058181196451 Acc 0.9771250176429749 Perturbed Loss 0.08694988946430385
Loss 0.07383097585290671 Acc 0.9779797554016113 Perturbed Loss 0.07431367833167314
Loss 0.06533480916172266 Acc 0.9818804347515107 Perturbed Loss 0.0659244092181325
Loss 0.06824383912608027 Acc 0.9769539368152619 Perturbed Loss 0.06887679930776358
Loss 0.07775441609323025 Acc 0.9777727866172791 Perturbed Loss 0.07852522037923336
Loss 0.07987605281174183 Acc 0.9753809988498687 Perturbed Loss 0.08050210110843181
Loss 0.06641422575339676 Acc 0.9802856433391571 Perturbed Loss 0.06677760165184736
Loss 0.0749068321660161 Acc 0.9768740057945251 Perturbed Loss 0.0755313553661108
Loss 0.07750767603516578 Acc 0.9779437363147736 Perturbed Loss 0.07808894660323858
Loss 0.08159593738615513 Acc 0.980895048379898 Perturbed Loss 0.08232266098260879
Loss 0.07026112467050552 Acc 0.9784583711624145 Perturbed Loss 0.07066373094916344
Loss 0.0686039797961712 Acc 0.9769179284572601 Perturbed Loss 0.06914045576006174
Loss 0.07296348482370377 Acc 0.9806524860858917 Perturbed Loss 0.07395736388862133
Loss 0.08324901632964611 Acc 0.9760567557811737 Perturbed Loss 0.08393347550183534
Epoch 7.0 val loss 0.05915834382176399 val acc 0.9782886505126953
Loss 0.07232180580496789 Acc 0.9773738408088684 Perturbed Loss 0.07300026945769787
Loss 0.0710730242356658 Acc 0.9727380549907685 Perturbed Loss 0.07166748257353901
Loss 0.06734055744484067 Acc 0.9785800290107727 Perturbed Loss 0.06786538999527693
Loss 0.0771252504363656 Acc 0.9754669547080994 Perturbed Loss 0.07786645349115133
Loss 0.0675470484048128 Acc 0.9791155755519867 Perturbed Loss 0.06831502921879291
Loss 0.07292857304215432 Acc 0.9782797682285309 Perturbed Loss 0.07341303592547774
Loss 0.06581368643790483 Acc 0.9774055337905884 Perturbed Loss 0.0664015045389533
Loss 0.06828475341200829 Acc 0.9786213958263397 Perturbed Loss 0.06874694675207138
Loss 0.07659513579681515 Acc 0.9754901623725891 Perturbed Loss 0.07714854521676898
Loss 0.06722576085478067 Acc 0.9770381414890289 Perturbed Loss 0.06785756316035986
Loss 0.07224132981151342 Acc 0.9785104715824127 Perturbed Loss 0.07277737148106098
Loss 0.07569686077535152 Acc 0.9782844281196594 Perturbed Loss 0.07607975531369447
Loss 0.07015856843441724 Acc 0.9785565996170044 Perturbed Loss 0.07077775433659554
Loss 0.07785212025046348 Acc 0.9770294094085693 Perturbed Loss 0.07836503589525819
Loss 0.07615692999213934 Acc 0.9819449627399445 Perturbed Loss 0.07671961072832346
Epoch 8.0 val loss 0.06047500669956207 val acc 0.9792774319648743
Loss 0.07110342290252447 Acc 0.9754910469055176 Perturbed Loss 0.07168130043894053
Loss 0.07154876235872507 Acc 0.9782550644874572 Perturbed Loss 0.07228093758225441
Loss 0.07435848707333208 Acc 0.9759142231941224 Perturbed Loss 0.07500530496239662
Loss 0.06293759904801846 Acc 0.9784541857242585 Perturbed Loss 0.06347129389643669
Loss 0.0750485983863473 Acc 0.9774173188209534 Perturbed Loss 0.07555329795926809
Loss 0.07188044842332601 Acc 0.9769868350028992 Perturbed Loss 0.0722241073474288
Loss 0.06013517644256353 Acc 0.981175286769867 Perturbed Loss 0.06049514692276716
Loss 0.0820807534456253 Acc 0.9793933761119843 Perturbed Loss 0.08262667085975409
Loss 0.06599479887634516 Acc 0.9798310601711273 Perturbed Loss 0.06664497289806605
Loss 0.06755848743021488 Acc 0.9816546499729156 Perturbed Loss 0.0680341788008809
Loss 0.0661250825598836 Acc 0.9803808808326722 Perturbed Loss 0.06653347838670015
Loss 0.06814409844577313 Acc 0.97842200756073 Perturbed Loss 0.06864607352763415
Loss 0.07172483503818512 Acc 0.9779269993305206 Perturbed Loss 0.07218066778033971
Loss 0.08399867488071322 Acc 0.9766208600997924 Perturbed Loss 0.08456833710893989
Loss 0.07635558053851127 Acc 0.9771588933467865 Perturbed Loss 0.0768563049286604
Epoch 9.0 val loss 0.056090306490659714 val acc 0.9796311855316162
Loss 0.07122797252610326 Acc 0.9816952955722809 Perturbed Loss 0.07178330164402723
Loss 0.072753522451967 Acc 0.9763161075115204 Perturbed Loss 0.07308765521273017
Loss 0.06651899717748165 Acc 0.9803351616859436 Perturbed Loss 0.06708719588816166
Loss 0.07664578387513757 Acc 0.9742087507247925 Perturbed Loss 0.07747701654210687
Loss 0.06575323525816203 Acc 0.9827815985679627 Perturbed Loss 0.06631801322102547
Loss 0.06706933720968664 Acc 0.9785018122196197 Perturbed Loss 0.067800196679309
Loss 0.06916290026158095 Acc 0.9774725687503815 Perturbed Loss 0.0698122250288725
Loss 0.06301237504929304 Acc 0.9822262799739838 Perturbed Loss 0.06372677040286362
Loss 0.06630939081311225 Acc 0.9779806971549988 Perturbed Loss 0.0669275813549757
Loss 0.06884917106479406 Acc 0.9767748558521271 Perturbed Loss 0.06962237488478422
Loss 0.06677226658910512 Acc 0.9787241291999816 Perturbed Loss 0.06747525077313185
Loss 0.080092194378376 Acc 0.9754430234432221 Perturbed Loss 0.08068987898528576
Loss 0.06694629421457648 Acc 0.979481817483902 Perturbed Loss 0.06743964337743819
Loss 0.06728199765086174 Acc 0.9778558158874512 Perturbed Loss 0.06785842027515172
Loss 0.06442520208656788 Acc 0.9785684049129486 Perturbed Loss 0.06486266732215881
Epoch 10.0 val loss 0.05758293718099594 val acc 0.979655921459198
Loss 0.06647112067788839 Acc 0.9798724210262298 Perturbed Loss 0.06700915987603366
Loss 0.06857545839622617 Acc 0.9810896742343903 Perturbed Loss 0.06899944998323917
Loss 0.06635670321062208 Acc 0.9800102293491364 Perturbed Loss 0.06670536318793893
Loss 0.06085279757156968 Acc 0.9789943814277648 Perturbed Loss 0.061377540975809095
Loss 0.06987378502264618 Acc 0.9779637777805328 Perturbed Loss 0.07041066356003284
Loss 0.060880943834781646 Acc 0.9782993459701538 Perturbed Loss 0.06132186904549599
Loss 0.07324398022145033 Acc 0.9790862560272217 Perturbed Loss 0.07386623250320554
Loss 0.07823799259960651 Acc 0.9774123704433442 Perturbed Loss 0.07884401112794875
Loss 0.062410411052405836 Acc 0.9795883405208587 Perturbed Loss 0.06305065663531423
Loss 0.06648736950010062 Acc 0.981132628917694 Perturbed Loss 0.06694835968315602
Loss 0.06837636638432741 Acc 0.976265766620636 Perturbed Loss 0.06888650137931109
Loss 0.06934382233768702 Acc 0.9801523327827454 Perturbed Loss 0.06982556983828545
Loss 0.08063455585390329 Acc 0.9770269453525543 Perturbed Loss 0.08127994753420353
Loss 0.06507290547713637 Acc 0.9812497103214264 Perturbed Loss 0.06551540995016694
Loss 0.06418662374839186 Acc 0.9799198436737061 Perturbed Loss 0.06460421333089471
Epoch 11.0 val loss 0.05592012032866478 val acc 0.9793116450309753
Loss 0.0771738599985838 Acc 0.9790762257575989 Perturbed Loss 0.0775621286779642
Loss 0.07451115809381008 Acc 0.9764264869689941 Perturbed Loss 0.075172467418015
Loss 0.0718565483391285 Acc 0.9815039873123169 Perturbed Loss 0.07244536072015763
Loss 0.06355230439454317 Acc 0.9796279454231263 Perturbed Loss 0.06411713667213917
Loss 0.06454903056845068 Acc 0.9838736224174499 Perturbed Loss 0.06497429305687547
Loss 0.06329169902950525 Acc 0.9793682062625885 Perturbed Loss 0.06430672843009233
Loss 0.06901528039947152 Acc 0.979289538860321 Perturbed Loss 0.06947666956111789
Loss 0.06522361086681486 Acc 0.9796448945999146 Perturbed Loss 0.06567190896719693
Loss 0.06420905090868473 Acc 0.9778132104873657 Perturbed Loss 0.0646673332899809
Loss 0.06285199293866754 Acc 0.9814285814762116 Perturbed Loss 0.06360250890254975
Loss 0.07326815458014607 Acc 0.9764467978477478 Perturbed Loss 0.07387239696457983
Loss 0.06291492106392979 Acc 0.9769409501552582 Perturbed Loss 0.06328706813976169
Loss 0.08021420775912702 Acc 0.9803597807884217 Perturbed Loss 0.0809689811989665
Loss 0.06584546882659197 Acc 0.9799669551849365 Perturbed Loss 0.06635316502302885
Loss 0.07092392642050982 Acc 0.9742757403850555 Perturbed Loss 0.07154756728559733
Epoch 12.0 val loss 0.05600036680698395 val acc 0.9795877933502197
Loss 0.06791036069393158 Acc 0.9774190938472748 Perturbed Loss 0.06837571673095226
Loss 0.07849021904170513 Acc 0.9773067486286163 Perturbed Loss 0.07903222806751728
Loss 0.07531999316066504 Acc 0.9780507445335388 Perturbed Loss 0.07588419988751412
Loss 0.06739163041114807 Acc 0.9821514785289764 Perturbed Loss 0.06785913195461035
Loss 0.06658739611506462 Acc 0.9796593666076661 Perturbed Loss 0.06698555329814554
Loss 0.06768583822995425 Acc 0.9815395486354828 Perturbed Loss 0.0680137948319316
Loss 0.072804738804698 Acc 0.9749360179901123 Perturbed Loss 0.07323316097259522
Loss 0.0692168548796326 Acc 0.9781373882293701 Perturbed Loss 0.06972416676580906
Loss 0.07212151039391757 Acc 0.9783474481105805 Perturbed Loss 0.0725794498808682
Loss 0.06706113714724779 Acc 0.9799053525924682 Perturbed Loss 0.06752728816121817
Loss 0.07240405682474375 Acc 0.9781625926494598 Perturbed Loss 0.07280634708702564
Loss 0.07016097940504551 Acc 0.9808177471160888 Perturbed Loss 0.07071896519511939
Loss 0.06053949126973748 Acc 0.978636702299118 Perturbed Loss 0.061079767849296335
Loss 0.058598134871572255 Acc 0.980706889629364 Perturbed Loss 0.05906656404957175
Loss 0.06801633149385453 Acc 0.9818957042694092 Perturbed Loss 0.06862882025539875
Epoch 13.0 val loss 0.05649930611252785 val acc 0.9798089265823364
Loss 0.06336140593513846 Acc 0.9796002900600433 Perturbed Loss 0.06371198661625385
Loss 0.07507333729416132 Acc 0.9765172493457794 Perturbed Loss 0.07551100740209221
Loss 0.0681240750849247 Acc 0.9801010644435882 Perturbed Loss 0.06843835856765508
Loss 0.07228387782350182 Acc 0.9771018064022065 Perturbed Loss 0.07288733277469873
Loss 0.06844104088842869 Acc 0.9786213195323944 Perturbed Loss 0.0688325409963727
Loss 0.058750653881579636 Acc 0.9812709832191467 Perturbed Loss 0.05917667131870985
Loss 0.06241800088435411 Acc 0.9816096675395966 Perturbed Loss 0.06337808199226856
Loss 0.05914182540029287 Acc 0.9805330383777618 Perturbed Loss 0.05960011351853609
Loss 0.06528752963989973 Acc 0.9808194506168365 Perturbed Loss 0.06595529565587639
Loss 0.06522473484277726 Acc 0.9753858160972595 Perturbed Loss 0.06599929615855217
Loss 0.07319868482649326 Acc 0.9790702855587006 Perturbed Loss 0.07378247525542975
Loss 0.06847630452364684 Acc 0.9758979785442352 Perturbed Loss 0.06895520567893981
Loss 0.0692785613425076 Acc 0.9796753847599029 Perturbed Loss 0.06972988367080689
Loss 0.07347698954865337 Acc 0.9745512878894806 Perturbed Loss 0.07402933677658438
Loss 0.06484158949926495 Acc 0.9800535750389099 Perturbed Loss 0.06521222712472081
Epoch 14.0 val loss 0.054744984954595566 val acc 0.9799239635467529
Loss 0.06985720040276647 Acc 0.9753042137622834 Perturbed Loss 0.07027654269710183
Loss 0.06743847738951445 Acc 0.9796675217151641 Perturbed Loss 0.06788515463471413
Loss 0.07556843049824238 Acc 0.9737540936470032 Perturbed Loss 0.0761926157027483
Loss 0.06919962817803026 Acc 0.9791443598270416 Perturbed Loss 0.06977459922432899
Loss 0.05665108630433679 Acc 0.9814551115036011 Perturbed Loss 0.057062762156128884
Loss 0.05968197077512741 Acc 0.9811117577552796 Perturbed Loss 0.060089270561002196
Loss 0.06617432904429733 Acc 0.9805037772655487 Perturbed Loss 0.06667934442870319
Loss 0.08344636870548129 Acc 0.9786372995376587 Perturbed Loss 0.08408559070900083
Loss 0.07265105213969945 Acc 0.9799353075027466 Perturbed Loss 0.07326388031244278
Loss 0.070643554572016 Acc 0.9802294683456421 Perturbed Loss 0.07113279275596142
Loss 0.06416091052815318 Acc 0.9835929584503174 Perturbed Loss 0.06451044136658311
Loss 0.06980834346264601 Acc 0.9778914737701416 Perturbed Loss 0.07016840808093548
Loss 0.06270593389868737 Acc 0.9815967202186584 Perturbed Loss 0.06321147628128529
Loss 0.06352390374988318 Acc 0.9816566956043243 Perturbed Loss 0.06394786432385445
Loss 0.07417278222739697 Acc 0.9780799293518067 Perturbed Loss 0.07473881602287293
Epoch 15.0 val loss 0.05552653968334198 val acc 0.9797713756561279
Loss 0.06666350215673447 Acc 0.9778863036632538 Perturbed Loss 0.06706974025815725
Loss 0.06740780506283045 Acc 0.9775657939910889 Perturbed Loss 0.06775791328400374
Loss 0.07135230652987958 Acc 0.9802690267562866 Perturbed Loss 0.07179578958079219
Loss 0.06222934152930975 Acc 0.9805665647983551 Perturbed Loss 0.06257285699248313
Loss 0.061323740836232904 Acc 0.9804047811031341 Perturbed Loss 0.06173206290230155
Loss 0.07023422507569194 Acc 0.9813170886039734 Perturbed Loss 0.07064044015482068
Loss 0.07269350949674845 Acc 0.9801869189739227 Perturbed Loss 0.07320087362080813
Loss 0.07523811835795641 Acc 0.9774468553066253 Perturbed Loss 0.07580226961523294
Loss 0.06359650621190667 Acc 0.9802161037921906 Perturbed Loss 0.0641448537632823
Loss 0.055353102404624224 Acc 0.9839772975444794 Perturbed Loss 0.055663483683019876
Loss 0.06581336367875337 Acc 0.9786038839817047 Perturbed Loss 0.06623872723430395
Loss 0.06348471417091787 Acc 0.9813077664375305 Perturbed Loss 0.06392930516041816
Loss 0.06034334845840931 Acc 0.9804043459892273 Perturbed Loss 0.0609046751819551
Loss 0.06580711347982288 Acc 0.9814735758304596 Perturbed Loss 0.06624712925404311
Loss 0.05865740433335304 Acc 0.9837822186946868 Perturbed Loss 0.058995108976960184
Epoch 16.0 val loss 0.05488203838467598 val acc 0.9799293875694275
Loss 0.06871596662327648 Acc 0.9801927423477172 Perturbed Loss 0.06914839912205935
Loss 0.07168630372732877 Acc 0.9822558534145355 Perturbed Loss 0.07218745023012162
Loss 0.06039464507251978 Acc 0.9797607100009919 Perturbed Loss 0.060881881453096864
Loss 0.07061013013124466 Acc 0.9791701090335846 Perturbed Loss 0.07106594171375036
Loss 0.06164350422099232 Acc 0.9810071408748626 Perturbed Loss 0.0620789080299437
Loss 0.059828775972127914 Acc 0.9800991189479827 Perturbed Loss 0.06035967916250229
Loss 0.06846150610595941 Acc 0.9767509996891022 Perturbed Loss 0.06917074974626303
Loss 0.06433167662471533 Acc 0.9811461126804352 Perturbed Loss 0.06469282127916813
Loss 0.05309207610785961 Acc 0.9831035876274109 Perturbed Loss 0.05345559697598219
Loss 0.07809672955423594 Acc 0.9775509345531463 Perturbed Loss 0.07856646284461022
Loss 0.06309388531371951 Acc 0.9796465802192688 Perturbed Loss 0.06342298975214362
Loss 0.06799978360533715 Acc 0.9793044698238372 Perturbed Loss 0.06845661196857691
Loss 0.06500703804194927 Acc 0.9748695766925812 Perturbed Loss 0.06543849308043719
Loss 0.0644353468157351 Acc 0.978841918706894 Perturbed Loss 0.06491271153092384
Loss 0.06415554540231824 Acc 0.9830523979663849 Perturbed Loss 0.06456913998350501
Epoch 17.0 val loss 0.055323030799627304 val acc 0.9803040027618408
Loss 0.06666871102526783 Acc 0.9800414597988129 Perturbed Loss 0.06718320930376649
Loss 0.06667757980525493 Acc 0.98042520403862 Perturbed Loss 0.06715610183775425
Loss 0.06443138673901558 Acc 0.9778240132331848 Perturbed Loss 0.0648065159842372
Loss 0.06397596899420023 Acc 0.9819845509529114 Perturbed Loss 0.06442290350794792
Loss 0.06370816990733147 Acc 0.9811112570762635 Perturbed Loss 0.064165627816692
Loss 0.05240517023950815 Acc 0.9822483289241791 Perturbed Loss 0.05277863698080182
Loss 0.05945211503654718 Acc 0.9786407053470612 Perturbed Loss 0.05999649353325367
Loss 0.05975458042696118 Acc 0.9811228489875794 Perturbed Loss 0.06027053358033299
Loss 0.06489269772544504 Acc 0.9801808285713196 Perturbed Loss 0.06521097760647536
Loss 0.06407497566193342 Acc 0.9797001588344574 Perturbed Loss 0.06449584901332855
Loss 0.06060489177703857 Acc 0.9791477370262146 Perturbed Loss 0.060992234610021116
Loss 0.07550706148147583 Acc 0.9752495205402374 Perturbed Loss 0.07595111437141895
Loss 0.06133165664970875 Acc 0.9794973433017731 Perturbed Loss 0.0618735701777041
Loss 0.07729175582528114 Acc 0.9788148105144501 Perturbed Loss 0.07777788273990155
Loss 0.06020605804398656 Acc 0.9782642054557801 Perturbed Loss 0.06053101748228073
Epoch 18.0 val loss 0.05431594327092171 val acc 0.9803427457809448
Loss 0.06652139216661453 Acc 0.976872810125351 Perturbed Loss 0.06688173566013575
Loss 0.07070365097373724 Acc 0.9790421056747437 Perturbed Loss 0.07128278989344836
Loss 0.06775766566395759 Acc 0.9792650818824769 Perturbed Loss 0.06808301370590925
Loss 0.05407882932573557 Acc 0.9795618236064911 Perturbed Loss 0.05441520858556032
Loss 0.06093552650883794 Acc 0.9822866213321686 Perturbed Loss 0.061281644608825445
Loss 0.06276081988587975 Acc 0.9782610738277435 Perturbed Loss 0.06333035914227367
Loss 0.08243188945576549 Acc 0.9759756910800934 Perturbed Loss 0.08302690092474223
Loss 0.06345823634415865 Acc 0.9799403619766235 Perturbed Loss 0.06384345728904009
Loss 0.06080786013975739 Acc 0.9810078108310699 Perturbed Loss 0.06120324678719044
Loss 0.06110927067697048 Acc 0.9799356591701508 Perturbed Loss 0.061472164392471315
Loss 0.06796746786683798 Acc 0.9792347204685211 Perturbed Loss 0.06834700606763362
Loss 0.060373535566031936 Acc 0.9787171387672424 Perturbed Loss 0.060842748433351516
Loss 0.06506094239652156 Acc 0.9799018764495849 Perturbed Loss 0.0654312739521265
Loss 0.07708821259438992 Acc 0.9797190773487091 Perturbed Loss 0.0775756399333477
Loss 0.059559165053069595 Acc 0.98285440325737 Perturbed Loss 0.060057257805019616
Epoch 19.0 val loss 0.05479879304766655 val acc 0.9801489114761353
[01:21:53] INFO     `Trainer.fit` stopped: `max_epochs=20` reached.                                                                                                                         rank_zero.py:53
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750/750 0:03:45 • 0:00:00 3.36it/s train/loss: 0.06 val_loss: 0.055
[01:21:56] INFO     Created a temporary directory at /tmp/tmpeo5xq0wm                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmpeo5xq0wm/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
           INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
           INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
           INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
           INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
[01:21:57] INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.0006, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.001, adaptive=True)
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.08821440797299146 Acc 0.9656280720233917 Perturbed Loss 0.088518206179142
[01:22:28] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.07757793478667736 Acc 0.9713643634319306 Perturbed Loss 0.07775268141180276
Loss 0.08707897884771228 Acc 0.9769311571121215 Perturbed Loss 0.08732387462630868
Loss 0.08463501153513789 Acc 0.9734117007255554 Perturbed Loss 0.0848606370203197
Loss 0.08556115660816431 Acc 0.9743680477142334 Perturbed Loss 0.08578024491667748
Loss 0.09731745693832636 Acc 0.9642984092235565 Perturbed Loss 0.0975411169975996
Loss 0.08230053007602692 Acc 0.9703337001800537 Perturbed Loss 0.0825347138941288
Loss 0.08668578006327152 Acc 0.9754251527786255 Perturbed Loss 0.08687038782984019
Loss 0.08535845953971148 Acc 0.9743041312694549 Perturbed Loss 0.08548675708472729
Loss 0.08412301080301404 Acc 0.9709861421585083 Perturbed Loss 0.0842901660874486
Loss 0.0757696421071887 Acc 0.9773088848590851 Perturbed Loss 0.0759246876090765
Loss 0.08575467232614756 Acc 0.9773443698883056 Perturbed Loss 0.0859656074643135
Loss 0.08157338095828891 Acc 0.9772560036182404 Perturbed Loss 0.08171657014638185
Loss 0.0667755550518632 Acc 0.9826708543300628 Perturbed Loss 0.06688065819442272
Loss 0.08469824109226465 Acc 0.975000171661377 Perturbed Loss 0.08485386496409773
Epoch 0.0 val loss 0.0566934309899807 val acc 0.9791523814201355
Loss 0.08222215533256531 Acc 0.9740104901790619 Perturbed Loss 0.0823799878358841
Loss 0.07651952899992466 Acc 0.9737564718723297 Perturbed Loss 0.07666867284104228
Loss 0.08246067769825459 Acc 0.9682201993465424 Perturbed Loss 0.08263144757598638
Loss 0.08198440108448267 Acc 0.9735149025917054 Perturbed Loss 0.08217911586165429
Loss 0.08655581934377551 Acc 0.9752786374092102 Perturbed Loss 0.08669081021100283
Loss 0.07574409218505025 Acc 0.9767989325523376 Perturbed Loss 0.07586425242945552
Loss 0.08619749058037997 Acc 0.9745272839069367 Perturbed Loss 0.08638170711696148
Loss 0.07597893632948399 Acc 0.9767603194713592 Perturbed Loss 0.07602593034505845
Loss 0.07760422259569168 Acc 0.9764623415470123 Perturbed Loss 0.07779121048748493
Loss 0.08022918067872524 Acc 0.9754460346698761 Perturbed Loss 0.08043986966833472
Loss 0.08052070504054427 Acc 0.968219096660614 Perturbed Loss 0.08067902360111474
Loss 0.09342556905001402 Acc 0.9704095196723937 Perturbed Loss 0.09361676786094904
Loss 0.08188486747443675 Acc 0.9767888772487641 Perturbed Loss 0.08204613290727139
Loss 0.09460507933050394 Acc 0.9722082114219666 Perturbed Loss 0.09474969513714314
Loss 0.07597900755703449 Acc 0.9761132764816284 Perturbed Loss 0.07613871064037085
Epoch 1.0 val loss 0.05726821348071098 val acc 0.9791520833969116
Loss 0.07137939231470228 Acc 0.975002611875534 Perturbed Loss 0.07148619325831533
Loss 0.08494960691779851 Acc 0.9784691274166107 Perturbed Loss 0.08507616769522429
Loss 0.08042806908488273 Acc 0.9739765298366546 Perturbed Loss 0.08069541253149509
Loss 0.07951811574399471 Acc 0.9773543000221252 Perturbed Loss 0.07967283524572849
Loss 0.08027364794164896 Acc 0.9785830402374267 Perturbed Loss 0.0804477621614933
Loss 0.074216343536973 Acc 0.9764030361175537 Perturbed Loss 0.07435031168162823
Loss 0.08419492587447167 Acc 0.9775915908813476 Perturbed Loss 0.08435789624229073
Loss 0.08272425621747971 Acc 0.9809190559387208 Perturbed Loss 0.08289981130510568
Loss 0.0856881795823574 Acc 0.9744005680084229 Perturbed Loss 0.08589742738753557
Loss 0.08119397858157754 Acc 0.9775433075428009 Perturbed Loss 0.08136693032458425
Loss 0.0795774007961154 Acc 0.9776362526416779 Perturbed Loss 0.0797706875950098
Loss 0.08547370869666338 Acc 0.9741246461868286 Perturbed Loss 0.08564448032528162
Loss 0.08501419201493263 Acc 0.970122377872467 Perturbed Loss 0.08515115093439818
Loss 0.09769464794546366 Acc 0.9666351127624512 Perturbed Loss 0.09786101162433625
Loss 0.08445333682000637 Acc 0.9766963720321655 Perturbed Loss 0.08460434213280678
Epoch 2.0 val loss 0.058087147772312164 val acc 0.9788442850112915
Loss 0.0764598961174488 Acc 0.9764333570003509 Perturbed Loss 0.07656967461109161
Loss 0.06786463793367148 Acc 0.979383784532547 Perturbed Loss 0.0679566828161478
Loss 0.0699596693739295 Acc 0.9800443959236145 Perturbed Loss 0.07007893674075603
Loss 0.07908050693571568 Acc 0.9794814205169677 Perturbed Loss 0.07921290818601846
Loss 0.08558161877095699 Acc 0.9772904539108276 Perturbed Loss 0.08577666688710452
Loss 0.0827295508608222 Acc 0.9753876543045044 Perturbed Loss 0.08287158478051423
Loss 0.07026101786643267 Acc 0.981527099609375 Perturbed Loss 0.07041340060532093
Loss 0.0802625011280179 Acc 0.9769893503189087 Perturbed Loss 0.08033304233103991
Loss 0.08698228918015957 Acc 0.9780036985874176 Perturbed Loss 0.08716900624334813
Loss 0.08010070623829961 Acc 0.9759811985492707 Perturbed Loss 0.08021562634035945
Loss 0.0695748271048069 Acc 0.9776867306232453 Perturbed Loss 0.06970710145309568
Loss 0.08644624654203653 Acc 0.9728372824192048 Perturbed Loss 0.08655813947319985
Loss 0.08641404569149018 Acc 0.9756790637969971 Perturbed Loss 0.0865609795972705
Loss 0.07820290256291627 Acc 0.9714901769161224 Perturbed Loss 0.078351894877851
Loss 0.08062412563711405 Acc 0.9771793925762177 Perturbed Loss 0.08071290154010058
Epoch 3.0 val loss 0.05788607895374298 val acc 0.9787420630455017
Loss 0.06403980297967792 Acc 0.9814650440216064 Perturbed Loss 0.06413338005542756
Loss 0.07574220009148121 Acc 0.9814287042617797 Perturbed Loss 0.0759196200966835
Loss 0.06721578216180206 Acc 0.9746155726909638 Perturbed Loss 0.06730168906971812
Loss 0.08959175255149603 Acc 0.9777831077575684 Perturbed Loss 0.08975165426731109
Loss 0.07608371274545789 Acc 0.9772348678112031 Perturbed Loss 0.07619440836831927
Loss 0.07517590314149857 Acc 0.9784413421154022 Perturbed Loss 0.07531841438263655
Loss 0.07322243843227624 Acc 0.9776842141151428 Perturbed Loss 0.07338324509561062
Loss 0.07308530226349831 Acc 0.977374610900879 Perturbed Loss 0.07316023491322994
Loss 0.07395899770781397 Acc 0.9758491277694702 Perturbed Loss 0.07406840307638049
Loss 0.06525020826607943 Acc 0.978665999174118 Perturbed Loss 0.06539950862526894
Loss 0.08068759948015213 Acc 0.9796009683609008 Perturbed Loss 0.08087437886744737
Loss 0.08421328721567989 Acc 0.9742337131500244 Perturbed Loss 0.08439199347048998
Loss 0.0785051359795034 Acc 0.9757903301715851 Perturbed Loss 0.07863470925018191
Loss 0.0789575045183301 Acc 0.9793840777873993 Perturbed Loss 0.07911228105425834
Loss 0.07649124126881361 Acc 0.9794691181182862 Perturbed Loss 0.07663662312552333
Epoch 4.0 val loss 0.05976323038339615 val acc 0.9788673520088196
Loss 0.07412797760218381 Acc 0.9771361494064331 Perturbed Loss 0.07424776569008827
Loss 0.0842767871543765 Acc 0.9785070550441742 Perturbed Loss 0.08441576633602381
Loss 0.08355582796037198 Acc 0.9765680193901062 Perturbed Loss 0.08371575344353914
Loss 0.08631756171584129 Acc 0.9723195111751557 Perturbed Loss 0.08646960642188788
Loss 0.07100016348063946 Acc 0.9784466600418091 Perturbed Loss 0.07114105958491564
Loss 0.08463591437786817 Acc 0.9737044191360473 Perturbed Loss 0.08476256154477596
Loss 0.06876384902745486 Acc 0.9801507425308228 Perturbed Loss 0.06885130409151316
Loss 0.06712760679423808 Acc 0.9777190697193145 Perturbed Loss 0.06714348550885915
Loss 0.08350483782589435 Acc 0.9769948995113373 Perturbed Loss 0.08369589425623417
Loss 0.07738118641078472 Acc 0.9766304063796997 Perturbed Loss 0.07752379942685365
Loss 0.0779641592502594 Acc 0.9771811997890473 Perturbed Loss 0.07809777919203043
Loss 0.08523132279515266 Acc 0.9741790866851807 Perturbed Loss 0.08542602255940437
Loss 0.08332641370594501 Acc 0.9783698272705078 Perturbed Loss 0.0834408426657319
Loss 0.08111590962857008 Acc 0.9777843916416168 Perturbed Loss 0.08122703399509192
Loss 0.07163219718262553 Acc 0.9768327093124389 Perturbed Loss 0.07175152689218521
Epoch 5.0 val loss 0.05860219523310661 val acc 0.978786051273346
Loss 0.07238506088033318 Acc 0.9781869184970856 Perturbed Loss 0.07249147474765777
Loss 0.07540154682472348 Acc 0.9786436283588409 Perturbed Loss 0.07551677912473678
Loss 0.07020332254469394 Acc 0.9788469851016999 Perturbed Loss 0.0703593162074685
Loss 0.08673550616949796 Acc 0.9754673552513122 Perturbed Loss 0.08686389077454805
Loss 0.07500636782497168 Acc 0.981272987127304 Perturbed Loss 0.0751115370169282
Loss 0.0801247520558536 Acc 0.9767453479766846 Perturbed Loss 0.08025025269016624
Loss 0.07564511295408011 Acc 0.9751845836639405 Perturbed Loss 0.075740365087986
Loss 0.07369366463273763 Acc 0.9813952040672302 Perturbed Loss 0.07380585461854934
Loss 0.07135208286345004 Acc 0.9787355363368988 Perturbed Loss 0.0714537388831377
Loss 0.08264616094529628 Acc 0.9766517984867096 Perturbed Loss 0.08276898052543402
Loss 0.0783967051282525 Acc 0.9769581866264343 Perturbed Loss 0.07854098593816161
Loss 0.07452726861461997 Acc 0.9784852409362793 Perturbed Loss 0.0746652564406395
Loss 0.07572286789305509 Acc 0.976663783788681 Perturbed Loss 0.07585095237009228
Loss 0.07810266725718976 Acc 0.9812991738319397 Perturbed Loss 0.07824279833585024
Loss 0.07920166984200477 Acc 0.9742043817043304 Perturbed Loss 0.07931965462863445
Epoch 6.0 val loss 0.05922926217317581 val acc 0.9792712926864624
Loss 0.080466666277498 Acc 0.9753350806236267 Perturbed Loss 0.08057363508269191
Loss 0.08161013804376126 Acc 0.9770911955833435 Perturbed Loss 0.08176787966862321
Loss 0.07395368795841932 Acc 0.9774834501743317 Perturbed Loss 0.0740819476172328
Loss 0.0663560289144516 Acc 0.9812772560119629 Perturbed Loss 0.06649213038384914
Loss 0.07318866107612848 Acc 0.9768249070644379 Perturbed Loss 0.07331328604370356
Loss 0.07719901233911514 Acc 0.977538959980011 Perturbed Loss 0.07726226642727851
Loss 0.07625983845442534 Acc 0.9753977346420288 Perturbed Loss 0.0763940168172121
Loss 0.0641898006387055 Acc 0.9802183151245117 Perturbed Loss 0.06427652150392532
Loss 0.07644576750695706 Acc 0.9776814568042755 Perturbed Loss 0.07654578439891338
Loss 0.07782319147139788 Acc 0.9789522886276245 Perturbed Loss 0.07793839599937201
Loss 0.07822879757732153 Acc 0.9804373860359192 Perturbed Loss 0.07841542460024357
Loss 0.06907799571752549 Acc 0.9793738496303558 Perturbed Loss 0.06917930191382765
Loss 0.07050292544066906 Acc 0.978048425912857 Perturbed Loss 0.07061999097466469
Loss 0.06955389384180308 Acc 0.9816884899139404 Perturbed Loss 0.06964245650917292
Loss 0.07835195336490869 Acc 0.9778595972061157 Perturbed Loss 0.07848174527287483
Epoch 7.0 val loss 0.05849631875753403 val acc 0.9789384603500366
Loss 0.06634710479527711 Acc 0.9778038609027863 Perturbed Loss 0.0664256763085723
Loss 0.06914197177626193 Acc 0.9734609723091125 Perturbed Loss 0.06922900127246975
Loss 0.06869888339191675 Acc 0.9778139328956604 Perturbed Loss 0.06884986706078053
Loss 0.07585119672119617 Acc 0.9760755801200867 Perturbed Loss 0.07594830267131329
Loss 0.06579465495422482 Acc 0.9785934042930603 Perturbed Loss 0.06589449383318424
Loss 0.07272406809031963 Acc 0.9779754424095154 Perturbed Loss 0.07285661693662406
Loss 0.06323886562138796 Acc 0.9784258711338043 Perturbed Loss 0.06332696225494146
Loss 0.06870247159153223 Acc 0.978083209991455 Perturbed Loss 0.0688217991963029
Loss 0.07430947702378035 Acc 0.974774614572525 Perturbed Loss 0.07443332772701979
Loss 0.06417863795533776 Acc 0.9768267250061036 Perturbed Loss 0.06426261430606246
Loss 0.0754560235887766 Acc 0.978430279493332 Perturbed Loss 0.07564061168581247
Loss 0.07611555924639106 Acc 0.9778424513339996 Perturbed Loss 0.0762770875915885
Loss 0.06998035162687302 Acc 0.9780961287021637 Perturbed Loss 0.0701310170814395
Loss 0.07826073149219155 Acc 0.9760799431800842 Perturbed Loss 0.07839976189658046
Loss 0.07497479129582643 Acc 0.9814300787448883 Perturbed Loss 0.07505526609718799
Epoch 8.0 val loss 0.056984055787324905 val acc 0.9794347286224365
Loss 0.07163535870611668 Acc 0.9756161665916443 Perturbed Loss 0.07173964612185955
Loss 0.06914675643667578 Acc 0.9788761782646179 Perturbed Loss 0.06926767999306321
Loss 0.07562241673469544 Acc 0.9767979717254639 Perturbed Loss 0.07573981139808893
Loss 0.06043924126774072 Acc 0.9777567660808564 Perturbed Loss 0.06053933829069138
Loss 0.07154726140201091 Acc 0.9774455738067627 Perturbed Loss 0.07165727436542511
Loss 0.0679417771846056 Acc 0.9767320024967193 Perturbed Loss 0.06800829455256462
Loss 0.06103044142946601 Acc 0.9814730572700501 Perturbed Loss 0.061103843580931426
Loss 0.07717052683234214 Acc 0.9804569137096405 Perturbed Loss 0.07723508358001709
Loss 0.06472962655127049 Acc 0.9797191274166107 Perturbed Loss 0.06486720860004425
Loss 0.06647332459688186 Acc 0.9819412231445312 Perturbed Loss 0.066574243940413
Loss 0.07052704036235809 Acc 0.9801308608055115 Perturbed Loss 0.07062742076814174
Loss 0.06923884501680731 Acc 0.9780889678001404 Perturbed Loss 0.0693177573941648
Loss 0.0715452479943633 Acc 0.9781817078590394 Perturbed Loss 0.07166416056454182
Loss 0.08339252892881632 Acc 0.9772140443325043 Perturbed Loss 0.08358364479616284
Loss 0.07578105352818966 Acc 0.9759442150592804 Perturbed Loss 0.075890740044415
Epoch 9.0 val loss 0.056296154856681824 val acc 0.9793717861175537
Loss 0.07307511450722813 Acc 0.9825657188892365 Perturbed Loss 0.07320908280089497
Loss 0.07295185461640358 Acc 0.9767713391780853 Perturbed Loss 0.07306390091776847
Loss 0.0663558823429048 Acc 0.980462681055069 Perturbed Loss 0.0664536776766181
Loss 0.0784113759174943 Acc 0.9740837323665619 Perturbed Loss 0.078508485481143
Loss 0.06358727676793934 Acc 0.9825655961036682 Perturbed Loss 0.06368169160559774
Loss 0.06454210748896003 Acc 0.9791393744945526 Perturbed Loss 0.06464331432245672
Loss 0.06631226904690266 Acc 0.9779535067081452 Perturbed Loss 0.06640741862356662
Loss 0.06504155267961323 Acc 0.9826332461833954 Perturbed Loss 0.06515261703170835
Loss 0.06532872375100851 Acc 0.9754999887943268 Perturbed Loss 0.06545244161039591
Loss 0.06988638333976269 Acc 0.9732031059265137 Perturbed Loss 0.07008857119828463
Loss 0.06605144422501326 Acc 0.9777662086486817 Perturbed Loss 0.06617832530289888
Loss 0.07506609138101339 Acc 0.9754854249954223 Perturbed Loss 0.07517745234072208
Loss 0.06504850731231272 Acc 0.9795097649097443 Perturbed Loss 0.06515580015257001
Loss 0.06872892580926418 Acc 0.9771023952960968 Perturbed Loss 0.06887081380933523
Loss 0.06461612720042467 Acc 0.9773412156105041 Perturbed Loss 0.06473779570311308
Epoch 10.0 val loss 0.05727825313806534 val acc 0.9794102907180786
Loss 0.06945254530757666 Acc 0.9788892304897309 Perturbed Loss 0.06956547094509005
Loss 0.06958692179992795 Acc 0.9813157629966736 Perturbed Loss 0.06968223091214895
Loss 0.0668969203904271 Acc 0.9800510394573212 Perturbed Loss 0.06697241820394993
Loss 0.06122087720781565 Acc 0.9788022744655609 Perturbed Loss 0.06130230061709881
Loss 0.06846153987571597 Acc 0.9782864892482758 Perturbed Loss 0.06857808358967304
Loss 0.0631213802844286 Acc 0.9784598696231842 Perturbed Loss 0.06323163155466319
Loss 0.06988357003778219 Acc 0.9790260922908783 Perturbed Loss 0.06996553415432573
Loss 0.07540639273822308 Acc 0.9782437574863434 Perturbed Loss 0.07549880709499121
Loss 0.05922872439026833 Acc 0.9795728230476379 Perturbed Loss 0.059358033686876296
Loss 0.06271044678986072 Acc 0.9810179746150971 Perturbed Loss 0.0627903875336051
Loss 0.06955863732844592 Acc 0.9779865801334381 Perturbed Loss 0.06965805303305388
Loss 0.06991396550089121 Acc 0.979982978105545 Perturbed Loss 0.07002575691789388
Loss 0.07744922418147325 Acc 0.9767392468452454 Perturbed Loss 0.0775796865671873
Loss 0.0664701241068542 Acc 0.981169902086258 Perturbed Loss 0.06661642076447606
Loss 0.06463843438774347 Acc 0.979843065738678 Perturbed Loss 0.06474325625225902
Epoch 11.0 val loss 0.05726689100265503 val acc 0.9791839718818665
Loss 0.08159812971949577 Acc 0.97842564702034 Perturbed Loss 0.0816995782032609
Loss 0.07433794029057025 Acc 0.9778358721733094 Perturbed Loss 0.07445078901946545
Loss 0.06765411455184221 Acc 0.9814763808250427 Perturbed Loss 0.06774958066642284
Loss 0.06382480598986148 Acc 0.9791200649738312 Perturbed Loss 0.06393754318356513
Loss 0.06310466390103102 Acc 0.9841760909557342 Perturbed Loss 0.06321640271693468
Loss 0.06442728903144598 Acc 0.9792923176288605 Perturbed Loss 0.06461382266134023
Loss 0.06812023101374506 Acc 0.9794940650463104 Perturbed Loss 0.06819633355364203
Loss 0.06493461003527046 Acc 0.9802921271324158 Perturbed Loss 0.06502910679206252
Loss 0.065311644859612 Acc 0.9781400239467621 Perturbed Loss 0.06537422496825457
Loss 0.06072894485667348 Acc 0.9813219165802002 Perturbed Loss 0.06080841965973377
Loss 0.07258768950589001 Acc 0.9799003493785858 Perturbed Loss 0.07270784775726497
Loss 0.06624863263219595 Acc 0.9766878688335419 Perturbed Loss 0.06636144226416946
Loss 0.07656973320059478 Acc 0.9815347492694855 Perturbed Loss 0.076668561687693
Loss 0.06564771492034197 Acc 0.980136263370514 Perturbed Loss 0.0657914649322629
Loss 0.072123999055475 Acc 0.9725543415546417 Perturbed Loss 0.07226587861776351
Epoch 12.0 val loss 0.05625440180301666 val acc 0.97945636510849
Loss 0.0703108362853527 Acc 0.9778628635406494 Perturbed Loss 0.07042327918112277
Loss 0.07821015447378159 Acc 0.976890139579773 Perturbed Loss 0.0783057799935341
Loss 0.07732875835150481 Acc 0.9779580521583557 Perturbed Loss 0.0774510332196951
Loss 0.06492037609219552 Acc 0.9821627736091614 Perturbed Loss 0.06499584034085273
Loss 0.06218585088849068 Acc 0.9795168364048004 Perturbed Loss 0.06229236330837011
Loss 0.07284109689295291 Acc 0.9810002648830414 Perturbed Loss 0.07292760096490383
Loss 0.07200889382511377 Acc 0.9757608795166015 Perturbed Loss 0.07209601737558842
Loss 0.07154396992176772 Acc 0.9771201908588409 Perturbed Loss 0.07164252806454897
Loss 0.06972102398052811 Acc 0.9787085354328156 Perturbed Loss 0.06982676450163126
Loss 0.06913483511656522 Acc 0.9790432047843933 Perturbed Loss 0.06923354296013713
Loss 0.0732945378497243 Acc 0.9778553509712219 Perturbed Loss 0.07338621661067009
Loss 0.07011443123221398 Acc 0.9804875040054322 Perturbed Loss 0.07020598888397217
Loss 0.06525701712816953 Acc 0.9780759501457215 Perturbed Loss 0.0653750966489315
Loss 0.05898067206144333 Acc 0.9813876414299011 Perturbed Loss 0.059073771983385086
Loss 0.06946272648870945 Acc 0.981904137134552 Perturbed Loss 0.06956518322229385
Epoch 13.0 val loss 0.05605052411556244 val acc 0.9796368479728699
Loss 0.06270733881741762 Acc 0.9799366664886474 Perturbed Loss 0.06276441605761647
Loss 0.07342075357213616 Acc 0.9767151951789856 Perturbed Loss 0.07355233469977975
Loss 0.06844779761508107 Acc 0.9800084280967712 Perturbed Loss 0.06853723838925362
Loss 0.07128480669111013 Acc 0.9780310225486756 Perturbed Loss 0.07139321975409985
Loss 0.06706378016620874 Acc 0.9786121046543121 Perturbed Loss 0.06714117091149091
Loss 0.058034486807882785 Acc 0.9813077318668365 Perturbed Loss 0.05811241075396538
Loss 0.06093570502474904 Acc 0.9815764176845551 Perturbed Loss 0.06103131387382746
Loss 0.05997927065938711 Acc 0.9801593351364136 Perturbed Loss 0.06007574051618576
Loss 0.06614242877811194 Acc 0.9808797419071198 Perturbed Loss 0.06623553697019816
Loss 0.06443857360631228 Acc 0.9744226539134979 Perturbed Loss 0.06463011529296636
Loss 0.07377178754657507 Acc 0.9786021327972412 Perturbed Loss 0.07387423247098923
Loss 0.06858582362532616 Acc 0.9764710414409637 Perturbed Loss 0.06868355259299279
Loss 0.07209154102951289 Acc 0.9798015332221985 Perturbed Loss 0.07222845934331418
Loss 0.07327773511409759 Acc 0.9746264493465424 Perturbed Loss 0.07337184567004443
Loss 0.06477463793009519 Acc 0.9802427411079406 Perturbed Loss 0.06484224669635295
Epoch 14.0 val loss 0.05474678426980972 val acc 0.9798685908317566
Loss 0.06840619586408138 Acc 0.976183443069458 Perturbed Loss 0.06848876448348165
Loss 0.06705563999712467 Acc 0.9795929026603699 Perturbed Loss 0.06716145128011704
Loss 0.07776660960167646 Acc 0.9745235812664031 Perturbed Loss 0.07793059347197413
Loss 0.06932953612878918 Acc 0.9793645489215851 Perturbed Loss 0.06940540686249733
Loss 0.0569342428073287 Acc 0.9811800384521484 Perturbed Loss 0.05700843010097742
Loss 0.05765185228548944 Acc 0.9816842770576477 Perturbed Loss 0.05775627451948821
Loss 0.06498341610655188 Acc 0.980729410648346 Perturbed Loss 0.06507856003008783
Loss 0.08624907745048403 Acc 0.9781680154800415 Perturbed Loss 0.08634868882596493
Loss 0.0734195152297616 Acc 0.9800723648071289 Perturbed Loss 0.07349386163055897
Loss 0.06864270862191915 Acc 0.9800421643257141 Perturbed Loss 0.06874102577567101
Loss 0.06476221555843949 Acc 0.9836721611022949 Perturbed Loss 0.06483823831193149
Loss 0.06811560861766339 Acc 0.9780988895893097 Perturbed Loss 0.06820830069482327
Loss 0.0625725980475545 Acc 0.9813299584388733 Perturbed Loss 0.06265840005129576
Loss 0.06530375808477401 Acc 0.9814543223381043 Perturbed Loss 0.06539704468101264
Loss 0.07826360885053874 Acc 0.9782115912437439 Perturbed Loss 0.07839757245033979
Epoch 15.0 val loss 0.05519420653581619 val acc 0.9795500636100769
Loss 0.06821534980088473 Acc 0.9777071452140809 Perturbed Loss 0.06833449699915946
Loss 0.06988563060760498 Acc 0.9768856048583985 Perturbed Loss 0.0699808919802308
Loss 0.07061728149652481 Acc 0.9803695297241211 Perturbed Loss 0.07070906026288867
Loss 0.0612006576731801 Acc 0.9806742179393768 Perturbed Loss 0.06131191678345203
Loss 0.062121836878359316 Acc 0.9803170311450958 Perturbed Loss 0.06219746321439743
Loss 0.07089688481763005 Acc 0.9801127350330353 Perturbed Loss 0.07099123816937208
Loss 0.07270440768450498 Acc 0.9807104361057282 Perturbed Loss 0.0728060682490468
Loss 0.07271730490028858 Acc 0.9793808853626251 Perturbed Loss 0.07279754303395748
Loss 0.06164348002523184 Acc 0.9801582109928131 Perturbed Loss 0.061733856685459616
Loss 0.05608948139473796 Acc 0.9843919742107391 Perturbed Loss 0.05616243878379464
Loss 0.06655690308660268 Acc 0.9794805884361267 Perturbed Loss 0.06664684921503067
Loss 0.06477010305970907 Acc 0.9810455846786499 Perturbed Loss 0.06485047955065966
Loss 0.06219598619267344 Acc 0.9804301822185516 Perturbed Loss 0.06226465677842498
Loss 0.06687707703560591 Acc 0.9799605667591095 Perturbed Loss 0.06696580696851015
Loss 0.057765811048448086 Acc 0.983924046754837 Perturbed Loss 0.05788005374372005
Epoch 16.0 val loss 0.05518614500761032 val acc 0.979857325553894
Loss 0.06858492117375135 Acc 0.9800452899932861 Perturbed Loss 0.06868762046098709
Loss 0.07125418789684773 Acc 0.9820815527439117 Perturbed Loss 0.07133120317012072
Loss 0.060130276270210746 Acc 0.9798439288139343 Perturbed Loss 0.06021551415324211
Loss 0.0673394974693656 Acc 0.9794788825511932 Perturbed Loss 0.06741166550666094
Loss 0.06180955776944756 Acc 0.9811449313163757 Perturbed Loss 0.06189185608178377
Loss 0.06182560816407204 Acc 0.9802562832832337 Perturbed Loss 0.06191419214010239
Loss 0.06816339882090688 Acc 0.9766222631931305 Perturbed Loss 0.06826425142586232
Loss 0.06543982796370983 Acc 0.9815210592746735 Perturbed Loss 0.06552062157541513
Loss 0.055202818773686886 Acc 0.9832035720348358 Perturbed Loss 0.05529025722295046
Loss 0.07864688985049724 Acc 0.9773434829711914 Perturbed Loss 0.07874472875148059
Loss 0.06312855556607247 Acc 0.9794245147705078 Perturbed Loss 0.06320373941212892
Loss 0.0672044812515378 Acc 0.9784355914592743 Perturbed Loss 0.06728336673229933
Loss 0.07086378660053015 Acc 0.9747619557380677 Perturbed Loss 0.0709777065552771
Loss 0.06461668688803911 Acc 0.9788812005519867 Perturbed Loss 0.06469994358718395
Loss 0.06426514223217965 Acc 0.9830896747112274 Perturbed Loss 0.0643610836751759
Epoch 17.0 val loss 0.05527104064822197 val acc 0.9799224734306335
Loss 0.06888992495834828 Acc 0.9805715084075928 Perturbed Loss 0.06899857461452484
Loss 0.06740939069539309 Acc 0.9798963177204132 Perturbed Loss 0.06748534802347422
Loss 0.06456847805529833 Acc 0.9776654183864594 Perturbed Loss 0.06464169815182685
Loss 0.063585116378963 Acc 0.9823974311351776 Perturbed Loss 0.06369036259129643
Loss 0.06390943450853229 Acc 0.9816871047019958 Perturbed Loss 0.06399904323741794
Loss 0.05475482290610671 Acc 0.9824051654338837 Perturbed Loss 0.054837990645319225
Loss 0.06285644937306642 Acc 0.9793118953704834 Perturbed Loss 0.06300764132291078
Loss 0.05951151862740517 Acc 0.9811226999759675 Perturbed Loss 0.059612702066078785
Loss 0.06545320883393288 Acc 0.9797026324272156 Perturbed Loss 0.0655178176611662
Loss 0.06459790572524071 Acc 0.9798260986804962 Perturbed Loss 0.06470068097114563
Loss 0.061045023687183855 Acc 0.9789237356185914 Perturbed Loss 0.06111383989453316
Loss 0.07651210568845272 Acc 0.9750737738609314 Perturbed Loss 0.07659664981067181
Loss 0.06119138319045305 Acc 0.979026654958725 Perturbed Loss 0.06128262793645263
Loss 0.07877755410969257 Acc 0.9782778871059418 Perturbed Loss 0.07885297764092684
Loss 0.06029970802366733 Acc 0.9787994027137756 Perturbed Loss 0.06036494199186564
Epoch 18.0 val loss 0.054686449468135834 val acc 0.9800790548324585
Loss 0.06739854112267495 Acc 0.977289832830429 Perturbed Loss 0.06748173534870147
Loss 0.06891353456303477 Acc 0.9786022472381591 Perturbed Loss 0.06900423506274819
Loss 0.0676192832365632 Acc 0.9793925583362579 Perturbed Loss 0.06768522202968598
Loss 0.055490626767277715 Acc 0.9790845656394959 Perturbed Loss 0.055576791241765025
Loss 0.059284799061715604 Acc 0.9822254610061646 Perturbed Loss 0.0593585610948503
Loss 0.06316417336463928 Acc 0.9779103064537048 Perturbed Loss 0.06325067130848766
Loss 0.08334643326699734 Acc 0.9763436675071716 Perturbed Loss 0.08345551285892724
Loss 0.06469443187117577 Acc 0.9800563740730286 Perturbed Loss 0.06477478303015233
Loss 0.06008404757827521 Acc 0.9810523128509522 Perturbed Loss 0.06015719460323453
Loss 0.06240979384630919 Acc 0.98009410738945 Perturbed Loss 0.06248535387217999
Loss 0.06883878333494067 Acc 0.9798348128795624 Perturbed Loss 0.06892878677695989
Loss 0.06113819655030966 Acc 0.9784342408180237 Perturbed Loss 0.06121062085032463
Loss 0.06444354904815555 Acc 0.9796774852275848 Perturbed Loss 0.06453219711780549
Loss 0.0765745386481285 Acc 0.98007453083992 Perturbed Loss 0.07666962943971158
Loss 0.059884376488626004 Acc 0.9829025495052338 Perturbed Loss 0.05996812831610441
Epoch 19.0 val loss 0.05506076663732529 val acc 0.9800416827201843
[02:45:47] INFO     `Trainer.fit` stopped: `max_epochs=20` reached.                                                                                                                         rank_zero.py:53
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750/750 0:03:45 • 0:00:00 3.36it/s train/loss: 0.06 val_loss: 0.055
[02:45:50] INFO     Created a temporary directory at /tmp/tmp739hwgiu                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmp739hwgiu/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
           INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
           INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
           INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
           INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
[02:45:51] INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.0006, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.0, adaptive=True)
[02:45:52] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.08811040788888931 Acc 0.9656881487369537 Perturbed Loss 0.08811040788888931
[02:46:22] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.078848200365901 Acc 0.9711616325378418 Perturbed Loss 0.078848200365901
Loss 0.0854174398072064 Acc 0.9771083521842957 Perturbed Loss 0.0854174398072064
Loss 0.08549253357574343 Acc 0.9737572634220123 Perturbed Loss 0.08549253357574343
Loss 0.08476403687149286 Acc 0.9745298027992249 Perturbed Loss 0.08476403687149286
Loss 0.09961299832910299 Acc 0.9652326393127442 Perturbed Loss 0.09961299832910299
Loss 0.08395957712084055 Acc 0.9692369735240937 Perturbed Loss 0.08395957712084055
Loss 0.08277177134528756 Acc 0.9770537900924683 Perturbed Loss 0.08277177134528756
Loss 0.09069538917392492 Acc 0.973725665807724 Perturbed Loss 0.09069538917392492
Loss 0.08971716221421958 Acc 0.9690923750400543 Perturbed Loss 0.08971716221421958
Loss 0.0797464730963111 Acc 0.97559494972229 Perturbed Loss 0.0797464730963111
Loss 0.09031849015504122 Acc 0.9746152877807617 Perturbed Loss 0.09031849015504122
Loss 0.08396060789003969 Acc 0.9774949264526367 Perturbed Loss 0.08396060789003969
Loss 0.07076226856559514 Acc 0.983107670545578 Perturbed Loss 0.07076226856559514
Loss 0.08389893624931574 Acc 0.9756854808330536 Perturbed Loss 0.08389893624931574
Epoch 0.0 val loss 0.05786759778857231 val acc 0.9791398048400879
Loss 0.07978745371103287 Acc 0.9744362545013427 Perturbed Loss 0.07978745371103287
Loss 0.07641919944435357 Acc 0.9734816706180572 Perturbed Loss 0.07641919944435357
Loss 0.08078841637820006 Acc 0.9663551950454712 Perturbed Loss 0.08078841637820006
Loss 0.07716178450733423 Acc 0.9749639892578125 Perturbed Loss 0.07716178450733423
Loss 0.08334998771548272 Acc 0.976377501487732 Perturbed Loss 0.08334998771548272
Loss 0.07811761664226652 Acc 0.9779158794879913 Perturbed Loss 0.07811761664226652
Loss 0.08557697732001543 Acc 0.9757133340835571 Perturbed Loss 0.08557697732001543
Loss 0.07819737646728754 Acc 0.9779496788978577 Perturbed Loss 0.07819737646728754
Loss 0.07659898629412056 Acc 0.9779330623149872 Perturbed Loss 0.07659898629412056
Loss 0.07741564013063908 Acc 0.9757178866863251 Perturbed Loss 0.07741564013063908
Loss 0.07882434699684382 Acc 0.9666268098354339 Perturbed Loss 0.07882434699684382
Loss 0.09256598416715861 Acc 0.973447984457016 Perturbed Loss 0.09256598416715861
Loss 0.08133739702403546 Acc 0.9786781513690949 Perturbed Loss 0.08133739702403546
Loss 0.09461103664711118 Acc 0.9722105300426483 Perturbed Loss 0.09461103664711118
Loss 0.08798403032124043 Acc 0.9739423131942749 Perturbed Loss 0.08798403032124043
Epoch 1.0 val loss 0.05955236032605171 val acc 0.9784154891967773
Loss 0.07518225813284517 Acc 0.9731252908706665 Perturbed Loss 0.07518225813284517
Loss 0.0864769821241498 Acc 0.9761955940723419 Perturbed Loss 0.0864769821241498
Loss 0.07965261206030845 Acc 0.9754842936992645 Perturbed Loss 0.07965261206030845
Loss 0.07135743454098702 Acc 0.980894570350647 Perturbed Loss 0.07135743454098702
Loss 0.07506931629031896 Acc 0.9789469766616822 Perturbed Loss 0.07506931629031896
Loss 0.07303198374807834 Acc 0.9767261695861816 Perturbed Loss 0.07303198374807834
Loss 0.08538294922560453 Acc 0.9776740407943726 Perturbed Loss 0.08538294922560453
Loss 0.07125377014279366 Acc 0.9809960961341858 Perturbed Loss 0.07125377014279366
Loss 0.08450602777302266 Acc 0.9771710360050201 Perturbed Loss 0.08450602777302266
Loss 0.07838400254026055 Acc 0.9799782705307006 Perturbed Loss 0.07838400254026055
Loss 0.07806812476366759 Acc 0.9785180771350861 Perturbed Loss 0.07806812476366759
Loss 0.08268856406211852 Acc 0.9734320831298828 Perturbed Loss 0.08268856406211852
Loss 0.08632687639445066 Acc 0.9719669854640961 Perturbed Loss 0.08632687639445066
Loss 0.10146904315799475 Acc 0.9666302287578583 Perturbed Loss 0.10146904315799475
Loss 0.08327623903751373 Acc 0.9766909074783325 Perturbed Loss 0.08327623903751373
Epoch 2.0 val loss 0.05901120975613594 val acc 0.9790000915527344
Loss 0.07717575121670961 Acc 0.9756005692481995 Perturbed Loss 0.07717575121670961
Loss 0.0679447215795517 Acc 0.9792117822170258 Perturbed Loss 0.0679447215795517
Loss 0.07726034436374903 Acc 0.9792447209358215 Perturbed Loss 0.07726034436374903
Loss 0.076877885684371 Acc 0.9799784648418427 Perturbed Loss 0.076877885684371
Loss 0.08782661061733961 Acc 0.9778026604652404 Perturbed Loss 0.08782661061733961
Loss 0.08379186792299151 Acc 0.9761395311355591 Perturbed Loss 0.08379186792299151
Loss 0.07520805064588786 Acc 0.982121889591217 Perturbed Loss 0.07520805064588786
Loss 0.08263383071869612 Acc 0.9762829005718231 Perturbed Loss 0.08263383071869612
Loss 0.08732755728065968 Acc 0.9772360265254975 Perturbed Loss 0.08732755728065968
Loss 0.0768270905315876 Acc 0.9761327862739563 Perturbed Loss 0.0768270905315876
Loss 0.06778813228011131 Acc 0.9765001821517945 Perturbed Loss 0.06778813228011131
Loss 0.08485655464231968 Acc 0.9733873808383942 Perturbed Loss 0.08485655464231968
Loss 0.09373906470835208 Acc 0.9750105607509613 Perturbed Loss 0.09373906470835208
Loss 0.07676889780908823 Acc 0.9716533041000366 Perturbed Loss 0.07676889780908823
Loss 0.08304120272397995 Acc 0.9757590460777282 Perturbed Loss 0.08304120272397995
Epoch 3.0 val loss 0.057495590299367905 val acc 0.9788060188293457
Loss 0.06264086458832026 Acc 0.9809624934196473 Perturbed Loss 0.06264086458832026
Loss 0.0743494763597846 Acc 0.9805501329898835 Perturbed Loss 0.0743494763597846
Loss 0.06515889186412097 Acc 0.9742163729667663 Perturbed Loss 0.06515889186412097
Loss 0.08497154656797648 Acc 0.976635057926178 Perturbed Loss 0.08497154656797648
Loss 0.081888367831707 Acc 0.9750218939781189 Perturbed Loss 0.081888367831707
Loss 0.07501496201381087 Acc 0.9783984792232513 Perturbed Loss 0.07501496201381087
Loss 0.06516296863555908 Acc 0.9796746838092804 Perturbed Loss 0.06516296863555908
Loss 0.06986921712756157 Acc 0.9794290745258332 Perturbed Loss 0.06986921712756157
Loss 0.07459431122988462 Acc 0.9761868560314179 Perturbed Loss 0.07459431122988462
Loss 0.06809228600934147 Acc 0.977454445362091 Perturbed Loss 0.06809228600934147
Loss 0.07987229947000742 Acc 0.9786501979827881 Perturbed Loss 0.07987229947000742
Loss 0.07931676752865315 Acc 0.9759080862998962 Perturbed Loss 0.07931676752865315
Loss 0.07850457355380058 Acc 0.9770424044132233 Perturbed Loss 0.07850457355380058
Loss 0.07614015966653824 Acc 0.9796099126338959 Perturbed Loss 0.07614015966653824
Loss 0.07584442630410194 Acc 0.9798222780227661 Perturbed Loss 0.07584442630410194
Epoch 4.0 val loss 0.05885859578847885 val acc 0.9789590835571289
Loss 0.07392539568245411 Acc 0.9785075974464417 Perturbed Loss 0.07392539568245411
Loss 0.07823073744773865 Acc 0.9797543716430664 Perturbed Loss 0.07823073744773865
Loss 0.08206587843596935 Acc 0.974443930387497 Perturbed Loss 0.08206587843596935
Loss 0.08407972531393171 Acc 0.9715879929065704 Perturbed Loss 0.08407972531393171
Loss 0.07700840588659048 Acc 0.976891747713089 Perturbed Loss 0.07700840588659048
Loss 0.0826232435181737 Acc 0.9750350570678711 Perturbed Loss 0.0826232435181737
Loss 0.0751069213077426 Acc 0.9790902721881867 Perturbed Loss 0.0751069213077426
Loss 0.07537575133144855 Acc 0.9759813189506531 Perturbed Loss 0.07537575133144855
Loss 0.07862489040941 Acc 0.9776214599609375 Perturbed Loss 0.07862489040941
Loss 0.07476973425596953 Acc 0.9775568187236786 Perturbed Loss 0.07476973425596953
Loss 0.07895946208387614 Acc 0.9769882953166962 Perturbed Loss 0.07895946208387614
Loss 0.08159954085946083 Acc 0.9753860056400299 Perturbed Loss 0.08159954085946083
Loss 0.08172535113990306 Acc 0.9795568573474884 Perturbed Loss 0.08172535113990306
Loss 0.0791882824152708 Acc 0.9769929945468903 Perturbed Loss 0.0791882824152708
Loss 0.07020257933065295 Acc 0.9766015791893006 Perturbed Loss 0.07020257933065295
Epoch 5.0 val loss 0.056642211973667145 val acc 0.9793177247047424
Loss 0.07521603118628263 Acc 0.9782462954521179 Perturbed Loss 0.07521603118628263
Loss 0.07312856674194336 Acc 0.979501622915268 Perturbed Loss 0.07312856674194336
Loss 0.07701491907238961 Acc 0.9791269576549531 Perturbed Loss 0.07701491907238961
Loss 0.08242963407188654 Acc 0.9758729004859924 Perturbed Loss 0.08242963407188654
Loss 0.07346776861697435 Acc 0.9819396221637726 Perturbed Loss 0.07346776861697435
Loss 0.07627361921593546 Acc 0.975947380065918 Perturbed Loss 0.07627361921593546
Loss 0.07216999161988497 Acc 0.9748420226573944 Perturbed Loss 0.07216999161988497
Loss 0.06926152501255274 Acc 0.9812708175182343 Perturbed Loss 0.06926152501255274
Loss 0.07204291954636574 Acc 0.9794241321086884 Perturbed Loss 0.07204291954636574
Loss 0.0823446698859334 Acc 0.9762493515014649 Perturbed Loss 0.0823446698859334
Loss 0.07361442323774099 Acc 0.9787617802619935 Perturbed Loss 0.07361442323774099
Loss 0.07475640985183418 Acc 0.978638002872467 Perturbed Loss 0.07475640985183418
Loss 0.07224789461120963 Acc 0.9761598300933838 Perturbed Loss 0.07224789461120963
Loss 0.07552632085978984 Acc 0.9809454059600831 Perturbed Loss 0.07552632085978984
Loss 0.07660569239407777 Acc 0.974078757762909 Perturbed Loss 0.07660569239407777
Epoch 6.0 val loss 0.05650658532977104 val acc 0.9793493747711182
Loss 0.0786884374730289 Acc 0.9756352627277374 Perturbed Loss 0.0786884374730289
Loss 0.0774835487920791 Acc 0.9773169875144958 Perturbed Loss 0.0774835487920791
Loss 0.0737384295463562 Acc 0.9773444378376007 Perturbed Loss 0.0737384295463562
Loss 0.06593136643990874 Acc 0.9822878396511078 Perturbed Loss 0.06593136643990874
Loss 0.07077897299081087 Acc 0.9771985197067261 Perturbed Loss 0.07077897299081087
Loss 0.07677268274128438 Acc 0.9773866224288941 Perturbed Loss 0.07677268274128438
Loss 0.08266672156751156 Acc 0.9729559624195099 Perturbed Loss 0.08266672156751156
Loss 0.07001630075275898 Acc 0.9808405363559722 Perturbed Loss 0.07001630075275898
Loss 0.07719475015997887 Acc 0.9769879066944123 Perturbed Loss 0.07719475015997887
Loss 0.07663239158689976 Acc 0.9783950889110565 Perturbed Loss 0.07663239158689976
Loss 0.0799320125952363 Acc 0.9803342723846435 Perturbed Loss 0.0799320125952363
Loss 0.0735261694341898 Acc 0.9795294761657715 Perturbed Loss 0.0735261694341898
Loss 0.06835074007511138 Acc 0.9766040086746216 Perturbed Loss 0.06835074007511138
Loss 0.07150821790099143 Acc 0.9813834035396576 Perturbed Loss 0.07150821790099143
Loss 0.07825162574648857 Acc 0.9773100709915161 Perturbed Loss 0.07825162574648857
Epoch 7.0 val loss 0.05856247618794441 val acc 0.9786951541900635
Loss 0.07094373192638159 Acc 0.9777692413330078 Perturbed Loss 0.07094373192638159
Loss 0.07122526771388948 Acc 0.9727960789203643 Perturbed Loss 0.07122526771388948
Loss 0.06671704780310392 Acc 0.9781102514266968 Perturbed Loss 0.06671704780310392
Loss 0.07197430856525898 Acc 0.9770932066440582 Perturbed Loss 0.07197430856525898
Loss 0.06536849545314909 Acc 0.9791039574146271 Perturbed Loss 0.06536849545314909
Loss 0.07315598982386291 Acc 0.9764708769321442 Perturbed Loss 0.07315598982386291
Loss 0.06241058900952339 Acc 0.9786346614360809 Perturbed Loss 0.06241058900952339
Loss 0.06660057365894317 Acc 0.9785803830623627 Perturbed Loss 0.06660057365894317
Loss 0.07756221016868949 Acc 0.9764367997646332 Perturbed Loss 0.07756221016868949
Loss 0.06802104193717241 Acc 0.9766413807868958 Perturbed Loss 0.06802104193717241
Loss 0.07927667889744043 Acc 0.9786122453212738 Perturbed Loss 0.07927667889744043
Loss 0.0731506579183042 Acc 0.9791903150081634 Perturbed Loss 0.0731506579183042
Loss 0.06688167177140712 Acc 0.9788997411727905 Perturbed Loss 0.06688167177140712
Loss 0.07452848821878433 Acc 0.978343768119812 Perturbed Loss 0.07452848821878433
Loss 0.07405481989495456 Acc 0.9820082592964172 Perturbed Loss 0.07405481989495456
Epoch 8.0 val loss 0.05835481360554695 val acc 0.9789720773696899
Loss 0.07360560789704323 Acc 0.97470712184906 Perturbed Loss 0.07360560789704323
Loss 0.07032955979928374 Acc 0.9784471750259399 Perturbed Loss 0.07032955979928374
Loss 0.07110830686986447 Acc 0.9773195660114289 Perturbed Loss 0.07110830686986447
Loss 0.06101984951645136 Acc 0.9800344681739808 Perturbed Loss 0.06101984951645136
Loss 0.07219475641846657 Acc 0.9779423415660858 Perturbed Loss 0.07219475641846657
Loss 0.06936362780630588 Acc 0.9773450684547424 Perturbed Loss 0.06936362780630588
Loss 0.0664961151778698 Acc 0.9811664474010467 Perturbed Loss 0.0664961151778698
Loss 0.0817404480278492 Acc 0.97921466588974 Perturbed Loss 0.0817404480278492
Loss 0.06300731919705868 Acc 0.9800048696994782 Perturbed Loss 0.06300731919705868
Loss 0.06861838396638632 Acc 0.9817091012001038 Perturbed Loss 0.06861838396638632
Loss 0.06685701414942741 Acc 0.9800772678852081 Perturbed Loss 0.06685701414942741
Loss 0.07403762269765139 Acc 0.9788945686817169 Perturbed Loss 0.07403762269765139
Loss 0.07240127965807915 Acc 0.9777889287471772 Perturbed Loss 0.07240127965807915
Loss 0.08271882366389036 Acc 0.9766736912727356 Perturbed Loss 0.08271882366389036
Loss 0.07715129114687443 Acc 0.9771111142635346 Perturbed Loss 0.07715129114687443
Epoch 9.0 val loss 0.0558355338871479 val acc 0.9795466661453247
Loss 0.07529355201870203 Acc 0.9826083815097809 Perturbed Loss 0.07529355201870203
Loss 0.07327822756022215 Acc 0.9770619344711303 Perturbed Loss 0.07327822756022215
Loss 0.0677019883506 Acc 0.981089676618576 Perturbed Loss 0.0677019883506
Loss 0.07760782232508064 Acc 0.9744110429286956 Perturbed Loss 0.07760782232508064
Loss 0.06214175023138523 Acc 0.9826406586170197 Perturbed Loss 0.06214175023138523
Loss 0.06518165595829487 Acc 0.9787645030021668 Perturbed Loss 0.06518165595829487
Loss 0.06791659250855446 Acc 0.9771164345741272 Perturbed Loss 0.06791659250855446
Loss 0.06622538425959647 Acc 0.9830131018161774 Perturbed Loss 0.06622538425959647
Loss 0.06373026084154844 Acc 0.9789928674697876 Perturbed Loss 0.06373026084154844
Loss 0.06894166408106685 Acc 0.9772040998935699 Perturbed Loss 0.06894166408106685
Loss 0.06838881019502878 Acc 0.9788674151897431 Perturbed Loss 0.06838881019502878
Loss 0.07733101166784763 Acc 0.9775720620155335 Perturbed Loss 0.07733101166784763
Loss 0.06461052378639578 Acc 0.9798482573032379 Perturbed Loss 0.06461052378639578
Loss 0.06453663278371095 Acc 0.978283498287201 Perturbed Loss 0.06453663278371095
Loss 0.06616623692214489 Acc 0.977342096567154 Perturbed Loss 0.06616623692214489
Epoch 10.0 val loss 0.05640905722975731 val acc 0.9796004891395569
Loss 0.06870434041135014 Acc 0.9798296403884887 Perturbed Loss 0.06870434041135014
Loss 0.07161664105951786 Acc 0.980686469078064 Perturbed Loss 0.07161664105951786
Loss 0.06614457359537482 Acc 0.9798396289348602 Perturbed Loss 0.06614457359537482
Loss 0.06269090196117759 Acc 0.9789478862285614 Perturbed Loss 0.06269090196117759
Loss 0.06644765824079514 Acc 0.9778246665000916 Perturbed Loss 0.06644765824079514
Loss 0.06290241848677397 Acc 0.9782915616035461 Perturbed Loss 0.06290241848677397
Loss 0.07026292271912098 Acc 0.9787350904941559 Perturbed Loss 0.07026292271912098
Loss 0.07651266347616911 Acc 0.9779553484916687 Perturbed Loss 0.07651266347616911
Loss 0.0601037760078907 Acc 0.9802962136268616 Perturbed Loss 0.0601037760078907
Loss 0.06299266450107098 Acc 0.9817773997783661 Perturbed Loss 0.06299266450107098
Loss 0.06816944867372512 Acc 0.9776591837406159 Perturbed Loss 0.06816944867372512
Loss 0.07030974786728621 Acc 0.9807388186454773 Perturbed Loss 0.07030974786728621
Loss 0.07937043480575084 Acc 0.976427686214447 Perturbed Loss 0.07937043480575084
Loss 0.06184514133259654 Acc 0.9816444337368011 Perturbed Loss 0.06184514133259654
Loss 0.06369032949209213 Acc 0.9799415946006775 Perturbed Loss 0.06369032949209213
Epoch 11.0 val loss 0.05587536469101906 val acc 0.9791110754013062
Loss 0.08318046253174544 Acc 0.9780755174160004 Perturbed Loss 0.08318046253174544
Loss 0.07358593702316284 Acc 0.9762669670581817 Perturbed Loss 0.07358593702316284
Loss 0.07293769907206298 Acc 0.9811880731582642 Perturbed Loss 0.07293769907206298
Loss 0.06260489892214537 Acc 0.9793915784358979 Perturbed Loss 0.06260489892214537
Loss 0.06323682779446244 Acc 0.9843067419528961 Perturbed Loss 0.06323682779446244
Loss 0.062318687010556456 Acc 0.9793784129619598 Perturbed Loss 0.062318687010556456
Loss 0.06813901288434863 Acc 0.9793312096595764 Perturbed Loss 0.06813901288434863
Loss 0.06663105929270387 Acc 0.9793952035903931 Perturbed Loss 0.06663105929270387
Loss 0.06376612447202205 Acc 0.9773966634273529 Perturbed Loss 0.06376612447202205
Loss 0.061666753068566324 Acc 0.9810181450843811 Perturbed Loss 0.061666753068566324
Loss 0.0734243006631732 Acc 0.9780443906784058 Perturbed Loss 0.0734243006631732
Loss 0.06338888799771666 Acc 0.9766446828842164 Perturbed Loss 0.06338888799771666
Loss 0.07345892202109099 Acc 0.9809992146492005 Perturbed Loss 0.07345892202109099
Loss 0.06282838635146618 Acc 0.9803411054611206 Perturbed Loss 0.06282838635146618
Loss 0.06822772718966007 Acc 0.9744341003894806 Perturbed Loss 0.06822772718966007
Epoch 12.0 val loss 0.055562060326337814 val acc 0.9794588088989258
Loss 0.06958980644121766 Acc 0.9782961821556091 Perturbed Loss 0.06958980644121766
Loss 0.07715087581425906 Acc 0.9772513914108276 Perturbed Loss 0.07715087581425906
Loss 0.07553873028606177 Acc 0.9777288734912872 Perturbed Loss 0.07553873028606177
Loss 0.0683931703865528 Acc 0.9803797173500061 Perturbed Loss 0.0683931703865528
Loss 0.06526185715571046 Acc 0.9798638761043549 Perturbed Loss 0.06526185715571046
Loss 0.06835724737495184 Acc 0.9815928399562835 Perturbed Loss 0.06835724737495184
Loss 0.07126224432140589 Acc 0.9761819958686828 Perturbed Loss 0.07126224432140589
Loss 0.0723610127530992 Acc 0.9779621767997742 Perturbed Loss 0.0723610127530992
Loss 0.06978639833629131 Acc 0.9786802232265472 Perturbed Loss 0.06978639833629131
Loss 0.06648515282198787 Acc 0.9795780193805694 Perturbed Loss 0.06648515282198787
Loss 0.073945791721344 Acc 0.9785704898834229 Perturbed Loss 0.073945791721344
Loss 0.06991313744336367 Acc 0.9810618448257447 Perturbed Loss 0.06991313744336367
Loss 0.06250999683514237 Acc 0.9772413444519042 Perturbed Loss 0.06250999683514237
Loss 0.061305003706365824 Acc 0.9797458660602569 Perturbed Loss 0.061305003706365824
Loss 0.06659580256789922 Acc 0.9814611387252807 Perturbed Loss 0.06659580256789922
Epoch 13.0 val loss 0.05587686970829964 val acc 0.9796777367591858
Loss 0.06478225016966462 Acc 0.9796686244010925 Perturbed Loss 0.06478225016966462
Loss 0.07328331287950278 Acc 0.97636190533638 Perturbed Loss 0.07328331287950278
Loss 0.06772853014990687 Acc 0.979932074546814 Perturbed Loss 0.06772853014990687
Loss 0.0703407471626997 Acc 0.9777947318553925 Perturbed Loss 0.0703407471626997
Loss 0.06894868049770593 Acc 0.978297061920166 Perturbed Loss 0.06894868049770593
Loss 0.05824159562587738 Acc 0.9811490380764007 Perturbed Loss 0.05824159562587738
Loss 0.06123870626091957 Acc 0.9816133379936218 Perturbed Loss 0.06123870626091957
Loss 0.06022149708122015 Acc 0.9803872632980347 Perturbed Loss 0.06022149708122015
Loss 0.06343672934919596 Acc 0.981062730550766 Perturbed Loss 0.06343672934919596
Loss 0.06750553615391254 Acc 0.9750968790054322 Perturbed Loss 0.06750553615391254
Loss 0.07392957594245672 Acc 0.9790034329891205 Perturbed Loss 0.07392957594245672
Loss 0.06798536885529756 Acc 0.9766190159320831 Perturbed Loss 0.06798536885529756
Loss 0.06850879373028874 Acc 0.9802924013137817 Perturbed Loss 0.06850879373028874
Loss 0.07537671955302358 Acc 0.9736767089366913 Perturbed Loss 0.07537671955302358
Loss 0.0653962865844369 Acc 0.9796754658222199 Perturbed Loss 0.0653962865844369
Epoch 14.0 val loss 0.05497784912586212 val acc 0.9800431728363037
Loss 0.0682248554006219 Acc 0.9757949912548065 Perturbed Loss 0.0682248554006219
Loss 0.06787531517446041 Acc 0.9802628540992737 Perturbed Loss 0.06787531517446041
Loss 0.07495726127177477 Acc 0.973786541223526 Perturbed Loss 0.07495726127177477
Loss 0.07065900582820177 Acc 0.9793613660335541 Perturbed Loss 0.07065900582820177
Loss 0.05676195677369833 Acc 0.981336520910263 Perturbed Loss 0.05676195677369833
Loss 0.05815071106422692 Acc 0.9814615261554718 Perturbed Loss 0.05815071106422692
Loss 0.06408172282390297 Acc 0.9804947221279144 Perturbed Loss 0.06408172282390297
Loss 0.08738179737702012 Acc 0.9782192718982696 Perturbed Loss 0.08738179737702012
Loss 0.07570879109203815 Acc 0.9800350153446198 Perturbed Loss 0.07570879109203815
Loss 0.06900903297588229 Acc 0.9800115346908569 Perturbed Loss 0.06900903297588229
Loss 0.0635621639341116 Acc 0.9837211179733276 Perturbed Loss 0.0635621639341116
Loss 0.06731773484498263 Acc 0.9782143473625183 Perturbed Loss 0.06731773484498263
Loss 0.062150168716907504 Acc 0.9815539634227752 Perturbed Loss 0.062150168716907504
Loss 0.06185479961335659 Acc 0.9819440770149231 Perturbed Loss 0.06185479961335659
Loss 0.07723781105130911 Acc 0.9778425896167755 Perturbed Loss 0.07723781105130911
Epoch 15.0 val loss 0.05502548813819885 val acc 0.9795665740966797
Loss 0.06687936139293015 Acc 0.9773168110847473 Perturbed Loss 0.06687936139293015
Loss 0.0667398713901639 Acc 0.9777196514606475 Perturbed Loss 0.0667398713901639
Loss 0.07203817535191774 Acc 0.9802713656425476 Perturbed Loss 0.07203817535191774
Loss 0.061858580298721794 Acc 0.9805883204936982 Perturbed Loss 0.061858580298721794
Loss 0.06159427411854267 Acc 0.9804278695583344 Perturbed Loss 0.06159427411854267
Loss 0.06873875038698316 Acc 0.9811507451534272 Perturbed Loss 0.06873875038698316
Loss 0.07166792415082454 Acc 0.980039119720459 Perturbed Loss 0.07166792415082454
Loss 0.07258560840040446 Acc 0.9788495993614197 Perturbed Loss 0.07258560840040446
Loss 0.05945720050483942 Acc 0.980391491651535 Perturbed Loss 0.05945720050483942
Loss 0.05586497031152248 Acc 0.984100626707077 Perturbed Loss 0.05586497031152248
Loss 0.06662793502211571 Acc 0.9788773369789123 Perturbed Loss 0.06662793502211571
Loss 0.06461181778460741 Acc 0.9814768946170807 Perturbed Loss 0.06461181778460741
Loss 0.06059679539874196 Acc 0.980641770362854 Perturbed Loss 0.06059679539874196
Loss 0.06675065035000444 Acc 0.9813553881645203 Perturbed Loss 0.06675065035000444
Loss 0.05886878505349159 Acc 0.9843028128147125 Perturbed Loss 0.05886878505349159
Epoch 16.0 val loss 0.05485016852617264 val acc 0.979945719242096
Loss 0.06958067506551742 Acc 0.9790383493900299 Perturbed Loss 0.06958067506551742
Loss 0.07109623406082392 Acc 0.9820016872882843 Perturbed Loss 0.07109623406082392
Loss 0.06108921026811004 Acc 0.9799492752552033 Perturbed Loss 0.06108921026811004
Loss 0.06998174790292978 Acc 0.9794914770126343 Perturbed Loss 0.06998174790292978
Loss 0.06239593038335443 Acc 0.9809096312522888 Perturbed Loss 0.06239593038335443
Loss 0.06018571633845568 Acc 0.9800229620933533 Perturbed Loss 0.06018571633845568
Loss 0.0679063289053738 Acc 0.9763702583312989 Perturbed Loss 0.0679063289053738
Loss 0.06373647756874562 Acc 0.9816282212734222 Perturbed Loss 0.06373647756874562
Loss 0.05472327327355742 Acc 0.9829784941673279 Perturbed Loss 0.05472327327355742
Loss 0.07993478886783123 Acc 0.9770663368701935 Perturbed Loss 0.07993478886783123
Loss 0.06433196971192956 Acc 0.9791553258895874 Perturbed Loss 0.06433196971192956
Loss 0.0700192091614008 Acc 0.9778469562530517 Perturbed Loss 0.0700192091614008
Loss 0.06313222715631127 Acc 0.9748499441146851 Perturbed Loss 0.06313222715631127
Loss 0.06386853363364935 Acc 0.9786193490028381 Perturbed Loss 0.06386853363364935
Loss 0.06461672514677047 Acc 0.982890157699585 Perturbed Loss 0.06461672514677047
Epoch 17.0 val loss 0.055059947073459625 val acc 0.9799293875694275
Loss 0.06675139762461185 Acc 0.9797248649597168 Perturbed Loss 0.06675139762461185
Loss 0.06717982232570648 Acc 0.9801305830478668 Perturbed Loss 0.06717982232570648
Loss 0.06649576433002949 Acc 0.97697496175766 Perturbed Loss 0.06649576433002949
Loss 0.06347383350133896 Acc 0.9823396682739258 Perturbed Loss 0.06347383350133896
Loss 0.06263688215985894 Acc 0.9811567556858063 Perturbed Loss 0.06263688215985894
Loss 0.054693361166864636 Acc 0.9824694764614105 Perturbed Loss 0.054693361166864636
Loss 0.05740781247615814 Acc 0.9794743311405182 Perturbed Loss 0.05740781247615814
Loss 0.060558224506676195 Acc 0.9809114027023316 Perturbed Loss 0.060558224506676195
Loss 0.06812739500775933 Acc 0.9797432768344879 Perturbed Loss 0.06812739500775933
Loss 0.06530639201402665 Acc 0.9797889709472656 Perturbed Loss 0.06530639201402665
Loss 0.06286452449858189 Acc 0.9789389884471893 Perturbed Loss 0.06286452449858189
Loss 0.07596097383648157 Acc 0.975210155248642 Perturbed Loss 0.07596097383648157
Loss 0.06249577084556222 Acc 0.9792597913742065 Perturbed Loss 0.06249577084556222
Loss 0.07588606417179107 Acc 0.9787588346004487 Perturbed Loss 0.07588606417179107
Loss 0.058731313515454533 Acc 0.978946830034256 Perturbed Loss 0.058731313515454533
Epoch 18.0 val loss 0.054416120052337646 val acc 0.9800968170166016
Loss 0.06639735482633113 Acc 0.9769915330410004 Perturbed Loss 0.06639735482633113
Loss 0.0691604490764439 Acc 0.9782861030101776 Perturbed Loss 0.0691604490764439
Loss 0.06710907626897096 Acc 0.979418078660965 Perturbed Loss 0.06710907626897096
Loss 0.055630128048360344 Acc 0.9792290568351746 Perturbed Loss 0.055630128048360344
Loss 0.05885199785232544 Acc 0.9822986137866974 Perturbed Loss 0.05885199785232544
Loss 0.06341348718851805 Acc 0.9774974060058593 Perturbed Loss 0.06341348718851805
Loss 0.08323341770097613 Acc 0.9764462292194367 Perturbed Loss 0.08323341770097613
Loss 0.06271446811035275 Acc 0.9797795414924622 Perturbed Loss 0.06271446811035275
Loss 0.06063158819451928 Acc 0.9809728682041168 Perturbed Loss 0.06063158819451928
Loss 0.06195496927946806 Acc 0.979863657951355 Perturbed Loss 0.06195496927946806
Loss 0.06817896500229835 Acc 0.9793006289005279 Perturbed Loss 0.06817896500229835
Loss 0.060758921056985854 Acc 0.9785003805160523 Perturbed Loss 0.060758921056985854
Loss 0.0649074270389974 Acc 0.9799541223049164 Perturbed Loss 0.0649074270389974
Loss 0.07616006929427385 Acc 0.9800897884368897 Perturbed Loss 0.07616006929427385
Loss 0.05996244836598635 Acc 0.9817516219615936 Perturbed Loss 0.05996244836598635
Epoch 19.0 val loss 0.05498683825135231 val acc 0.9799297451972961
[04:09:38] INFO     `Trainer.fit` stopped: `max_epochs=20` reached.                                                                                                                         rank_zero.py:53
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750/750 0:03:45 • 0:00:00 3.36it/s train/loss: 0.06 val_loss: 0.055
ADAPTIVE FALSE RHO GRID SEARCH
[04:09:41] INFO     Created a temporary directory at /tmp/tmptv_5fdgh                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmptv_5fdgh/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
           INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
           INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
[04:09:42] INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
           INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
           INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
[04:09:43] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.0006, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.01, adaptive=False)
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.08804336670786142 Acc 0.9658453857898712 Perturbed Loss 0.09322506807744503
[04:10:13] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.07508870057761668 Acc 0.9715870881080627 Perturbed Loss 0.0785295619815588
Loss 0.08599556708708406 Acc 0.9772976136207581 Perturbed Loss 0.0901980334147811
Loss 0.08357080275192857 Acc 0.9739525961875916 Perturbed Loss 0.08583327732980252
Loss 0.08286699844524265 Acc 0.9753444576263428 Perturbed Loss 0.08602798767387868
Loss 0.09539454337209463 Acc 0.9663227009773254 Perturbed Loss 0.09877199862152337
Loss 0.08164209183305501 Acc 0.9710800921916962 Perturbed Loss 0.08419537883251905
Loss 0.0781952608190477 Acc 0.9783739173412322 Perturbed Loss 0.0808600839227438
Loss 0.09067626103758812 Acc 0.9727272427082062 Perturbed Loss 0.09340232864022255
Loss 0.08773143500089646 Acc 0.9688721036911011 Perturbed Loss 0.09118083249777556
Loss 0.07576631963253021 Acc 0.9780155372619629 Perturbed Loss 0.07762916143983603
Loss 0.08740285461768509 Acc 0.9767056620121002 Perturbed Loss 0.0903744107671082
Loss 0.08078838819637894 Acc 0.9774356651306152 Perturbed Loss 0.08419080052524805
Loss 0.07094432886689901 Acc 0.9824328804016114 Perturbed Loss 0.07348783969879151
Loss 0.08087109407410026 Acc 0.9756214487552642 Perturbed Loss 0.08353817503899336
Epoch 0.0 val loss 0.056897733360528946 val acc 0.9790181517601013
Loss 0.08156875524669886 Acc 0.9736979925632476 Perturbed Loss 0.08419255968183278
Loss 0.07506756312213839 Acc 0.9732870590686798 Perturbed Loss 0.07728353497572243
Loss 0.07835072036832572 Acc 0.9679147958755493 Perturbed Loss 0.08043646205216647
Loss 0.07115486161783338 Acc 0.9751124382019043 Perturbed Loss 0.0731132835522294
Loss 0.08321787925437092 Acc 0.9770049858093262 Perturbed Loss 0.08563630422577262
Loss 0.07926185568794608 Acc 0.9763117110729218 Perturbed Loss 0.08161424983292818
Loss 0.0861605316400528 Acc 0.9745281374454499 Perturbed Loss 0.08850745037198067
Loss 0.0737054269760847 Acc 0.9785771715641022 Perturbed Loss 0.07553598955273629
Loss 0.07914243165403605 Acc 0.976532289981842 Perturbed Loss 0.08159325169399381
Loss 0.08193261602893472 Acc 0.9763042986392975 Perturbed Loss 0.08424907116219402
Loss 0.07973725821822882 Acc 0.9682010996341706 Perturbed Loss 0.08221581641584635
Loss 0.09488354668021202 Acc 0.9728741765022277 Perturbed Loss 0.09757681496441364
Loss 0.07904537551105023 Acc 0.980184121131897 Perturbed Loss 0.08067501466721297
Loss 0.09584470190107823 Acc 0.972700412273407 Perturbed Loss 0.09886510070413351
Loss 0.08331185482442378 Acc 0.9752553713321686 Perturbed Loss 0.08642896890640259
Epoch 1.0 val loss 0.057585567235946655 val acc 0.9792121052742004
Loss 0.0744726519100368 Acc 0.9747000753879547 Perturbed Loss 0.07649962686002254
Loss 0.08727989129722119 Acc 0.9784642553329468 Perturbed Loss 0.0892271527275443
Loss 0.07753612242639064 Acc 0.9773996996879578 Perturbed Loss 0.07989765822887421
Loss 0.07392227992415429 Acc 0.9811137998104096 Perturbed Loss 0.07643209362402559
Loss 0.07349977061152459 Acc 0.9800951671600342 Perturbed Loss 0.07584079541265965
Loss 0.072842968814075 Acc 0.976543561220169 Perturbed Loss 0.0753402728587389
Loss 0.08063915768638254 Acc 0.9788980162143708 Perturbed Loss 0.08316800698637962
Loss 0.07340151462703944 Acc 0.9817814683914184 Perturbed Loss 0.07543150812387467
Loss 0.08258197229355574 Acc 0.9752391207218171 Perturbed Loss 0.08531937777996063
Loss 0.07824570452794433 Acc 0.9781126523017883 Perturbed Loss 0.08105708576738835
Loss 0.08006719365715981 Acc 0.9771304273605347 Perturbed Loss 0.08257942955940961
Loss 0.08494140312075615 Acc 0.9733902359008789 Perturbed Loss 0.08696615256369114
Loss 0.08404934499412775 Acc 0.9710282766819001 Perturbed Loss 0.08671817053109407
Loss 0.09511261753737926 Acc 0.9681032633781433 Perturbed Loss 0.09722697358578443
Loss 0.08212596587836743 Acc 0.9766664385795594 Perturbed Loss 0.08388667890802026
Epoch 2.0 val loss 0.05707613751292229 val acc 0.9794623255729675
Loss 0.07233520902693272 Acc 0.975939210653305 Perturbed Loss 0.07409265708178282
Loss 0.0662848797440529 Acc 0.9785044169425965 Perturbed Loss 0.06822310850024223
Loss 0.07345286283642054 Acc 0.9797479188442231 Perturbed Loss 0.07582571659237146
Loss 0.07735984731465578 Acc 0.9797933542728424 Perturbed Loss 0.0801373777166009
Loss 0.08335072066634894 Acc 0.9768858277797698 Perturbed Loss 0.08583548601716756
Loss 0.08718115156516433 Acc 0.9758877348899841 Perturbed Loss 0.08902786256745458
Loss 0.06739607095718383 Acc 0.9820984864234924 Perturbed Loss 0.06940046802163125
Loss 0.07645393315702677 Acc 0.9779530370235443 Perturbed Loss 0.07817554492503405
Loss 0.08471533764153719 Acc 0.978343379497528 Perturbed Loss 0.08653311979025602
Loss 0.07689569868147374 Acc 0.9762804520130157 Perturbed Loss 0.07814917819574475
Loss 0.06394108336418867 Acc 0.9777360761165619 Perturbed Loss 0.06562706176191568
Loss 0.08578429196029902 Acc 0.9744107604026795 Perturbed Loss 0.08791710570454597
Loss 0.0929178724065423 Acc 0.9753625857830047 Perturbed Loss 0.09597633495926856
Loss 0.0737864226847887 Acc 0.9728549814224243 Perturbed Loss 0.07600736550986767
Loss 0.07604666791856289 Acc 0.9775686502456665 Perturbed Loss 0.07826416656374931
Epoch 3.0 val loss 0.05934082344174385 val acc 0.9787506461143494
Loss 0.0697920798137784 Acc 0.9778369045257569 Perturbed Loss 0.07276671081781387
Loss 0.07586956862360239 Acc 0.9816067945957184 Perturbed Loss 0.07853560723364353
Loss 0.06915591595694423 Acc 0.9739964413642883 Perturbed Loss 0.07138165535405278
Loss 0.09323957460932433 Acc 0.9767290759086609 Perturbed Loss 0.09567998636513948
Loss 0.07855492519214749 Acc 0.9757963752746582 Perturbed Loss 0.08312727082520724
Loss 0.07768116679042578 Acc 0.9779714643955231 Perturbed Loss 0.07933111064136028
Loss 0.07106949988752603 Acc 0.9782205605506897 Perturbed Loss 0.07321095131337643
Loss 0.07543451063334942 Acc 0.9778466451168061 Perturbed Loss 0.07744258023798466
Loss 0.0710670230165124 Acc 0.97510626912117 Perturbed Loss 0.07265529258176684
Loss 0.06967435538768768 Acc 0.977224372625351 Perturbed Loss 0.07256269317120313
Loss 0.0790792802721262 Acc 0.98017169713974 Perturbed Loss 0.08158461648970843
Loss 0.0805493238568306 Acc 0.9769287168979645 Perturbed Loss 0.08246311113238335
Loss 0.08108850268647075 Acc 0.9744569146633149 Perturbed Loss 0.08377299331128597
Loss 0.07532824914902449 Acc 0.9792150950431824 Perturbed Loss 0.0767605772614479
Loss 0.073149188850075 Acc 0.9798883020877838 Perturbed Loss 0.07491306938230992
Epoch 4.0 val loss 0.059250250458717346 val acc 0.9788812398910522
Loss 0.07415381858125329 Acc 0.9771929824352265 Perturbed Loss 0.0762228793464601
Loss 0.0783940127119422 Acc 0.9798677325248718 Perturbed Loss 0.08063686940819025
Loss 0.08307812098413705 Acc 0.9771618795394897 Perturbed Loss 0.0857517771422863
Loss 0.0859819608926773 Acc 0.9726464164257049 Perturbed Loss 0.08814584117382765
Loss 0.07345906741917134 Acc 0.9791361284255982 Perturbed Loss 0.07529726233333349
Loss 0.08442204773426056 Acc 0.9751231777667999 Perturbed Loss 0.08705897718667983
Loss 0.0690852389484644 Acc 0.979701601266861 Perturbed Loss 0.07087022567167878
Loss 0.06754101030528545 Acc 0.9776037776470184 Perturbed Loss 0.0693474499695003
Loss 0.07944155175238848 Acc 0.9790659999847412 Perturbed Loss 0.0814742885529995
Loss 0.0706404035165906 Acc 0.9777027237415313 Perturbed Loss 0.07296528041362763
Loss 0.07780563373118639 Acc 0.9777426493167877 Perturbed Loss 0.0802089300751686
Loss 0.08478729199618101 Acc 0.9740032875537872 Perturbed Loss 0.08697812784463167
Loss 0.07700825024396181 Acc 0.9799898493289948 Perturbed Loss 0.07861371107399463
Loss 0.0790920828655362 Acc 0.9779108691215516 Perturbed Loss 0.08110130134969949
Loss 0.07000237079337239 Acc 0.9777000832557678 Perturbed Loss 0.07156623667106032
Epoch 5.0 val loss 0.05816129222512245 val acc 0.9789936542510986
Loss 0.07504893902689219 Acc 0.9781938230991364 Perturbed Loss 0.0769892843440175
Loss 0.07442681616172195 Acc 0.9794492852687836 Perturbed Loss 0.07632568309083582
Loss 0.07074170731008053 Acc 0.9793284356594085 Perturbed Loss 0.07301528483629227
Loss 0.08194977715611458 Acc 0.9754941213130951 Perturbed Loss 0.08353952083736658
Loss 0.07410948758944869 Acc 0.981926884651184 Perturbed Loss 0.0758400365896523
Loss 0.07704639052972198 Acc 0.976472989320755 Perturbed Loss 0.07885219715535641
Loss 0.07343964952975511 Acc 0.975189917087555 Perturbed Loss 0.07500269100069999
Loss 0.07270320151001215 Acc 0.9815926289558411 Perturbed Loss 0.074293951690197
Loss 0.07055265489965677 Acc 0.9789468908309936 Perturbed Loss 0.07261921003460885
Loss 0.08499893402680754 Acc 0.9764235591888428 Perturbed Loss 0.08728027371689677
Loss 0.07725925823673606 Acc 0.9777314579486847 Perturbed Loss 0.07896353468298913
Loss 0.07541651705279946 Acc 0.978700852394104 Perturbed Loss 0.07706074910238385
Loss 0.07467525128275156 Acc 0.9769805216789246 Perturbed Loss 0.07627738061361015
Loss 0.07798757165670395 Acc 0.9807704079151154 Perturbed Loss 0.08064784657210111
Loss 0.07898714620620012 Acc 0.9736598742008209 Perturbed Loss 0.08125502411276102
Epoch 6.0 val loss 0.05912187695503235 val acc 0.9787865877151489
Loss 0.0859549119696021 Acc 0.9756175410747528 Perturbed Loss 0.08884609939530491
Loss 0.08983193377032876 Acc 0.9755004334449768 Perturbed Loss 0.0928439155779779
Loss 0.07296107165515422 Acc 0.9772908651828766 Perturbed Loss 0.07437238298356533
Loss 0.06691013824194669 Acc 0.9811640024185181 Perturbed Loss 0.06986361846327782
Loss 0.07574825178831816 Acc 0.9760128140449524 Perturbed Loss 0.07802153335884214
Loss 0.07625386897474527 Acc 0.9780473518371582 Perturbed Loss 0.07784266715869308
Loss 0.08146507821977139 Acc 0.9752666246891022 Perturbed Loss 0.08388355795294046
Loss 0.06536379754543305 Acc 0.9805796802043915 Perturbed Loss 0.06706904690712691
Loss 0.07500713843852282 Acc 0.9773748409748078 Perturbed Loss 0.07651988245546817
Loss 0.0787754950299859 Acc 0.9785702979564667 Perturbed Loss 0.08058470886200667
Loss 0.07593165628612042 Acc 0.9812079513072968 Perturbed Loss 0.07771119564771652
Loss 0.06930259892717004 Acc 0.9792693591117859 Perturbed Loss 0.07066291183233261
Loss 0.0669719410687685 Acc 0.9786194717884064 Perturbed Loss 0.06880215335637331
Loss 0.0681738044321537 Acc 0.9809966170787812 Perturbed Loss 0.07010426621884108
Loss 0.0783077547699213 Acc 0.9773914647102356 Perturbed Loss 0.08069344386458396
Epoch 7.0 val loss 0.05801382660865784 val acc 0.9788498282432556
Loss 0.06783173434436321 Acc 0.9773266243934632 Perturbed Loss 0.06951034251600503
Loss 0.07041948670521378 Acc 0.9732913386821747 Perturbed Loss 0.07219363413751126
Loss 0.06447583397850394 Acc 0.9778740966320038 Perturbed Loss 0.066359799541533
Loss 0.07166861668229103 Acc 0.9766660392284393 Perturbed Loss 0.07321190156042576
Loss 0.06927756985649466 Acc 0.9789488327503204 Perturbed Loss 0.0707246682420373
Loss 0.07216620395891368 Acc 0.9776236569881439 Perturbed Loss 0.07425292250700295
Loss 0.06555890012532473 Acc 0.9774738717079162 Perturbed Loss 0.06738053254783154
Loss 0.06532923407852649 Acc 0.9785400235652923 Perturbed Loss 0.06686322338879108
Loss 0.07159890159964562 Acc 0.9753174138069153 Perturbed Loss 0.0737884782999754
Loss 0.06836033523082734 Acc 0.9769504165649414 Perturbed Loss 0.07004444863647223
Loss 0.07336718756705522 Acc 0.9791601502895355 Perturbed Loss 0.07528782859444619
Loss 0.07216678181663155 Acc 0.9783824336528778 Perturbed Loss 0.07382856210693717
Loss 0.06775191191583872 Acc 0.978504991531372 Perturbed Loss 0.06997728284448385
Loss 0.07804124753922224 Acc 0.9783191621303559 Perturbed Loss 0.08037243409082294
Loss 0.07444748979061842 Acc 0.9807981491088867 Perturbed Loss 0.07588137298822403
Epoch 8.0 val loss 0.058026429265737534 val acc 0.9785766005516052
Loss 0.06977695010602475 Acc 0.9754882252216339 Perturbed Loss 0.07186678115278483
Loss 0.0698383341357112 Acc 0.9780200457572937 Perturbed Loss 0.07254739053547382
Loss 0.07366559429094195 Acc 0.9773476672172546 Perturbed Loss 0.0755665860325098
Loss 0.06408151946961879 Acc 0.9776825737953186 Perturbed Loss 0.0661730357632041
Loss 0.07482138264924287 Acc 0.977208845615387 Perturbed Loss 0.0768157658725977
Loss 0.06981498129665852 Acc 0.9766912674903869 Perturbed Loss 0.07180344451218844
Loss 0.06074340645223856 Acc 0.9804571163654328 Perturbed Loss 0.06221802083775401
Loss 0.07737390786409377 Acc 0.9798088347911835 Perturbed Loss 0.07917721889913082
Loss 0.06417045336216688 Acc 0.9787107753753662 Perturbed Loss 0.06674770016223192
Loss 0.06685570821166038 Acc 0.9819187557697296 Perturbed Loss 0.06867882300168276
Loss 0.06940822776407003 Acc 0.9804872095584869 Perturbed Loss 0.07179030474275351
Loss 0.07148297289386392 Acc 0.9780861473083496 Perturbed Loss 0.07301841374486685
Loss 0.07183558322489261 Acc 0.9785466980934143 Perturbed Loss 0.07326140094548464
Loss 0.08518049255013466 Acc 0.9752422022819519 Perturbed Loss 0.0874510377831757
Loss 0.07475199941545725 Acc 0.9770920753479004 Perturbed Loss 0.07620097499340772
Epoch 9.0 val loss 0.055296704173088074 val acc 0.979544460773468
Loss 0.07336461739614605 Acc 0.9824647510051727 Perturbed Loss 0.07481149151921272
Loss 0.07115438353270293 Acc 0.9761011624336242 Perturbed Loss 0.07280422307550907
Loss 0.06441615421324969 Acc 0.9811365711688995 Perturbed Loss 0.06579329447820782
Loss 0.07617225285619497 Acc 0.975135726928711 Perturbed Loss 0.07815430376678706
Loss 0.0627071188390255 Acc 0.982336413860321 Perturbed Loss 0.06513379728421569
Loss 0.06626238247379661 Acc 0.9790079545974731 Perturbed Loss 0.06800034956075252
Loss 0.0691112768650055 Acc 0.9783078587055206 Perturbed Loss 0.07084974501281976
Loss 0.06242555919103324 Acc 0.9828201496601104 Perturbed Loss 0.06373011497780681
Loss 0.06313138958066702 Acc 0.9788411140441895 Perturbed Loss 0.06459325656294823
Loss 0.06748605078086257 Acc 0.9773123252391815 Perturbed Loss 0.06925424035638571
Loss 0.06655063334852457 Acc 0.9777712953090668 Perturbed Loss 0.06804757360368967
Loss 0.0798401327431202 Acc 0.976892991065979 Perturbed Loss 0.08174486994743348
Loss 0.06754975681193173 Acc 0.9796079266071319 Perturbed Loss 0.06906993098556996
Loss 0.06680049970746041 Acc 0.9770887219905853 Perturbed Loss 0.06876502361148595
Loss 0.06493249282240868 Acc 0.9780631005764008 Perturbed Loss 0.06644611041992902
Epoch 10.0 val loss 0.05725483596324921 val acc 0.9790439009666443
Loss 0.06797516016289591 Acc 0.9801016533374787 Perturbed Loss 0.07043170211836695
Loss 0.06810633603483439 Acc 0.9808525443077087 Perturbed Loss 0.06994024550542235
Loss 0.0677396103553474 Acc 0.9797905910015107 Perturbed Loss 0.06906717542558909
Loss 0.060657036527991294 Acc 0.9790978419780731 Perturbed Loss 0.06195668686181307
Loss 0.07046860260888935 Acc 0.9778775107860566 Perturbed Loss 0.0724315613694489
Loss 0.06373399242758751 Acc 0.978817949295044 Perturbed Loss 0.06523258056491614
Loss 0.06993453152477741 Acc 0.9789500486850738 Perturbed Loss 0.07253448251634836
Loss 0.07647936165332794 Acc 0.9776997470855713 Perturbed Loss 0.07797264333814383
Loss 0.06350201576948165 Acc 0.9797939598560333 Perturbed Loss 0.064869913905859
Loss 0.06326999325305223 Acc 0.9818577682971954 Perturbed Loss 0.0644671255722642
Loss 0.06860069688409567 Acc 0.9768528008460998 Perturbed Loss 0.0701402099430561
Loss 0.07008375246077776 Acc 0.9802065408229828 Perturbed Loss 0.07170453485101462
Loss 0.07835822720080614 Acc 0.9769108498096466 Perturbed Loss 0.07993380360305309
Loss 0.06549845254048706 Acc 0.9814456284046174 Perturbed Loss 0.06693612212315202
Loss 0.06234485495835543 Acc 0.9805682563781738 Perturbed Loss 0.0633592801913619
Epoch 11.0 val loss 0.05575437843799591 val acc 0.9789722561836243
Loss 0.07722835402935743 Acc 0.9786991822719574 Perturbed Loss 0.07860646683722734
Loss 0.07056740526109934 Acc 0.9770398342609405 Perturbed Loss 0.0721917947754264
Loss 0.06953563641756773 Acc 0.9819919407367707 Perturbed Loss 0.07148311249911785
Loss 0.06269296482205391 Acc 0.9801119828224182 Perturbed Loss 0.06415925990790129
Loss 0.06422720335423947 Acc 0.9843112087249756 Perturbed Loss 0.06574174474924803
Loss 0.0616851413063705 Acc 0.9798237824440003 Perturbed Loss 0.06394891485571862
Loss 0.06630747238174081 Acc 0.9797183203697205 Perturbed Loss 0.06761250777170062
Loss 0.06384765917435288 Acc 0.9801392018795013 Perturbed Loss 0.06535607116296888
Loss 0.0631185271218419 Acc 0.978253687620163 Perturbed Loss 0.06436509769409895
Loss 0.06638583142310381 Acc 0.9816674423217774 Perturbed Loss 0.06816738843917847
Loss 0.07462848695926368 Acc 0.9788578736782074 Perturbed Loss 0.07676748210564256
Loss 0.06385006869211793 Acc 0.9767800390720367 Perturbed Loss 0.06495930353179574
Loss 0.0759435470495373 Acc 0.9809896600246429 Perturbed Loss 0.07755753887817264
Loss 0.06428975373506546 Acc 0.9804585802555085 Perturbed Loss 0.06614631947129965
Loss 0.06892668120563031 Acc 0.9747246789932251 Perturbed Loss 0.07079563252627849
Epoch 12.0 val loss 0.05521102249622345 val acc 0.9793750643730164
Loss 0.0695197637192905 Acc 0.978380389213562 Perturbed Loss 0.07190612744539976
Loss 0.07805574540048837 Acc 0.9772455179691315 Perturbed Loss 0.07981920707970858
Loss 0.07611554130911827 Acc 0.9778002333641053 Perturbed Loss 0.07748019278049469
Loss 0.0653135009855032 Acc 0.9823112511634826 Perturbed Loss 0.06647514507174491
Loss 0.062285422049462795 Acc 0.979570345878601 Perturbed Loss 0.06356031123548746
Loss 0.07037141602486371 Acc 0.9811944580078125 Perturbed Loss 0.07155378833413124
Loss 0.0701756601035595 Acc 0.9758474826812744 Perturbed Loss 0.07147309441119433
Loss 0.06949207433499396 Acc 0.9776380741596222 Perturbed Loss 0.0716745735425502
Loss 0.07162274183705448 Acc 0.9769120335578918 Perturbed Loss 0.07363625571131706
Loss 0.06953698268160224 Acc 0.9791388130187988 Perturbed Loss 0.07138977879658341
Loss 0.0731396098434925 Acc 0.9784095680713654 Perturbed Loss 0.07500172518193722
Loss 0.0759583369269967 Acc 0.9810050821304321 Perturbed Loss 0.07779450543224811
Loss 0.06355990318581461 Acc 0.9780624973773956 Perturbed Loss 0.0652641050890088
Loss 0.059841130338609216 Acc 0.9806304752826691 Perturbed Loss 0.06197573680430651
Loss 0.06931612066924572 Acc 0.9818860983848572 Perturbed Loss 0.07079341690987348
Epoch 13.0 val loss 0.058010123670101166 val acc 0.979443371295929
Loss 0.06662147564813495 Acc 0.9796884059906006 Perturbed Loss 0.06792523240670562
Loss 0.07585143901407719 Acc 0.9768118238449097 Perturbed Loss 0.07759949829429388
Loss 0.06770561559125782 Acc 0.9799556291103363 Perturbed Loss 0.06869877124205231
Loss 0.07227711664512754 Acc 0.9775859498977661 Perturbed Loss 0.07377879783511161
Loss 0.07091011423617602 Acc 0.978386138677597 Perturbed Loss 0.07261257342994214
Loss 0.06064526200294495 Acc 0.9815256547927856 Perturbed Loss 0.061907236184924844
Loss 0.06417201064527035 Acc 0.9815373957157135 Perturbed Loss 0.06544681247323751
Loss 0.05988791145384312 Acc 0.9804023218154907 Perturbed Loss 0.061659491378813984
Loss 0.06379970479756594 Acc 0.9816071653366089 Perturbed Loss 0.06494662377983332
Loss 0.06689617820084096 Acc 0.974288821220398 Perturbed Loss 0.06924736347049475
Loss 0.06820560358464718 Acc 0.979272027015686 Perturbed Loss 0.07065743044018745
Loss 0.06807049762457609 Acc 0.9759126269817352 Perturbed Loss 0.0695532214641571
Loss 0.07030101377516985 Acc 0.9795566940307617 Perturbed Loss 0.0715736641921103
Loss 0.07413086863234639 Acc 0.9737380790710449 Perturbed Loss 0.07566987048834563
Loss 0.06584486721083521 Acc 0.9802225530147552 Perturbed Loss 0.06725259356200695
Epoch 14.0 val loss 0.05527813360095024 val acc 0.9794383645057678
Loss 0.06910851537249982 Acc 0.9759883248806 Perturbed Loss 0.07038893127813935
Loss 0.07036760337650776 Acc 0.9796599328517914 Perturbed Loss 0.07211432810872793
Loss 0.07643153635784984 Acc 0.9742640101909638 Perturbed Loss 0.0780457304418087
Loss 0.07032159689813852 Acc 0.979046242237091 Perturbed Loss 0.07231996906921268
Loss 0.05584153404459357 Acc 0.981502605676651 Perturbed Loss 0.05683267284184694
Loss 0.05912317461334169 Acc 0.9816196060180664 Perturbed Loss 0.06098138544242829
Loss 0.06555730545893311 Acc 0.9800056874752044 Perturbed Loss 0.06679825286380947
Loss 0.08755185883492231 Acc 0.9789074850082398 Perturbed Loss 0.09016512472182513
Loss 0.07268136654049158 Acc 0.9799078404903412 Perturbed Loss 0.07453982587903737
Loss 0.06875416662544012 Acc 0.9808499073982239 Perturbed Loss 0.07026460649445652
Loss 0.06335889055393636 Acc 0.9835890376567841 Perturbed Loss 0.06465395585633814
Loss 0.06750409938395023 Acc 0.9782099521160126 Perturbed Loss 0.06925493877381086
Loss 0.062492816597223284 Acc 0.9814463412761688 Perturbed Loss 0.06459824785590172
Loss 0.06278910346329213 Acc 0.9815366721153259 Perturbed Loss 0.06429635599255562
Loss 0.07885177616029977 Acc 0.9780393922328949 Perturbed Loss 0.08069783836603164
Epoch 15.0 val loss 0.05536423623561859 val acc 0.9794489145278931
Loss 0.0696507934294641 Acc 0.9775441527366638 Perturbed Loss 0.07140321891754865
Loss 0.06937564682215452 Acc 0.9771635746955871 Perturbed Loss 0.07103300146758557
Loss 0.072782629635185 Acc 0.9803553199768067 Perturbed Loss 0.07449057642370463
Loss 0.06398358769714832 Acc 0.9802574419975281 Perturbed Loss 0.06563178207725287
Loss 0.0639837053604424 Acc 0.9802995443344116 Perturbed Loss 0.06543892446905375
Loss 0.06891503933817149 Acc 0.9808739757537842 Perturbed Loss 0.07001683346927166
Loss 0.07288042657077312 Acc 0.9809403228759765 Perturbed Loss 0.07475476462393998
Loss 0.07309765681624412 Acc 0.9791746473312378 Perturbed Loss 0.07469904355704785
Loss 0.06250885125249624 Acc 0.9808084285259246 Perturbed Loss 0.06425518658012151
Loss 0.056485944762825965 Acc 0.9843007481098175 Perturbed Loss 0.057862660717219114
Loss 0.06711731046438217 Acc 0.9788594841957092 Perturbed Loss 0.06858792942017317
Loss 0.06495141953229905 Acc 0.9816351640224457 Perturbed Loss 0.06639209167100489
Loss 0.06099464911967516 Acc 0.9808652329444886 Perturbed Loss 0.0630718450807035
Loss 0.06831084854900837 Acc 0.9816213548183441 Perturbed Loss 0.06982465837150813
Loss 0.060097331050783395 Acc 0.9838348770141602 Perturbed Loss 0.06163406047970057
Epoch 16.0 val loss 0.05477415397763252 val acc 0.9797264337539673
Loss 0.06955922573804856 Acc 0.9792466759681702 Perturbed Loss 0.07160469304770231
Loss 0.07047544315457344 Acc 0.9821844339370728 Perturbed Loss 0.07207520961761475
Loss 0.06117983229458332 Acc 0.9794683587551117 Perturbed Loss 0.06258478999137879
Loss 0.06909831130877137 Acc 0.9795678114891052 Perturbed Loss 0.07035199578851462
Loss 0.06180522657930851 Acc 0.9805209505558014 Perturbed Loss 0.06340449504554271
Loss 0.057025679461658 Acc 0.9803167498111724 Perturbed Loss 0.05829418186098337
Loss 0.06860531028360128 Acc 0.9768058478832244 Perturbed Loss 0.07055938955396414
Loss 0.0633577492646873 Acc 0.9813330769538879 Perturbed Loss 0.06446308474987746
Loss 0.05403907837346196 Acc 0.9832189214229584 Perturbed Loss 0.055362949818372725
Loss 0.07651476286351681 Acc 0.9779191994667054 Perturbed Loss 0.07811416670680046
Loss 0.06365904537960887 Acc 0.9792377746105194 Perturbed Loss 0.06492722840979695
Loss 0.06879622653126717 Acc 0.9782715058326721 Perturbed Loss 0.07015760671347379
Loss 0.06349264498800039 Acc 0.9756098926067353 Perturbed Loss 0.0646490022726357
Loss 0.06543820537626743 Acc 0.9792147350311279 Perturbed Loss 0.06741585295647383
Loss 0.06453972848132253 Acc 0.9822076690196991 Perturbed Loss 0.06607808412984013
Epoch 17.0 val loss 0.055662088096141815 val acc 0.9799325466156006
Loss 0.06660411678254605 Acc 0.9802438056468964 Perturbed Loss 0.0685763630270958
Loss 0.06946411799639464 Acc 0.9803345096111298 Perturbed Loss 0.07111366976052523
Loss 0.0658615998737514 Acc 0.977363168001175 Perturbed Loss 0.06704402910545468
Loss 0.06293937059119344 Acc 0.9821414625644684 Perturbed Loss 0.06407392222434283
Loss 0.06493774447590113 Acc 0.9816804242134094 Perturbed Loss 0.06650712946429849
Loss 0.054060063567012547 Acc 0.9826332569122315 Perturbed Loss 0.05519025752320886
Loss 0.06140179697424173 Acc 0.9792618680000306 Perturbed Loss 0.06249650333076715
Loss 0.05846330277621746 Acc 0.9813520228862762 Perturbed Loss 0.05984367955476046
Loss 0.06776882041245699 Acc 0.9796380352973938 Perturbed Loss 0.07021658202633262
Loss 0.06404257453978061 Acc 0.9786906707286834 Perturbed Loss 0.06588686931878328
Loss 0.06141887206584215 Acc 0.9794211375713349 Perturbed Loss 0.06267098098993301
Loss 0.07370791755616665 Acc 0.9758354020118714 Perturbed Loss 0.07512481179088354
Loss 0.06433970345184208 Acc 0.9791443574428559 Perturbed Loss 0.06650012275204062
Loss 0.07918782517313958 Acc 0.9783724546432495 Perturbed Loss 0.08120189998298884
Loss 0.06068546215072274 Acc 0.9784239065647126 Perturbed Loss 0.06192107766866684
Epoch 18.0 val loss 0.05468744784593582 val acc 0.9800714254379272
Loss 0.06606892913579941 Acc 0.9770821702480316 Perturbed Loss 0.06734084360301494
Loss 0.06965252770110965 Acc 0.9787985372543335 Perturbed Loss 0.0709236910380423
Loss 0.06798402801156044 Acc 0.9793392074108124 Perturbed Loss 0.06895921308547258
Loss 0.05433963533490896 Acc 0.9785558664798737 Perturbed Loss 0.05565719254314899
Loss 0.06057435356080532 Acc 0.9820229363441467 Perturbed Loss 0.06174590867012739
Loss 0.06302052212879061 Acc 0.9778389978408814 Perturbed Loss 0.06408921536058187
Loss 0.08345367584377528 Acc 0.9759316444396973 Perturbed Loss 0.08503591880202294
Loss 0.06448258098214865 Acc 0.9794207310676575 Perturbed Loss 0.06586715614423155
Loss 0.06085441576316953 Acc 0.9807745158672333 Perturbed Loss 0.0619333753362298
Loss 0.06154589954763651 Acc 0.9797377097606659 Perturbed Loss 0.06300934873521329
Loss 0.06854032400995493 Acc 0.9794945418834686 Perturbed Loss 0.07027037099003791
Loss 0.06107670694589615 Acc 0.9792355442047119 Perturbed Loss 0.061950246803462505
Loss 0.06607098340988159 Acc 0.9797520971298218 Perturbed Loss 0.06717588175088167
Loss 0.07688765466213227 Acc 0.9797325217723847 Perturbed Loss 0.07859568703919649
Loss 0.059884924441576004 Acc 0.982777841091156 Perturbed Loss 0.0610608995705843
Epoch 19.0 val loss 0.05477151274681091 val acc 0.979962170124054
[05:33:25] INFO     `Trainer.fit` stopped: `max_epochs=20` reached.                                                                                                                         rank_zero.py:53
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750/750 0:03:45 • 0:00:00 3.36it/s train/loss: 0.06 val_loss: 0.055
[05:33:28] INFO     Created a temporary directory at /tmp/tmpxekf0sqz                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmpxekf0sqz/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
           INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
           INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
           INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
           INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
[05:33:29] INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.0006, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.002, adaptive=False)
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.0881276099011302 Acc 0.9656948637962341 Perturbed Loss 0.08924584478139877
[05:34:00] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.07773928131908178 Acc 0.9715071439743042 Perturbed Loss 0.07844642639160156
Loss 0.08747982650995255 Acc 0.9770645999908447 Perturbed Loss 0.08821192676201463
Loss 0.0840492291841656 Acc 0.9738331818580628 Perturbed Loss 0.08449617324396969
Loss 0.08020166419446469 Acc 0.9759859371185303 Perturbed Loss 0.0807817560993135
Loss 0.09980683837085963 Acc 0.9651575839519501 Perturbed Loss 0.10069042585790157
Loss 0.08504842020571232 Acc 0.9696893739700317 Perturbed Loss 0.08595782428979874
Loss 0.08834931882098317 Acc 0.9759892094135284 Perturbed Loss 0.08886728655546904
Loss 0.0909960464388132 Acc 0.9727477729320526 Perturbed Loss 0.09153721027076245
Loss 0.08907555997371673 Acc 0.9700109243392945 Perturbed Loss 0.08972022535279393
Loss 0.07696748159825802 Acc 0.9772279608249664 Perturbed Loss 0.07744114447385073
Loss 0.0857098489254713 Acc 0.9769693899154663 Perturbed Loss 0.08616410434246063
Loss 0.0792550202831626 Acc 0.9779337918758393 Perturbed Loss 0.0798121671192348
Loss 0.06929434061050416 Acc 0.982904099225998 Perturbed Loss 0.06972394194453954
Loss 0.07947394639253616 Acc 0.9757016777992249 Perturbed Loss 0.08006911013275385
Epoch 0.0 val loss 0.05821213871240616 val acc 0.9785907864570618
Loss 0.08308615300804377 Acc 0.9729771745204926 Perturbed Loss 0.08385864775627852
Loss 0.08019593684002757 Acc 0.9729209744930267 Perturbed Loss 0.08058410082012415
Loss 0.08186194062232971 Acc 0.9666257607936859 Perturbed Loss 0.08245225619524717
Loss 0.07798864336684347 Acc 0.9741019690036774 Perturbed Loss 0.07840647475793958
Loss 0.08368639210239052 Acc 0.9754681813716889 Perturbed Loss 0.08413415843620896
Loss 0.07875014897435903 Acc 0.976779761314392 Perturbed Loss 0.07929259514436125
Loss 0.08772892102599145 Acc 0.9756087839603425 Perturbed Loss 0.08813360299915075
Loss 0.07396859537810087 Acc 0.9788124001026154 Perturbed Loss 0.0745685038715601
Loss 0.08181392163038254 Acc 0.9770454287528991 Perturbed Loss 0.08247779551893472
Loss 0.08034664427861571 Acc 0.9776754605770112 Perturbed Loss 0.08084947254508734
Loss 0.0830832721106708 Acc 0.9684175741672516 Perturbed Loss 0.08373110124841332
Loss 0.09226854901760817 Acc 0.9712120425701142 Perturbed Loss 0.092921948954463
Loss 0.08063338667154313 Acc 0.9790631067752839 Perturbed Loss 0.0811163406074047
Loss 0.10492333739995957 Acc 0.9704643332958222 Perturbed Loss 0.10600454155355692
Loss 0.0860211580246687 Acc 0.974813904762268 Perturbed Loss 0.08669394768774509
Epoch 1.0 val loss 0.05980069562792778 val acc 0.9786224961280823
Loss 0.07662971872836351 Acc 0.9738616931438446 Perturbed Loss 0.07702897844836115
Loss 0.08345448713749647 Acc 0.978344818353653 Perturbed Loss 0.0838740662485361
Loss 0.07911730751395225 Acc 0.977362904548645 Perturbed Loss 0.07962214522063732
Loss 0.07425115982070565 Acc 0.9815327072143555 Perturbed Loss 0.07485424058511853
Loss 0.07852363027632236 Acc 0.9794693899154663 Perturbed Loss 0.07914900273084641
Loss 0.07107414335012435 Acc 0.9754003858566285 Perturbed Loss 0.07151678953319789
Loss 0.07852586405351758 Acc 0.9799991416931152 Perturbed Loss 0.07901163067668676
Loss 0.07603350687772036 Acc 0.9809608769416809 Perturbed Loss 0.0765403526648879
Loss 0.07843690004199744 Acc 0.9769388592243194 Perturbed Loss 0.07896641653031111
Loss 0.07878076493740081 Acc 0.9774142217636108 Perturbed Loss 0.07928201779723168
Loss 0.07778603099286556 Acc 0.9788421070575715 Perturbed Loss 0.07839943941682577
Loss 0.08206062782555819 Acc 0.9744328916072845 Perturbed Loss 0.08249167200177908
Loss 0.07887555453926325 Acc 0.9725891411304474 Perturbed Loss 0.07955098781734705
Loss 0.10318713802844286 Acc 0.9669000720977783 Perturbed Loss 0.1039044439047575
Loss 0.08530614867806435 Acc 0.9763927471637726 Perturbed Loss 0.08591026224195958
Epoch 2.0 val loss 0.05957576259970665 val acc 0.9788573384284973
Loss 0.07833294130861759 Acc 0.9729015028476715 Perturbed Loss 0.07890996683388948
Loss 0.07255254734307527 Acc 0.9767153334617614 Perturbed Loss 0.07313661895692349
Loss 0.07347757369279861 Acc 0.9795821118354797 Perturbed Loss 0.07417637020349503
Loss 0.07685413859784603 Acc 0.980143438577652 Perturbed Loss 0.07726131975650788
Loss 0.0942291446402669 Acc 0.9776526403427124 Perturbed Loss 0.09491399075835943
Loss 0.08338271496817469 Acc 0.9765543377399445 Perturbed Loss 0.0837387559004128
Loss 0.07191393345594406 Acc 0.9814627277851105 Perturbed Loss 0.07251384317874908
Loss 0.08150384943932294 Acc 0.9763677692413331 Perturbed Loss 0.0819163203239441
Loss 0.08713269475847482 Acc 0.9779551720619202 Perturbed Loss 0.08754524920135737
Loss 0.07708076121285558 Acc 0.9763836622238159 Perturbed Loss 0.07732808426022529
Loss 0.06562304733321071 Acc 0.9781918287277221 Perturbed Loss 0.0659584653005004
Loss 0.08687028914690018 Acc 0.9731247925758362 Perturbed Loss 0.08735289968550206
Loss 0.09292430628091097 Acc 0.9743733918666839 Perturbed Loss 0.09346974488347769
Loss 0.07764264408499003 Acc 0.9688254499435425 Perturbed Loss 0.07809315200895071
Loss 0.0797682711482048 Acc 0.9746599125862122 Perturbed Loss 0.0801787380874157
Epoch 3.0 val loss 0.059837911278009415 val acc 0.9787904620170593
Loss 0.0685463518090546 Acc 0.9803940117359161 Perturbed Loss 0.06904556281864643
Loss 0.08054982502013446 Acc 0.9819202840328216 Perturbed Loss 0.08100054271519185
Loss 0.06794708833098412 Acc 0.9741706025600433 Perturbed Loss 0.06835482314229012
Loss 0.08752321917563677 Acc 0.9782883501052857 Perturbed Loss 0.08811293406412006
Loss 0.07575267042964696 Acc 0.9748887610435486 Perturbed Loss 0.0761284457333386
Loss 0.07592217335477472 Acc 0.9775939083099365 Perturbed Loss 0.07633513994514943
Loss 0.06643407717347145 Acc 0.9788340127468109 Perturbed Loss 0.06680867966264487
Loss 0.07144865591078997 Acc 0.978403822183609 Perturbed Loss 0.07171911742538213
Loss 0.0719467693567276 Acc 0.9761778914928436 Perturbed Loss 0.07241022491827608
Loss 0.06720427226275205 Acc 0.9776074743270874 Perturbed Loss 0.06770767498761415
Loss 0.07736453041434288 Acc 0.979194804430008 Perturbed Loss 0.07798187628388405
Loss 0.08164528036490083 Acc 0.9746293187141418 Perturbed Loss 0.08208067312836648
Loss 0.07729348067194224 Acc 0.9759743237495422 Perturbed Loss 0.07772240992635489
Loss 0.07524031300097704 Acc 0.9796652531623841 Perturbed Loss 0.07566048860549927
Loss 0.08179255407303572 Acc 0.9798973047733307 Perturbed Loss 0.08244854072108865
Epoch 4.0 val loss 0.06152354180812836 val acc 0.9786459803581238
Loss 0.0789385898411274 Acc 0.9765928971767426 Perturbed Loss 0.07946389254182577
Loss 0.0805469162762165 Acc 0.9780292940139771 Perturbed Loss 0.0809567854180932
Loss 0.08523131527006626 Acc 0.9765922904014588 Perturbed Loss 0.0857208863645792
Loss 0.08391402117908 Acc 0.9729026901721954 Perturbed Loss 0.08437937032431364
Loss 0.07434652600437403 Acc 0.9763167500495911 Perturbed Loss 0.07482331950217486
Loss 0.08789861034601927 Acc 0.9743141186237335 Perturbed Loss 0.08853181317448616
Loss 0.07267459023743868 Acc 0.9801356208324432 Perturbed Loss 0.07308688160032034
Loss 0.06940730307251215 Acc 0.9770283007621765 Perturbed Loss 0.0697243245691061
Loss 0.075453663431108 Acc 0.9788755714893341 Perturbed Loss 0.07588043086230754
Loss 0.07171462923288345 Acc 0.9773312878608703 Perturbed Loss 0.07207217868417501
Loss 0.07788564376533032 Acc 0.977148928642273 Perturbed Loss 0.07836817476898432
Loss 0.083333073630929 Acc 0.9732460367679596 Perturbed Loss 0.08385668877512216
Loss 0.07962394338101149 Acc 0.9786519396305084 Perturbed Loss 0.07999525930732489
Loss 0.07343161448836327 Acc 0.9785781228542327 Perturbed Loss 0.07394944187253713
Loss 0.07323697755113244 Acc 0.9771501326560974 Perturbed Loss 0.07364994117990137
Epoch 5.0 val loss 0.058319274336099625 val acc 0.9789649248123169
Loss 0.07300656225532293 Acc 0.9782985031604767 Perturbed Loss 0.07324582397937775
Loss 0.07324645154178143 Acc 0.9789583778381348 Perturbed Loss 0.07359980452805757
Loss 0.067625537738204 Acc 0.9793225491046905 Perturbed Loss 0.06808947641402482
Loss 0.08307720124721527 Acc 0.9751825058460235 Perturbed Loss 0.08358737029135227
Loss 0.07544359896332026 Acc 0.9819003081321717 Perturbed Loss 0.07579619413241744
Loss 0.07919076979160308 Acc 0.976085330247879 Perturbed Loss 0.07966180903837085
Loss 0.07257591016590595 Acc 0.9755445897579194 Perturbed Loss 0.07291403833776712
Loss 0.07203668184578418 Acc 0.9812021827697754 Perturbed Loss 0.07235496252775192
Loss 0.06938274215906859 Acc 0.9779120671749115 Perturbed Loss 0.06971255451440811
Loss 0.08139611201360822 Acc 0.9757653403282166 Perturbed Loss 0.08177548181265593
Loss 0.07526477966457605 Acc 0.9785463345050812 Perturbed Loss 0.07555835243314504
Loss 0.07309430506080389 Acc 0.9787963104248046 Perturbed Loss 0.07335823171772063
Loss 0.07535814564675093 Acc 0.9766237962245942 Perturbed Loss 0.07581242976710201
Loss 0.07808872524648905 Acc 0.9812639582157135 Perturbed Loss 0.07856017753481864
Loss 0.07595211412757635 Acc 0.9750005662441253 Perturbed Loss 0.07630762234330177
Epoch 6.0 val loss 0.05921238288283348 val acc 0.9789441227912903
Loss 0.0845789978839457 Acc 0.9756398522853851 Perturbed Loss 0.0851582514308393
Loss 0.0852001014444977 Acc 0.9767491853237152 Perturbed Loss 0.08568837691098452
Loss 0.07327729400247335 Acc 0.9778025770187377 Perturbed Loss 0.07366753298789262
Loss 0.06488403448835016 Acc 0.9817069435119629 Perturbed Loss 0.065317148193717
Loss 0.070275982003659 Acc 0.9778790938854217 Perturbed Loss 0.07058269532397389
Loss 0.07876779936254025 Acc 0.9777888894081116 Perturbed Loss 0.07914501927793026
Loss 0.07309780839830637 Acc 0.9761057031154633 Perturbed Loss 0.07317311447113753
Loss 0.0639091351814568 Acc 0.9808202612400055 Perturbed Loss 0.0642325982451439
Loss 0.07385997384786606 Acc 0.9778912806510925 Perturbed Loss 0.07417725432664156
Loss 0.0770270836353302 Acc 0.978707983493805 Perturbed Loss 0.07732074331492185
Loss 0.0774064714089036 Acc 0.9811415016651154 Perturbed Loss 0.07789098877459764
Loss 0.0676076272316277 Acc 0.9794075465202332 Perturbed Loss 0.06793384067714214
Loss 0.06787565346807241 Acc 0.977719429731369 Perturbed Loss 0.06833260968327522
Loss 0.0681296344846487 Acc 0.9802935445308685 Perturbed Loss 0.06848693326115608
Loss 0.07762323133647442 Acc 0.9775505101680756 Perturbed Loss 0.07792970642447472
Epoch 7.0 val loss 0.05829237028956413 val acc 0.9787158370018005
Loss 0.06995598569512368 Acc 0.9768127512931823 Perturbed Loss 0.07025212161242962
Loss 0.07054273780435323 Acc 0.973494803905487 Perturbed Loss 0.07085299382917583
Loss 0.06430503593757748 Acc 0.9780154383182526 Perturbed Loss 0.06463709009811282
Loss 0.07771533090621233 Acc 0.9762366127967834 Perturbed Loss 0.07813110597431659
Loss 0.0707921715080738 Acc 0.9795281779766083 Perturbed Loss 0.07114669339731336
Loss 0.07242424566298723 Acc 0.9779753279685974 Perturbed Loss 0.0727141847461462
Loss 0.0643363082408905 Acc 0.9786555707454682 Perturbed Loss 0.06465864587575197
Loss 0.06853883393108845 Acc 0.9786792016029358 Perturbed Loss 0.06885934989899396
Loss 0.0706855109333992 Acc 0.9759274494647979 Perturbed Loss 0.07106162941083312
Loss 0.06806253429502249 Acc 0.9763762474060058 Perturbed Loss 0.06846909854561091
Loss 0.07519512310624123 Acc 0.9786073613166809 Perturbed Loss 0.0755144465714693
Loss 0.07051768217235804 Acc 0.97877454996109 Perturbed Loss 0.0708090359903872
Loss 0.06800858590751886 Acc 0.9788725411891938 Perturbed Loss 0.06847437229007483
Loss 0.0772706312686205 Acc 0.977107800245285 Perturbed Loss 0.07771204246208072
Loss 0.07070451196283102 Acc 0.9816178798675537 Perturbed Loss 0.07093767870217561
Epoch 8.0 val loss 0.05829405039548874 val acc 0.9790879487991333
Loss 0.0723051567003131 Acc 0.9758119571208954 Perturbed Loss 0.07269979868084192
Loss 0.07091097140684724 Acc 0.9786255085468292 Perturbed Loss 0.0714259853027761
Loss 0.0771508701890707 Acc 0.9768186104297638 Perturbed Loss 0.07756021089851856
Loss 0.06400073450058699 Acc 0.9787590956687927 Perturbed Loss 0.06433125864714384
Loss 0.07360405314713717 Acc 0.9768597996234893 Perturbed Loss 0.07410191111266613
Loss 0.07075144696980715 Acc 0.9766962409019471 Perturbed Loss 0.07170133911073208
Loss 0.06564255945384502 Acc 0.9806537115573883 Perturbed Loss 0.06603897472843528
Loss 0.07637869756668807 Acc 0.9791042089462281 Perturbed Loss 0.07677272479981184
Loss 0.06971958387643098 Acc 0.9771143245697022 Perturbed Loss 0.07049398984760046
Loss 0.06811454132199288 Acc 0.9812355005741119 Perturbed Loss 0.06845440469682217
Loss 0.06859598986804485 Acc 0.9793695688247681 Perturbed Loss 0.06896034546196461
Loss 0.06997869165614247 Acc 0.9775624763965607 Perturbed Loss 0.07032329784706234
Loss 0.07144580192863942 Acc 0.9776335167884826 Perturbed Loss 0.07173759091645479
Loss 0.08403463996946811 Acc 0.9756821990013123 Perturbed Loss 0.08463737504556774
Loss 0.07478021692484617 Acc 0.9771553039550781 Perturbed Loss 0.07512694578617811
Epoch 9.0 val loss 0.05816921964287758 val acc 0.9795874357223511
Loss 0.0719506155513227 Acc 0.9824242627620697 Perturbed Loss 0.07231339430436493
Loss 0.07275274015963078 Acc 0.976954733133316 Perturbed Loss 0.07303842842578888
Loss 0.0669542553089559 Acc 0.9809285402297974 Perturbed Loss 0.06728350574150682
Loss 0.07808023950085044 Acc 0.9741057288646698 Perturbed Loss 0.078831433262676
Loss 0.06544270547106862 Acc 0.9820462536811828 Perturbed Loss 0.06592065943405032
Loss 0.06799024342559278 Acc 0.9778886771202088 Perturbed Loss 0.06842907279729843
Loss 0.06693885404616594 Acc 0.9772518229484558 Perturbed Loss 0.0673041919618845
Loss 0.06442951861768961 Acc 0.9823541009426117 Perturbed Loss 0.06488555914722383
Loss 0.06452870905399323 Acc 0.9783389413356781 Perturbed Loss 0.06483235597610473
Loss 0.07025180373340845 Acc 0.9763813138008117 Perturbed Loss 0.0705582926236093
Loss 0.06709798604249954 Acc 0.9778842687606811 Perturbed Loss 0.06738360445946455
Loss 0.0736301863193512 Acc 0.977200700044632 Perturbed Loss 0.07401941925287246
Loss 0.06499218865297735 Acc 0.9803681254386902 Perturbed Loss 0.0653600627090782
Loss 0.06337533585727215 Acc 0.9774935054779053 Perturbed Loss 0.06361586634069681
Loss 0.06707745648920536 Acc 0.9764756166934967 Perturbed Loss 0.06760101418942213
Epoch 10.0 val loss 0.05826159939169884 val acc 0.9789032936096191
Loss 0.0719729030225426 Acc 0.9790106678009033 Perturbed Loss 0.0724057102855295
Loss 0.07182237358763814 Acc 0.9813255655765534 Perturbed Loss 0.07220861030742526
Loss 0.0668900522775948 Acc 0.979752036333084 Perturbed Loss 0.0672360291518271
Loss 0.06241119083017111 Acc 0.9786519086360932 Perturbed Loss 0.06267863323912025
Loss 0.06799842674285174 Acc 0.9785786581039428 Perturbed Loss 0.0683490221761167
Loss 0.0636053779348731 Acc 0.9784843277931213 Perturbed Loss 0.06387344028800726
Loss 0.0725664228014648 Acc 0.9786862289905548 Perturbed Loss 0.07302024137228727
Loss 0.0776029909029603 Acc 0.9774393308162689 Perturbed Loss 0.07792854752391577
Loss 0.059612996391952035 Acc 0.979668333530426 Perturbed Loss 0.060014827959239486
Loss 0.06581561844795943 Acc 0.9815740644931793 Perturbed Loss 0.06613896477967501
Loss 0.06770372688770294 Acc 0.9778047955036163 Perturbed Loss 0.06795927856117487
Loss 0.06918573081493377 Acc 0.9802250432968139 Perturbed Loss 0.06947583187371492
Loss 0.0772018076851964 Acc 0.9761991250514984 Perturbed Loss 0.07749543234705925
Loss 0.0625353915989399 Acc 0.9818761134147644 Perturbed Loss 0.06279885072261095
Loss 0.06438693318516016 Acc 0.9803483581542969 Perturbed Loss 0.06463778669014573
Epoch 11.0 val loss 0.05785131826996803 val acc 0.9787887334823608
Loss 0.08050565371289849 Acc 0.9789964365959167 Perturbed Loss 0.08080907696858049
Loss 0.07352156225591898 Acc 0.9777904736995697 Perturbed Loss 0.07394736893475055
Loss 0.07208470419049264 Acc 0.9817695665359497 Perturbed Loss 0.07237441256642342
Loss 0.06357793357223272 Acc 0.9800715553760528 Perturbed Loss 0.0639443302154541
Loss 0.06293340815231203 Acc 0.9840041613578796 Perturbed Loss 0.06329560961574315
Loss 0.06415595201775431 Acc 0.9792553448677063 Perturbed Loss 0.06452155776321888
Loss 0.06656879181042313 Acc 0.9796540307998657 Perturbed Loss 0.06679748458787799
Loss 0.06503660252317786 Acc 0.9798807859420776 Perturbed Loss 0.06554974898695946
Loss 0.06523409444838763 Acc 0.9776868975162506 Perturbed Loss 0.06563973013311625
Loss 0.06401024781167507 Acc 0.9807140934467315 Perturbed Loss 0.0643534180894494
Loss 0.07327818223275244 Acc 0.9790378940105439 Perturbed Loss 0.07374436205253004
Loss 0.06308348932303488 Acc 0.9774533176422119 Perturbed Loss 0.063482108656317
Loss 0.0763026218302548 Acc 0.9806040930747986 Perturbed Loss 0.07670921322889626
Loss 0.06526147186756134 Acc 0.9808115100860596 Perturbed Loss 0.06575488973408937
Loss 0.06901139315217733 Acc 0.9740795290470123 Perturbed Loss 0.06932098265737295
Epoch 12.0 val loss 0.057320598512887955 val acc 0.9791467189788818
Loss 0.07425328243523836 Acc 0.9777698862552643 Perturbed Loss 0.07471997112035751
Loss 0.07591404233127833 Acc 0.9773347091674804 Perturbed Loss 0.07624363385140896
Loss 0.0741319415718317 Acc 0.977847911119461 Perturbed Loss 0.07440905820578336
Loss 0.06499672278761864 Acc 0.982564572095871 Perturbed Loss 0.06525828886777163
Loss 0.06554768117144703 Acc 0.9791307914257049 Perturbed Loss 0.06580191861838103
Loss 0.06828304305672646 Acc 0.9811657321453094 Perturbed Loss 0.06860279817134142
Loss 0.07193996034562587 Acc 0.9758358418941497 Perturbed Loss 0.07228465169668198
Loss 0.06912829983048141 Acc 0.9772557246685029 Perturbed Loss 0.06943502916023135
Loss 0.06990042887628078 Acc 0.9788125503063202 Perturbed Loss 0.07014614256098867
Loss 0.06794188655912876 Acc 0.9797475361824035 Perturbed Loss 0.06823878446593881
Loss 0.07516368977725506 Acc 0.9780599796772003 Perturbed Loss 0.07548416044563055
Loss 0.0691245799139142 Acc 0.9811127662658692 Perturbed Loss 0.06945468530058861
Loss 0.06562412448227406 Acc 0.9779598355293274 Perturbed Loss 0.06593791691586376
Loss 0.060688347816467286 Acc 0.9808507597446442 Perturbed Loss 0.06097591014578938
Loss 0.0700469034537673 Acc 0.9814558398723602 Perturbed Loss 0.07059657976031303
Epoch 13.0 val loss 0.0565967857837677 val acc 0.9797775745391846
Loss 0.06549796655774116 Acc 0.9795700716972351 Perturbed Loss 0.06571709455922246
Loss 0.07278767565265298 Acc 0.9763831281661988 Perturbed Loss 0.07314273627474904
Loss 0.0675284474529326 Acc 0.9801961421966553 Perturbed Loss 0.06772810267284513
Loss 0.07097569542005658 Acc 0.9784106016159058 Perturbed Loss 0.07148509934544563
Loss 0.06819435816258192 Acc 0.9786733484268189 Perturbed Loss 0.06851157777011395
Loss 0.06092562174424529 Acc 0.9814553451538086 Perturbed Loss 0.061615582704544064
Loss 0.0642973756045103 Acc 0.9812280869483948 Perturbed Loss 0.06471077855676413
Loss 0.057334291525185106 Acc 0.9798331916332245 Perturbed Loss 0.057614202946424484
Loss 0.06435105513781308 Acc 0.9809300100803375 Perturbed Loss 0.06461894264444709
Loss 0.06664644606411457 Acc 0.9752313315868377 Perturbed Loss 0.06704356774687767
Loss 0.06933937087655068 Acc 0.9790319156646728 Perturbed Loss 0.06984336603432893
Loss 0.06754438977688551 Acc 0.976121461391449 Perturbed Loss 0.06792531870305538
Loss 0.0702633283380419 Acc 0.9795589768886566 Perturbed Loss 0.07068198753520846
Loss 0.07438833681866526 Acc 0.9740805542469024 Perturbed Loss 0.07470856891945005
Loss 0.06525921421125531 Acc 0.9804539132118225 Perturbed Loss 0.06551600066944957
Epoch 14.0 val loss 0.05627049133181572 val acc 0.9799391627311707
Loss 0.06757335461676121 Acc 0.9752326345443726 Perturbed Loss 0.0679903681576252
Loss 0.06805408488959074 Acc 0.9796704244613648 Perturbed Loss 0.06834833282977343
Loss 0.07584826819598675 Acc 0.9736934113502502 Perturbed Loss 0.07624013748019934
Loss 0.06855223087593913 Acc 0.9788688755035401 Perturbed Loss 0.06884253311902284
Loss 0.05370550375431776 Acc 0.9813493299484253 Perturbed Loss 0.05394579980522394
Loss 0.05969427554868162 Acc 0.9806458747386932 Perturbed Loss 0.060072821425274016
Loss 0.06737514164298773 Acc 0.9801052308082581 Perturbed Loss 0.06781670240685343
Loss 0.0836778569407761 Acc 0.9788236284255981 Perturbed Loss 0.08409441992640496
Loss 0.07314235240221023 Acc 0.9788863337039948 Perturbed Loss 0.07357393674552441
Loss 0.06833521025255322 Acc 0.9806452798843384 Perturbed Loss 0.06860074745491147
Loss 0.06290661143139005 Acc 0.9834555804729461 Perturbed Loss 0.06314061928540468
Loss 0.06849080085754394 Acc 0.9766709303855896 Perturbed Loss 0.06888777792453765
Loss 0.06304324220865964 Acc 0.9820471382141114 Perturbed Loss 0.06354919400066138
Loss 0.06535330757498742 Acc 0.9818734514713288 Perturbed Loss 0.06568706572055817
Loss 0.07897236194461583 Acc 0.9774495506286621 Perturbed Loss 0.07937597725540399
Epoch 15.0 val loss 0.05670499801635742 val acc 0.9796835780143738
Loss 0.06701314132660627 Acc 0.97732701420784 Perturbed Loss 0.06729967234656214
Loss 0.06759597588330507 Acc 0.9762063348293304 Perturbed Loss 0.06788253333419561
Loss 0.07131036290898919 Acc 0.9801767492294311 Perturbed Loss 0.07168128002434969
Loss 0.0625483713299036 Acc 0.9799423515796661 Perturbed Loss 0.06294398877769708
Loss 0.062092133555561306 Acc 0.9800882458686828 Perturbed Loss 0.062384371105581524
Loss 0.06895121591165662 Acc 0.9809832143783569 Perturbed Loss 0.06933142190799117
Loss 0.07269027516245842 Acc 0.9802877449989319 Perturbed Loss 0.07289468351751566
Loss 0.07248357579112052 Acc 0.9789016616344451 Perturbed Loss 0.07316797897219658
Loss 0.06360937310382724 Acc 0.9807605183124543 Perturbed Loss 0.06400762785226106
Loss 0.05599733091890812 Acc 0.9843796539306641 Perturbed Loss 0.056345003005117175
Loss 0.06685114864259958 Acc 0.9794449186325074 Perturbed Loss 0.06709527354687453
Loss 0.06288915327750147 Acc 0.9809776389598847 Perturbed Loss 0.0631758421100676
Loss 0.06268116591498256 Acc 0.9808681631088256 Perturbed Loss 0.06297897685319186
Loss 0.06646742874756456 Acc 0.981125658750534 Perturbed Loss 0.06676828974857926
Loss 0.058241000920534136 Acc 0.9840842068195343 Perturbed Loss 0.05849633678793907
Epoch 16.0 val loss 0.05593381077051163 val acc 0.9798833131790161
Loss 0.06734748478978872 Acc 0.9793225538730621 Perturbed Loss 0.0676738941296935
Loss 0.06997921448200942 Acc 0.9820539224147796 Perturbed Loss 0.07025133516639472
Loss 0.05988425031304359 Acc 0.9799219572544098 Perturbed Loss 0.060171501561999324
Loss 0.06794138800352811 Acc 0.9798004424571991 Perturbed Loss 0.06819656116887927
Loss 0.06152964163571596 Acc 0.9809026336669922 Perturbed Loss 0.06180372320115566
Loss 0.058744286224246024 Acc 0.9803192353248597 Perturbed Loss 0.05908328201621771
Loss 0.07096530880779028 Acc 0.9762918508052826 Perturbed Loss 0.07135465655475855
Loss 0.06544195098802447 Acc 0.9810482299327851 Perturbed Loss 0.06577766235917806
Loss 0.05513249410316348 Acc 0.9831893813610076 Perturbed Loss 0.05549058075994253
Loss 0.07785306230187417 Acc 0.977197743654251 Perturbed Loss 0.07823107060045004
Loss 0.06283739807084203 Acc 0.9792980992794037 Perturbed Loss 0.06306234134361148
Loss 0.06867558877915143 Acc 0.9785349750518799 Perturbed Loss 0.06906834457069636
Loss 0.06500315116718411 Acc 0.9749232983589172 Perturbed Loss 0.06535404110327363
Loss 0.06689049733802677 Acc 0.9790026080608368 Perturbed Loss 0.06722725331783294
Loss 0.06361818114295602 Acc 0.9828173053264618 Perturbed Loss 0.06392120679840446
Epoch 17.0 val loss 0.056372519582509995 val acc 0.9799524545669556
Loss 0.06534804897382855 Acc 0.9802813601493835 Perturbed Loss 0.06572000863030553
Loss 0.06685806658118963 Acc 0.9803830909729004 Perturbed Loss 0.0671176790073514
Loss 0.0649493601731956 Acc 0.9773663055896759 Perturbed Loss 0.0651733199506998
Loss 0.061894654501229524 Acc 0.9823274004459381 Perturbed Loss 0.062114837411791086
Loss 0.06322048365138472 Acc 0.9821618509292602 Perturbed Loss 0.06350621562451124
Loss 0.05466311695054173 Acc 0.9828877925872803 Perturbed Loss 0.05490138359367847
Loss 0.059456917941570285 Acc 0.9791211724281311 Perturbed Loss 0.05979515366256237
Loss 0.05860928893089294 Acc 0.9811748540401459 Perturbed Loss 0.059015705995261666
Loss 0.06627296378836035 Acc 0.979869042634964 Perturbed Loss 0.06649017779156566
Loss 0.0669303034618497 Acc 0.979061781167984 Perturbed Loss 0.06729163493961096
Loss 0.06330842148512601 Acc 0.9787017846107483 Perturbed Loss 0.06357233084738255
Loss 0.07623884107917547 Acc 0.975253711938858 Perturbed Loss 0.07657597117125987
Loss 0.06325500626116991 Acc 0.9795021057128906 Perturbed Loss 0.06363949317485094
Loss 0.0772105722874403 Acc 0.9783223819732666 Perturbed Loss 0.0775062595680356
Loss 0.05826466292142868 Acc 0.9789292299747467 Perturbed Loss 0.05846864186227321
Epoch 18.0 val loss 0.05551263689994812 val acc 0.9801825881004333
Loss 0.06690675869584084 Acc 0.9768227589130402 Perturbed Loss 0.06719048041850328
Loss 0.07068904373794795 Acc 0.9791319739818573 Perturbed Loss 0.07097377188503742
Loss 0.06774421468377113 Acc 0.9793116855621338 Perturbed Loss 0.06795687764883042
Loss 0.05458175286650658 Acc 0.9780535483360291 Perturbed Loss 0.05493989542126656
Loss 0.060334422662854194 Acc 0.9821626818180085 Perturbed Loss 0.06062156729400158
Loss 0.06357123233377933 Acc 0.9767184174060821 Perturbed Loss 0.06392801720649004
Loss 0.08299957152456044 Acc 0.9760282766819001 Perturbed Loss 0.08347458153963089
Loss 0.06296654511243105 Acc 0.9797086524963379 Perturbed Loss 0.06320212064310908
Loss 0.060174808725714686 Acc 0.980872300863266 Perturbed Loss 0.060378591679036614
Loss 0.0610438134893775 Acc 0.9801374292373657 Perturbed Loss 0.061291067712008956
Loss 0.06928655844181776 Acc 0.9790754723548889 Perturbed Loss 0.06957452356815338
Loss 0.06229197723791003 Acc 0.9784666097164154 Perturbed Loss 0.06262273155152798
Loss 0.06396450331434607 Acc 0.9799472737312317 Perturbed Loss 0.06417040172964335
Loss 0.07786153320223094 Acc 0.9799440717697143 Perturbed Loss 0.07812727075070143
Loss 0.05936951337382197 Acc 0.9820016610622406 Perturbed Loss 0.05960639875382185
Epoch 19.0 val loss 0.05602378025650978 val acc 0.9800267219543457
[06:57:14] INFO     `Trainer.fit` stopped: `max_epochs=20` reached.                                                                                                                         rank_zero.py:53
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750/750 0:03:45 • 0:00:00 3.36it/s train/loss: 0.059 val_loss: 0.056
[06:57:16] INFO     Created a temporary directory at /tmp/tmpatua2uiv                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmpatua2uiv/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
           INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
[06:57:17] INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
           INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
           INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
           INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
[06:57:18] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.0006, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.0005, adaptive=False)
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.08815171264111996 Acc 0.9656726801395417 Perturbed Loss 0.08843030277639627
[06:57:48] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.07761428445577621 Acc 0.9714554333686829 Perturbed Loss 0.07783326368778944
Loss 0.08593821819871664 Acc 0.9769651138782501 Perturbed Loss 0.08614901969209314
Loss 0.08247348876670003 Acc 0.9742623591423034 Perturbed Loss 0.08260394444689155
Loss 0.08069627910852432 Acc 0.9756981384754181 Perturbed Loss 0.08081874750554562
Loss 0.09942430138587952 Acc 0.963894624710083 Perturbed Loss 0.09962544780224562
Loss 0.0844625310227275 Acc 0.9690557360649109 Perturbed Loss 0.08467724703252316
Loss 0.080691935159266 Acc 0.9760733890533447 Perturbed Loss 0.08090547673404216
Loss 0.08865848511457443 Acc 0.9728478753566742 Perturbed Loss 0.08878482948988677
Loss 0.08497438162565231 Acc 0.9693449509143829 Perturbed Loss 0.08510443333536387
Loss 0.07723754301667213 Acc 0.9764364993572235 Perturbed Loss 0.07733720973134041
Loss 0.08528813019394875 Acc 0.9768481051921845 Perturbed Loss 0.08542161341756582
Loss 0.0814832892268896 Acc 0.977454229593277 Perturbed Loss 0.08168098269030452
Loss 0.07410214763134718 Acc 0.9814573180675507 Perturbed Loss 0.07425720430910587
Loss 0.08561653427779675 Acc 0.975152678489685 Perturbed Loss 0.08579705238342285
Epoch 0.0 val loss 0.060990314930677414 val acc 0.9781120419502258
Loss 0.08216078124940396 Acc 0.9739648532867432 Perturbed Loss 0.08231556490063667
Loss 0.07875890862196684 Acc 0.9720688486099243 Perturbed Loss 0.07887278631329536
Loss 0.07903961017727852 Acc 0.969063812494278 Perturbed Loss 0.0792029146105051
Loss 0.08046786174178124 Acc 0.9740310764312744 Perturbed Loss 0.0805861496180296
Loss 0.08670372743159532 Acc 0.9758716487884521 Perturbed Loss 0.08683275301009416
Loss 0.07579910969361663 Acc 0.9774861943721771 Perturbed Loss 0.07588410466909408
Loss 0.08328726213425398 Acc 0.9750581932067871 Perturbed Loss 0.0833858871459961
Loss 0.07194254048168659 Acc 0.9790499901771545 Perturbed Loss 0.07207430873066187
Loss 0.07785600120201706 Acc 0.9753102374076843 Perturbed Loss 0.07803423568606377
Loss 0.08500008335337043 Acc 0.9759300518035888 Perturbed Loss 0.08513337900862097
Loss 0.0778529960475862 Acc 0.9694812703132629 Perturbed Loss 0.07797541182488203
Loss 0.09711152106523514 Acc 0.9727110695838929 Perturbed Loss 0.09733843266963958
Loss 0.0812050487473607 Acc 0.9792333281040192 Perturbed Loss 0.08133323702961207
Loss 0.09668267723172903 Acc 0.9712007534503937 Perturbed Loss 0.09688613468781114
Loss 0.08774846702814103 Acc 0.9753874683380127 Perturbed Loss 0.08786754380911589
Epoch 1.0 val loss 0.057608891278505325 val acc 0.9791023135185242
Loss 0.07687030602246522 Acc 0.9733905625343323 Perturbed Loss 0.07698635336011649
Loss 0.08770035594701767 Acc 0.9777470660209656 Perturbed Loss 0.08781637601554394
Loss 0.07686870083212853 Acc 0.9776959896087647 Perturbed Loss 0.07701371259987354
Loss 0.07744775146245957 Acc 0.9794789266586303 Perturbed Loss 0.07761981572955846
Loss 0.07468265473842621 Acc 0.9797626519203186 Perturbed Loss 0.07479509726166725
Loss 0.07295355685055256 Acc 0.9772320652008056 Perturbed Loss 0.07305717702955007
Loss 0.08523659192025662 Acc 0.978816705942154 Perturbed Loss 0.08536623388528825
Loss 0.07666056413203477 Acc 0.981206260919571 Perturbed Loss 0.07682411681860685
Loss 0.07994752366095781 Acc 0.9768674552440644 Perturbed Loss 0.08005350843071937
Loss 0.07621653757989406 Acc 0.9792778825759888 Perturbed Loss 0.0763315318338573
Loss 0.0729083464294672 Acc 0.9793364012241363 Perturbed Loss 0.07302017703652382
Loss 0.08342896535992622 Acc 0.974087690114975 Perturbed Loss 0.08355934593826532
Loss 0.08590468265116215 Acc 0.9716188132762908 Perturbed Loss 0.08603461634367704
Loss 0.10624105788767338 Acc 0.9667942237854004 Perturbed Loss 0.10640941862016916
Loss 0.08704690229147673 Acc 0.9745422947406769 Perturbed Loss 0.08721869617700577
Epoch 2.0 val loss 0.057938601821660995 val acc 0.9786734580993652
Loss 0.07900870710611343 Acc 0.9747598493099212 Perturbed Loss 0.07910938527435064
Loss 0.06879888243973255 Acc 0.9792908108234406 Perturbed Loss 0.06888722509145737
Loss 0.07497232038527728 Acc 0.9794475603103637 Perturbed Loss 0.07507490232586861
Loss 0.07839027050882579 Acc 0.9797481882572174 Perturbed Loss 0.07855283383280039
Loss 0.089217340759933 Acc 0.9772081053256989 Perturbed Loss 0.08936379611492157
Loss 0.08036747138947248 Acc 0.9761320376396179 Perturbed Loss 0.08049549512565136
Loss 0.07137784894555807 Acc 0.9819949400424958 Perturbed Loss 0.07149360105395317
Loss 0.08027131322771311 Acc 0.9766105902194977 Perturbed Loss 0.08036361187696457
Loss 0.08410486973822116 Acc 0.9776861083507538 Perturbed Loss 0.08419857360422611
Loss 0.07763592801988124 Acc 0.9767378532886505 Perturbed Loss 0.07773763917386532
Loss 0.06722462944686412 Acc 0.977293336391449 Perturbed Loss 0.06732045002281666
Loss 0.08884345706552267 Acc 0.9727930557727814 Perturbed Loss 0.08899003688246011
Loss 0.08893032610416413 Acc 0.9755937671661377 Perturbed Loss 0.08912768919020891
Loss 0.07953173646703363 Acc 0.9709911656379699 Perturbed Loss 0.07967140633612871
Loss 0.08359849989414216 Acc 0.9767839014530182 Perturbed Loss 0.08370237372815609
Epoch 3.0 val loss 0.059496719390153885 val acc 0.978636622428894
Loss 0.0632616888359189 Acc 0.9798818159103394 Perturbed Loss 0.06335644897073507
Loss 0.07142418432980775 Acc 0.982552570104599 Perturbed Loss 0.07150223661214113
Loss 0.06792405756190419 Acc 0.971096019744873 Perturbed Loss 0.06805661780759692
Loss 0.08844548029825092 Acc 0.9769326281547547 Perturbed Loss 0.08856106393039226
Loss 0.07833339193835855 Acc 0.9741023230552673 Perturbed Loss 0.07847271105274559
Loss 0.07455291133373976 Acc 0.9785810434818267 Perturbed Loss 0.07467762434855103
Loss 0.06812728673219681 Acc 0.9790070700645447 Perturbed Loss 0.06823271077126264
Loss 0.07092518664896488 Acc 0.9784493899345398 Perturbed Loss 0.07101305585354567
Loss 0.07422026367858052 Acc 0.9751758289337158 Perturbed Loss 0.07434629075229168
Loss 0.06969583990052343 Acc 0.9770178878307343 Perturbed Loss 0.06982966816052795
Loss 0.07624404732137918 Acc 0.9794654929637909 Perturbed Loss 0.07634701859205961
Loss 0.08292861398309469 Acc 0.9750565254688263 Perturbed Loss 0.0830339821614325
Loss 0.07655684769153595 Acc 0.9751062250137329 Perturbed Loss 0.07669172588735819
Loss 0.0772946435213089 Acc 0.9788027274608612 Perturbed Loss 0.07739967089146375
Loss 0.07336492896080017 Acc 0.9802991569042205 Perturbed Loss 0.07345391765236854
Epoch 4.0 val loss 0.05878140777349472 val acc 0.979288637638092
Loss 0.07342227442190051 Acc 0.9771938908100128 Perturbed Loss 0.07350185621529817
Loss 0.07962527379393577 Acc 0.9791310453414916 Perturbed Loss 0.07978937599807978
Loss 0.08723800651729106 Acc 0.9760733258724212 Perturbed Loss 0.087327950745821
Loss 0.08281295992434025 Acc 0.9731591832637787 Perturbed Loss 0.08293767424300313
Loss 0.06991110596805811 Acc 0.9773550522327423 Perturbed Loss 0.06998584732413292
Loss 0.08397739421576261 Acc 0.9739520335197449 Perturbed Loss 0.08409376682713628
Loss 0.06657904133200646 Acc 0.9796400272846222 Perturbed Loss 0.06666628368198872
Loss 0.06586737174540758 Acc 0.9768742775917053 Perturbed Loss 0.06597293799743056
Loss 0.07120970759540796 Acc 0.9791138899326325 Perturbed Loss 0.07133162047713995
Loss 0.07220299873501063 Acc 0.9772649574279785 Perturbed Loss 0.07233079813420773
Loss 0.07737278908491135 Acc 0.9760266268253326 Perturbed Loss 0.07747208461165428
Loss 0.08663624845445156 Acc 0.97402592420578 Perturbed Loss 0.08677608240395784
Loss 0.076746696382761 Acc 0.9793995225429535 Perturbed Loss 0.07685365103185177
Loss 0.07490456037223339 Acc 0.9774628043174743 Perturbed Loss 0.07504757888615131
Loss 0.07371979795396327 Acc 0.9760062634944916 Perturbed Loss 0.07384099816903472
Epoch 5.0 val loss 0.06104385107755661 val acc 0.978802502155304
Loss 0.07385691538453103 Acc 0.9772344291210174 Perturbed Loss 0.0739420691691339
Loss 0.0741611405275762 Acc 0.9789213097095489 Perturbed Loss 0.07425807891413569
Loss 0.07017899110913277 Acc 0.9789731347560883 Perturbed Loss 0.07026869840919972
Loss 0.08316917192190885 Acc 0.9751985847949982 Perturbed Loss 0.08334413543343544
Loss 0.07700610058382154 Acc 0.9810908353328704 Perturbed Loss 0.07711573733016848
Loss 0.08058010233566165 Acc 0.9741827762126922 Perturbed Loss 0.0807033527083695
Loss 0.07254241898655892 Acc 0.9740393161773682 Perturbed Loss 0.07263913605362177
Loss 0.07471086584031582 Acc 0.980777028799057 Perturbed Loss 0.07484036952257156
Loss 0.07021519053727389 Acc 0.9784561145305634 Perturbed Loss 0.07030681002885103
Loss 0.08072831854224205 Acc 0.9767124700546265 Perturbed Loss 0.0808109756372869
Loss 0.07599812572821975 Acc 0.9781161487102509 Perturbed Loss 0.07606300013139844
Loss 0.07360162134282291 Acc 0.9783322811126709 Perturbed Loss 0.0736995149962604
Loss 0.07649441744200886 Acc 0.9759887874126434 Perturbed Loss 0.0765915956441313
Loss 0.07887167327105998 Acc 0.9809090399742126 Perturbed Loss 0.07898343823850155
Loss 0.0766839900240302 Acc 0.9735772895812989 Perturbed Loss 0.07678475227206945
Epoch 6.0 val loss 0.057614102959632874 val acc 0.9790550470352173
Loss 0.07920815417543053 Acc 0.9754096937179565 Perturbed Loss 0.0792931042984128
Loss 0.08199720817618072 Acc 0.9768917286396026 Perturbed Loss 0.08209814430214464
Loss 0.07445200990885496 Acc 0.9787487363815308 Perturbed Loss 0.07453028906136751
Loss 0.06851971382275224 Acc 0.9813051831722259 Perturbed Loss 0.06862496376037598
Loss 0.06754455786198378 Acc 0.9771776187419892 Perturbed Loss 0.06763492537662387
Loss 0.07610513303428888 Acc 0.9775844371318817 Perturbed Loss 0.07618481684476137
Loss 0.07701671417802572 Acc 0.9750345110893249 Perturbed Loss 0.07713254150003195
Loss 0.06801219718530774 Acc 0.9800756716728211 Perturbed Loss 0.06811312295496463
Loss 0.07513207040727138 Acc 0.9773229587078095 Perturbed Loss 0.07524393402040004
Loss 0.08199437584728003 Acc 0.9780199146270752 Perturbed Loss 0.0821265184879303
Loss 0.08026934668421745 Acc 0.9802414178848267 Perturbed Loss 0.08044183354824781
Loss 0.06979637660086155 Acc 0.9786033928394318 Perturbed Loss 0.06986592633649708
Loss 0.07144322406500578 Acc 0.9776925098896027 Perturbed Loss 0.07158457484096288
Loss 0.06725873902440072 Acc 0.9809212231636047 Perturbed Loss 0.06736009772866965
Loss 0.07864846251904964 Acc 0.9766546261310577 Perturbed Loss 0.07875147547572851
Epoch 7.0 val loss 0.059522178024053574 val acc 0.9786277413368225
Loss 0.06865553773939609 Acc 0.9764471626281739 Perturbed Loss 0.06877512816339731
Loss 0.06934871348552406 Acc 0.9743982803821564 Perturbed Loss 0.06942890281789005
Loss 0.06438373830169439 Acc 0.9778251147270203 Perturbed Loss 0.06448875159025193
Loss 0.073504520021379 Acc 0.9769357061386108 Perturbed Loss 0.07356657948344945
Loss 0.06426643822342157 Acc 0.9791530859470368 Perturbed Loss 0.06432855352759362
Loss 0.06701975680887699 Acc 0.9781164562702179 Perturbed Loss 0.06711511307395995
Loss 0.06719603482633829 Acc 0.976852058172226 Perturbed Loss 0.06729244586080313
Loss 0.06568034939467907 Acc 0.9782649087905884 Perturbed Loss 0.06577621899545193
Loss 0.07243235513567925 Acc 0.9765658724308014 Perturbed Loss 0.07252833735197782
Loss 0.06804007619619369 Acc 0.976531058549881 Perturbed Loss 0.06816456770524383
Loss 0.07901711739599705 Acc 0.9777862203121185 Perturbed Loss 0.07912499401718379
Loss 0.07286122787743807 Acc 0.9784418344497681 Perturbed Loss 0.07295518953353167
Loss 0.07069439738988877 Acc 0.9778417778015137 Perturbed Loss 0.07079198211431503
Loss 0.07372245362028479 Acc 0.9772781109809876 Perturbed Loss 0.07380499638617039
Loss 0.07523593166843057 Acc 0.9816868948936462 Perturbed Loss 0.07532205933704972
Epoch 8.0 val loss 0.05899747461080551 val acc 0.9793119430541992
Loss 0.07255564741790295 Acc 0.9755893802642822 Perturbed Loss 0.072673528380692
Loss 0.07115886155515909 Acc 0.9788927805423736 Perturbed Loss 0.07124584145843983
Loss 0.0719605042412877 Acc 0.9779455900192261 Perturbed Loss 0.07205216728150844
Loss 0.06440859522670507 Acc 0.978365490436554 Perturbed Loss 0.06452748682349921
Loss 0.07184858452528715 Acc 0.9782102262973785 Perturbed Loss 0.0719588964805007
Loss 0.07040835414081811 Acc 0.9770313584804535 Perturbed Loss 0.07047783806920052
Loss 0.059596444889903066 Acc 0.9810588026046753 Perturbed Loss 0.05966155892238021
Loss 0.07759763900190592 Acc 0.9796503591537475 Perturbed Loss 0.0776650082692504
Loss 0.062130906395614145 Acc 0.9797987139225006 Perturbed Loss 0.06229215085506439
Loss 0.0731382741034031 Acc 0.9812369215488433 Perturbed Loss 0.07323521442711353
Loss 0.07057765010744334 Acc 0.9792314112186432 Perturbed Loss 0.07069319859147072
Loss 0.07408860309049486 Acc 0.9778126358985901 Perturbed Loss 0.07418928870931268
Loss 0.07190898090600967 Acc 0.97764608502388 Perturbed Loss 0.07198322009295226
Loss 0.07960775518789888 Acc 0.9750525212287903 Perturbed Loss 0.07970761090517044
Loss 0.07675701953470707 Acc 0.9771361863613128 Perturbed Loss 0.0768704041838646
Epoch 9.0 val loss 0.05659475177526474 val acc 0.9794797897338867
Loss 0.07178462037816644 Acc 0.9823015010356904 Perturbed Loss 0.07195849020034074
Loss 0.07201128095388412 Acc 0.9767167735099792 Perturbed Loss 0.07207189343869685
Loss 0.0652448658645153 Acc 0.9808454096317292 Perturbed Loss 0.06531050579622388
Loss 0.07733441514894367 Acc 0.9747193503379822 Perturbed Loss 0.077415169198066
Loss 0.05906544541940093 Acc 0.9826254034042359 Perturbed Loss 0.05913412697613239
Loss 0.064325367892161 Acc 0.9785931062698364 Perturbed Loss 0.06443625217303633
Loss 0.06685726948082447 Acc 0.9779597234725952 Perturbed Loss 0.06692612987011672
Loss 0.06125347868539393 Acc 0.9826731896400451 Perturbed Loss 0.06132771586067975
Loss 0.06396278385072947 Acc 0.9776489341259003 Perturbed Loss 0.0640414172038436
Loss 0.06747197372838855 Acc 0.9768283760547638 Perturbed Loss 0.06756118480116129
Loss 0.06706841304898262 Acc 0.9776595532894135 Perturbed Loss 0.0671558130159974
Loss 0.07516250669956208 Acc 0.9775286114215851 Perturbed Loss 0.07528425391763449
Loss 0.06597849695943296 Acc 0.9793122112751007 Perturbed Loss 0.06606877471320331
Loss 0.06373269166797399 Acc 0.9778712463378906 Perturbed Loss 0.06382055912166834
Loss 0.06397132012993097 Acc 0.9777329874038696 Perturbed Loss 0.06406747967004776
Epoch 10.0 val loss 0.05833142623305321 val acc 0.9795363545417786
Loss 0.06751193660311401 Acc 0.979433822631836 Perturbed Loss 0.06760715376585721
Loss 0.06985177662223578 Acc 0.9806545448303222 Perturbed Loss 0.06992454724386335
Loss 0.06443363958969713 Acc 0.9805794894695282 Perturbed Loss 0.06448397979140282
Loss 0.05890111610293389 Acc 0.9795293927192688 Perturbed Loss 0.05896433738991618
Loss 0.0678865989111364 Acc 0.9776231527328492 Perturbed Loss 0.06793256690725684
Loss 0.062061146944761274 Acc 0.9786339402198792 Perturbed Loss 0.0621376771107316
Loss 0.0676729610748589 Acc 0.9789796578884125 Perturbed Loss 0.06775000780820846
Loss 0.07452199671417475 Acc 0.9781350922584534 Perturbed Loss 0.07460487585514784
Loss 0.06254049807786942 Acc 0.9795134699344635 Perturbed Loss 0.06261061802506447
Loss 0.06248663701117039 Acc 0.9824102473258972 Perturbed Loss 0.06254590395838022
Loss 0.06796479806303977 Acc 0.9772461092472077 Perturbed Loss 0.06804309092462063
Loss 0.06945303719490767 Acc 0.9799578535556793 Perturbed Loss 0.06951251700520515
Loss 0.08039405971765518 Acc 0.9763978385925293 Perturbed Loss 0.08050472341477871
Loss 0.06523567330092192 Acc 0.9814627838134765 Perturbed Loss 0.06530750382691622
Loss 0.06431771358475089 Acc 0.9809947073459625 Perturbed Loss 0.06437326034530998
Epoch 11.0 val loss 0.05642275884747505 val acc 0.978889524936676
Loss 0.08022887699306011 Acc 0.9784482479095459 Perturbed Loss 0.08034478325396777
Loss 0.07237550675868988 Acc 0.976001935005188 Perturbed Loss 0.07249734066426754
Loss 0.07173614751547575 Acc 0.9813962352275848 Perturbed Loss 0.07182868510484695
Loss 0.06343057867139577 Acc 0.9791956150531769 Perturbed Loss 0.06351982347667218
Loss 0.06141138916835189 Acc 0.9840626037120819 Perturbed Loss 0.0615053696744144
Loss 0.06294456681236625 Acc 0.9793967151641846 Perturbed Loss 0.06305914351716638
Loss 0.06841615684330464 Acc 0.9791834354400635 Perturbed Loss 0.06849683290347457
Loss 0.06213873723521829 Acc 0.9792803573608398 Perturbed Loss 0.06221153760328889
Loss 0.06484163109213113 Acc 0.9779567754268647 Perturbed Loss 0.06496604822576046
Loss 0.06408881314098835 Acc 0.9808486557006836 Perturbed Loss 0.06418690156191588
Loss 0.0775393469631672 Acc 0.9782012677192689 Perturbed Loss 0.07765407989732921
Loss 0.0637852904573083 Acc 0.9760867893695832 Perturbed Loss 0.06388558918610215
Loss 0.07675473633222282 Acc 0.9802605211734772 Perturbed Loss 0.07686051159165799
Loss 0.06499741543084384 Acc 0.9806742823123932 Perturbed Loss 0.06508189540356397
Loss 0.06867914712056518 Acc 0.9744490122795105 Perturbed Loss 0.06875391375273467
Epoch 12.0 val loss 0.05712927132844925 val acc 0.9792425036430359
Loss 0.07055080752819777 Acc 0.9778835415840149 Perturbed Loss 0.07064494159072637
Loss 0.07808680094778538 Acc 0.9775238883495331 Perturbed Loss 0.07819479752331972
Loss 0.07292809784412384 Acc 0.9779575824737549 Perturbed Loss 0.07301115576177836
Loss 0.06615832038223743 Acc 0.9824292278289795 Perturbed Loss 0.06622738428413869
Loss 0.06561952503398061 Acc 0.9792464113235474 Perturbed Loss 0.06570143738761544
Loss 0.06867917362600565 Acc 0.9813019251823425 Perturbed Loss 0.06874283917248249
Loss 0.06997961550951004 Acc 0.976065354347229 Perturbed Loss 0.0700382562354207
Loss 0.07078687648288906 Acc 0.9767224943637848 Perturbed Loss 0.07084277236834169
Loss 0.07119258366525173 Acc 0.978219141960144 Perturbed Loss 0.07129970878362656
Loss 0.0668045518361032 Acc 0.979986937046051 Perturbed Loss 0.06686593327671289
Loss 0.07162708427757025 Acc 0.9781712186336518 Perturbed Loss 0.071698948033154
Loss 0.06862757086753846 Acc 0.9816973793506623 Perturbed Loss 0.06871973346918821
Loss 0.06471971390768885 Acc 0.9778106188774109 Perturbed Loss 0.06478355003520847
Loss 0.05924711650237441 Acc 0.9811923027038574 Perturbed Loss 0.05933597689494491
Loss 0.06989042740315199 Acc 0.98185511469841 Perturbed Loss 0.07001379266381264
Epoch 13.0 val loss 0.05680891498923302 val acc 0.9796320796012878
Loss 0.062082513384521004 Acc 0.9799926674365997 Perturbed Loss 0.06215110519900918
Loss 0.07283950518816709 Acc 0.9770281028747558 Perturbed Loss 0.07291404312476515
Loss 0.06763822196051478 Acc 0.9803801214694977 Perturbed Loss 0.06770059391856194
Loss 0.06974824322387577 Acc 0.9775853526592254 Perturbed Loss 0.06982676124200225
Loss 0.07038266737014055 Acc 0.9789292991161347 Perturbed Loss 0.07047772958874703
Loss 0.0581206108443439 Acc 0.9813556265830994 Perturbed Loss 0.05818488525226712
Loss 0.06198300015181303 Acc 0.9813030779361724 Perturbed Loss 0.062058358788490295
Loss 0.0582992373406887 Acc 0.9804582321643829 Perturbed Loss 0.05838078372180462
Loss 0.06542516166344285 Acc 0.9820723223686219 Perturbed Loss 0.06552231600508093
Loss 0.06576674997806549 Acc 0.9750292456150055 Perturbed Loss 0.0658656731620431
Loss 0.06934925816953182 Acc 0.978998761177063 Perturbed Loss 0.06950899295508861
Loss 0.06620110906660556 Acc 0.9763802778720856 Perturbed Loss 0.06626917291432619
Loss 0.07119777666404843 Acc 0.9795715320110321 Perturbed Loss 0.071358995847404
Loss 0.07436075709760188 Acc 0.9738540518283844 Perturbed Loss 0.07449918070808054
Loss 0.06525551285594702 Acc 0.9795947992801666 Perturbed Loss 0.06531743600964546
Epoch 14.0 val loss 0.05626674368977547 val acc 0.979834258556366
Loss 0.07173999455757439 Acc 0.9760213768482209 Perturbed Loss 0.07184251599013805
Loss 0.06796221606433392 Acc 0.9788770484924316 Perturbed Loss 0.06805702704936266
Loss 0.07593011267483235 Acc 0.9736525309085846 Perturbed Loss 0.07600797468796372
Loss 0.06780521469190717 Acc 0.978724137544632 Perturbed Loss 0.06789125541225076
Loss 0.05564392603933811 Acc 0.9811938095092774 Perturbed Loss 0.05571133237332106
Loss 0.058050505775026975 Acc 0.9810468661785126 Perturbed Loss 0.0581595966918394
Loss 0.06684116719290614 Acc 0.9795866012573242 Perturbed Loss 0.06693819873034954
Loss 0.08533829774707556 Acc 0.9787330842018127 Perturbed Loss 0.08547205632552504
Loss 0.07365461178123951 Acc 0.9797894597053528 Perturbed Loss 0.0737448151782155
Loss 0.07082293577492237 Acc 0.9804442155361176 Perturbed Loss 0.07091162117198109
Loss 0.062296433113515376 Acc 0.983529521226883 Perturbed Loss 0.062351367827504875
Loss 0.06906233258545398 Acc 0.9771923911571503 Perturbed Loss 0.06916373420506716
Loss 0.06321345441043377 Acc 0.981442803144455 Perturbed Loss 0.06330380465835334
Loss 0.06208705376833677 Acc 0.9813998258113861 Perturbed Loss 0.06214611273258924
Loss 0.07646374475210906 Acc 0.9782112181186676 Perturbed Loss 0.07656627513468266
Epoch 15.0 val loss 0.056508298963308334 val acc 0.9793365001678467
Loss 0.06791273216716945 Acc 0.977358500957489 Perturbed Loss 0.06796625633724034
Loss 0.06743669219315052 Acc 0.9769574570655822 Perturbed Loss 0.06751607794314624
Loss 0.07233333701267838 Acc 0.9799729371070862 Perturbed Loss 0.072398236785084
Loss 0.06193497240543366 Acc 0.980459349155426 Perturbed Loss 0.06199715442955494
Loss 0.06262694688513876 Acc 0.9802822005748749 Perturbed Loss 0.06270880294963717
Loss 0.07107826704159378 Acc 0.980867029428482 Perturbed Loss 0.07115700190886855
Loss 0.06911081325262786 Acc 0.9806675493717194 Perturbed Loss 0.06917583622038365
Loss 0.06967261284589768 Acc 0.9789206218719483 Perturbed Loss 0.06979475788772106
Loss 0.06076036546379328 Acc 0.9808294427394867 Perturbed Loss 0.06087174212560058
Loss 0.057273886892944575 Acc 0.9840753364562989 Perturbed Loss 0.057349023260176185
Loss 0.06682726372033358 Acc 0.978035705089569 Perturbed Loss 0.06689524851739406
Loss 0.06630874238908291 Acc 0.981177932024002 Perturbed Loss 0.06636326972395182
Loss 0.06262406468391418 Acc 0.9799671268463135 Perturbed Loss 0.06272362370043993
Loss 0.06802194423973561 Acc 0.9812272834777832 Perturbed Loss 0.06808262061327695
Loss 0.05898022476583719 Acc 0.9836351633071899 Perturbed Loss 0.05904300782829523
Epoch 16.0 val loss 0.0567607507109642 val acc 0.9798076152801514
Loss 0.07078253757208586 Acc 0.9787499666213989 Perturbed Loss 0.07089239014312625
Loss 0.0712594735249877 Acc 0.9820509707927704 Perturbed Loss 0.07132274080067873
Loss 0.06114598473533988 Acc 0.9796903121471405 Perturbed Loss 0.06124302627518773
Loss 0.06803690187633038 Acc 0.9794991815090179 Perturbed Loss 0.06810524966567755
Loss 0.06138559494167566 Acc 0.9810443794727326 Perturbed Loss 0.06143907776102424
Loss 0.059117636904120446 Acc 0.9799666011333465 Perturbed Loss 0.05919476617127657
Loss 0.06737083608284593 Acc 0.9763928580284119 Perturbed Loss 0.0674719319306314
Loss 0.06575951535254716 Acc 0.9810101330280304 Perturbed Loss 0.0658464971370995
Loss 0.052168564088642594 Acc 0.9832568609714508 Perturbed Loss 0.05222785245627165
Loss 0.07940982162952423 Acc 0.9769314861297608 Perturbed Loss 0.079501793384552
Loss 0.06495326152071357 Acc 0.9786008679866791 Perturbed Loss 0.06504818346351385
Loss 0.06638190500438214 Acc 0.9789103651046753 Perturbed Loss 0.0664565023779869
Loss 0.06356583165004849 Acc 0.9748709833621979 Perturbed Loss 0.06363994598388673
Loss 0.06657495632767678 Acc 0.9784631872177124 Perturbed Loss 0.06671241683885455
Loss 0.06280883507803083 Acc 0.9826892006397248 Perturbed Loss 0.06288373295217753
Epoch 17.0 val loss 0.05702332779765129 val acc 0.9800023436546326
Loss 0.0652191923931241 Acc 0.9801045262813568 Perturbed Loss 0.06531842365860939
Loss 0.06852037660777568 Acc 0.9797080993652344 Perturbed Loss 0.06860704641789198
Loss 0.0643270794302225 Acc 0.9778236770629882 Perturbed Loss 0.06439960734918714
Loss 0.06566015910357237 Acc 0.9817497980594635 Perturbed Loss 0.06573786420747638
Loss 0.06384821819141508 Acc 0.9819017040729523 Perturbed Loss 0.0639487671200186
Loss 0.05550780389457941 Acc 0.9823868989944458 Perturbed Loss 0.05559365440160036
Loss 0.05879795424640179 Acc 0.9790764832496643 Perturbed Loss 0.05888151343911886
Loss 0.059638333460316065 Acc 0.9810076749324799 Perturbed Loss 0.0597619051579386
Loss 0.06672083534300327 Acc 0.9798256087303162 Perturbed Loss 0.06679550966247916
Loss 0.06423761289566755 Acc 0.9790237498283386 Perturbed Loss 0.0643043302744627
Loss 0.06313433472067118 Acc 0.9786805856227875 Perturbed Loss 0.0632240478694439
Loss 0.07550855118781329 Acc 0.9751965129375457 Perturbed Loss 0.07558635363355279
Loss 0.06321998594328761 Acc 0.9794483661651612 Perturbed Loss 0.06330543573945761
Loss 0.07647538177669048 Acc 0.9783894097805024 Perturbed Loss 0.07655853141099214
Loss 0.060913579557091 Acc 0.9777644968032837 Perturbed Loss 0.061005349662154915
Epoch 18.0 val loss 0.05603675916790962 val acc 0.9802610874176025
Loss 0.06728167418390513 Acc 0.9768699777126312 Perturbed Loss 0.06734469383955002
Loss 0.07226576466113328 Acc 0.978848785161972 Perturbed Loss 0.07234319236129522
Loss 0.06826277356594801 Acc 0.9792024898529053 Perturbed Loss 0.06833527751266956
Loss 0.05699035193771124 Acc 0.9795502614974976 Perturbed Loss 0.05710461117327213
Loss 0.05925804456695914 Acc 0.9822147870063782 Perturbed Loss 0.05931802136823535
Loss 0.06135132070630789 Acc 0.9776722776889801 Perturbed Loss 0.06141461854800582
Loss 0.0829634553194046 Acc 0.976545296907425 Perturbed Loss 0.08304201815277339
Loss 0.06410253504291177 Acc 0.9797199475765228 Perturbed Loss 0.06418336542323232
Loss 0.0610445467941463 Acc 0.9807988905906677 Perturbed Loss 0.06111256254836917
Loss 0.06269898448139428 Acc 0.9797751462459564 Perturbed Loss 0.0627757192030549
Loss 0.06945801896974445 Acc 0.9789397299289704 Perturbed Loss 0.06953265622258187
Loss 0.06153077187016606 Acc 0.978425166606903 Perturbed Loss 0.06158223945647478
Loss 0.0631718754954636 Acc 0.9797424530982971 Perturbed Loss 0.06326331065967679
Loss 0.07437134109437465 Acc 0.9799391484260559 Perturbed Loss 0.07451793923974037
Loss 0.0597113755531609 Acc 0.9817414319515229 Perturbed Loss 0.05978728357702494
Epoch 19.0 val loss 0.056479018181562424 val acc 0.9800851345062256
[08:21:01] INFO     `Trainer.fit` stopped: `max_epochs=20` reached.                                                                                                                         rank_zero.py:53
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750/750 0:03:45 • 0:00:00 3.36it/s train/loss: 0.06 val_loss: 0.056
LR GRID SEARCH
[08:21:04] INFO     Created a temporary directory at /tmp/tmp1ygkpv50                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmp1ygkpv50/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
           INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
           INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
           INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
[08:21:05] INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
           INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
[08:21:06] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.0015, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.1, adaptive=True)
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.0849772034212947 Acc 0.9666005146503448 Perturbed Loss 0.10394747901707888
[08:21:36] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.08049071665853262 Acc 0.9710755336284638 Perturbed Loss 0.0944666327163577
Loss 0.10574951251968741 Acc 0.9726094686985016 Perturbed Loss 0.1310611648671329
Loss 0.0969288158416748 Acc 0.970605628490448 Perturbed Loss 0.11103706426918507
Loss 0.09028791395947337 Acc 0.9722415935993195 Perturbed Loss 0.10558469094336033
Loss 0.11998011969029904 Acc 0.9610636484622955 Perturbed Loss 0.14276229102164506
Loss 0.10063740938901901 Acc 0.9685458207130432 Perturbed Loss 0.11602359283715487
Loss 0.09721755400300026 Acc 0.9776233649253845 Perturbed Loss 0.10720447856932878
Loss 0.1081875615566969 Acc 0.9707312774658203 Perturbed Loss 0.12191967159509659
Loss 0.10795204807072878 Acc 0.9674058759212494 Perturbed Loss 0.125083780400455
Loss 0.0975523691624403 Acc 0.9731516349315643 Perturbed Loss 0.11292441837489604
Loss 0.09993979474529624 Acc 0.9725452923774719 Perturbed Loss 0.11368878765031695
Loss 0.10593865256756545 Acc 0.9750361692905426 Perturbed Loss 0.12089319933205843
Loss 0.08972205195575952 Acc 0.9803891587257385 Perturbed Loss 0.1067006129026413
Loss 0.09830031042918563 Acc 0.9711365270614624 Perturbed Loss 0.11254552759230137
Epoch 0.0 val loss 0.07695691287517548 val acc 0.974785327911377
Loss 0.10691857490688562 Acc 0.9704274678230286 Perturbed Loss 0.12439565159380436
Loss 0.10384093508124352 Acc 0.9666426467895508 Perturbed Loss 0.11992209035903216
Loss 0.0954032177105546 Acc 0.9641279792785644 Perturbed Loss 0.10836226835846902
Loss 0.0914754468947649 Acc 0.9698153531551361 Perturbed Loss 0.10088092930614949
Loss 0.09704030860215425 Acc 0.973524091243744 Perturbed Loss 0.10750441379845142
Loss 0.09273719932883978 Acc 0.9736794924736023 Perturbed Loss 0.10504681706428527
Loss 0.09948785237967968 Acc 0.9722694838047028 Perturbed Loss 0.11171747133135795
Loss 0.09005799010396004 Acc 0.9737164843082428 Perturbed Loss 0.10439785044640303
Loss 0.09217313447967172 Acc 0.9752468919754028 Perturbed Loss 0.10421100471168757
Loss 0.09191212520003318 Acc 0.9752327561378479 Perturbed Loss 0.1026111453026533
Loss 0.08918474171310663 Acc 0.9668108987808227 Perturbed Loss 0.10189047377556562
Loss 0.10651186518371106 Acc 0.9711944758892059 Perturbed Loss 0.11912305817008019
Loss 0.0898841793090105 Acc 0.9782859873771668 Perturbed Loss 0.09992458395659924
Loss 0.1087770300731063 Acc 0.9694177436828614 Perturbed Loss 0.1213816038519144
Loss 0.092469790764153 Acc 0.9744697785377503 Perturbed Loss 0.10538445692509413
Epoch 1.0 val loss 0.06967896968126297 val acc 0.9761819243431091
Loss 0.08866561679169535 Acc 0.9725726473331452 Perturbed Loss 0.09581019513309003
Loss 0.09779693830758333 Acc 0.9768785655498504 Perturbed Loss 0.10838224072009325
Loss 0.08277830570936202 Acc 0.9762427723407745 Perturbed Loss 0.09148882240056992
Loss 0.07857038490474225 Acc 0.978313844203949 Perturbed Loss 0.08891347773373127
Loss 0.08613568808883429 Acc 0.9800251841545105 Perturbed Loss 0.10312437817454338
Loss 0.0891511993855238 Acc 0.9732594966888428 Perturbed Loss 0.09963073641061783
Loss 0.09355428013950587 Acc 0.976351933479309 Perturbed Loss 0.10528230141848326
Loss 0.09710207607597113 Acc 0.977083580493927 Perturbed Loss 0.11121882475912571
Loss 0.10440361902117729 Acc 0.9727415752410888 Perturbed Loss 0.11872740603983402
Loss 0.09546036768704652 Acc 0.9743424952030182 Perturbed Loss 0.1051248363405466
Loss 0.08212640166282653 Acc 0.9775521957874298 Perturbed Loss 0.09036854587495327
Loss 0.09268378719687462 Acc 0.973669959306717 Perturbed Loss 0.10361969139426946
Loss 0.09288115311414004 Acc 0.9696826112270355 Perturbed Loss 0.10561576560139656
Loss 0.10706994347274304 Acc 0.9663444316387176 Perturbed Loss 0.11907442793250084
Loss 0.10350175285711885 Acc 0.9735490441322326 Perturbed Loss 0.11496401209384204
Epoch 2.0 val loss 0.07272038608789444 val acc 0.9765318036079407
Loss 0.09007663089781999 Acc 0.97254314661026 Perturbed Loss 0.10195085920393467
Loss 0.08363753817975521 Acc 0.9754839789867401 Perturbed Loss 0.09412612043321132
Loss 0.08894613698124886 Acc 0.9760968995094299 Perturbed Loss 0.0995065862312913
Loss 0.08575568370521068 Acc 0.9780562198162079 Perturbed Loss 0.09807825833559036
Loss 0.09805112458765507 Acc 0.9733728063106537 Perturbed Loss 0.11235987342894077
Loss 0.09685359781607986 Acc 0.9731582570075988 Perturbed Loss 0.10702834617346525
Loss 0.08952869899570942 Acc 0.9766157400608063 Perturbed Loss 0.10301208727061749
Loss 0.09323670275509358 Acc 0.9734608936309814 Perturbed Loss 0.10373570911586284
Loss 0.10593723639845848 Acc 0.9746499538421631 Perturbed Loss 0.11920845784246921
Loss 0.09331323437392712 Acc 0.9735358357429504 Perturbed Loss 0.10202211771160365
Loss 0.07999124381691218 Acc 0.9747290921211242 Perturbed Loss 0.09110400583595038
Loss 0.10758122570812702 Acc 0.9690516602993011 Perturbed Loss 0.12071926645934582
Loss 0.10678058408200741 Acc 0.9724272239208221 Perturbed Loss 0.1157968109101057
Loss 0.08562081132084132 Acc 0.9713615608215332 Perturbed Loss 0.09576058827340603
Loss 0.0896210877224803 Acc 0.9753761398792267 Perturbed Loss 0.09741276260465384
Epoch 3.0 val loss 0.06851033866405487 val acc 0.9764388203620911
Loss 0.07493936527520419 Acc 0.9796652603149414 Perturbed Loss 0.08411437261849641
Loss 0.0827029625698924 Acc 0.980948930978775 Perturbed Loss 0.09038417022675276
Loss 0.07415822345763445 Acc 0.9723114800453186 Perturbed Loss 0.08356512565165758
Loss 0.09914131291210651 Acc 0.9758223640918732 Perturbed Loss 0.11029321484267712
Loss 0.08996946720406412 Acc 0.9735240054130554 Perturbed Loss 0.0985070706345141
Loss 0.08663186663761735 Acc 0.9759742927551269 Perturbed Loss 0.09835584670305252
Loss 0.08235780633985997 Acc 0.9766242671012878 Perturbed Loss 0.09300549626350403
Loss 0.07835239864885807 Acc 0.9773955178260804 Perturbed Loss 0.08621211867779494
Loss 0.08390557985752821 Acc 0.9743426334857941 Perturbed Loss 0.09794164340943098
Loss 0.08789985390380024 Acc 0.9757474899291992 Perturbed Loss 0.10582313124090433
Loss 0.11759612277150154 Acc 0.9711657750606537 Perturbed Loss 0.13387328889220954
Loss 0.0993220991268754 Acc 0.969408187866211 Perturbed Loss 0.11403206177055836
Loss 0.09811132200062275 Acc 0.970823061466217 Perturbed Loss 0.10980218347162009
Loss 0.09430487792938948 Acc 0.9766757643222809 Perturbed Loss 0.10532797012478114
Loss 0.09447751805186272 Acc 0.976196905374527 Perturbed Loss 0.10774363372474909
Epoch 4.0 val loss 0.07105573266744614 val acc 0.9750234484672546
Loss 0.08080142643302679 Acc 0.9762186968326568 Perturbed Loss 0.0884510413184762
Loss 0.09822653993964195 Acc 0.9764477956295013 Perturbed Loss 0.10985356315970421
Loss 0.09947919838130474 Acc 0.9743549013137818 Perturbed Loss 0.10925118539482355
Loss 0.0963612457178533 Acc 0.9708784818649292 Perturbed Loss 0.10579115245491266
Loss 0.0828454003483057 Acc 0.9761229085922242 Perturbed Loss 0.09253532081842422
Loss 0.08936764273792505 Acc 0.9740373027324677 Perturbed Loss 0.09733918316662311
Loss 0.0774946342036128 Acc 0.977874002456665 Perturbed Loss 0.08545803844928741
Loss 0.08003673736006021 Acc 0.9754228138923645 Perturbed Loss 0.08856668755412102
Loss 0.09169673167169094 Acc 0.9763521075248718 Perturbed Loss 0.10085110690444708
Loss 0.08677836135029793 Acc 0.9767264258861542 Perturbed Loss 0.09875845048576594
Loss 0.08568190984427929 Acc 0.9768298518657684 Perturbed Loss 0.09396923027932644
Loss 0.09329208683222533 Acc 0.9722469687461853 Perturbed Loss 0.1016972379013896
Loss 0.089786173440516 Acc 0.9774875795841217 Perturbed Loss 0.09864645354449748
Loss 0.0857949010655284 Acc 0.9751782619953155 Perturbed Loss 0.09260333832353354
Loss 0.08628722498193384 Acc 0.9754312932491302 Perturbed Loss 0.09602975357323885
Epoch 5.0 val loss 0.0713375061750412 val acc 0.9765474796295166
Loss 0.08497368674725295 Acc 0.9758824014663696 Perturbed Loss 0.09261122889816761
Loss 0.08540901046246291 Acc 0.9750310730934143 Perturbed Loss 0.09459960415959358
Loss 0.09096435278654098 Acc 0.9760421228408813 Perturbed Loss 0.09872642450034619
Loss 0.09828437563031912 Acc 0.9733913671970368 Perturbed Loss 0.1062805063277483
Loss 0.08237130315974354 Acc 0.979013501405716 Perturbed Loss 0.09000789558514953
Loss 0.08911388751119376 Acc 0.9744607317447662 Perturbed Loss 0.09853098012506961
Loss 0.08754258323460817 Acc 0.9738180768489838 Perturbed Loss 0.09879918865859509
Loss 0.08118843007832766 Acc 0.9802333891391755 Perturbed Loss 0.09065260585397482
Loss 0.0899976110085845 Acc 0.975784205198288 Perturbed Loss 0.10107202101498843
Loss 0.09179048899561167 Acc 0.9740923321247101 Perturbed Loss 0.102646369561553
Loss 0.08889680497348308 Acc 0.9754674375057221 Perturbed Loss 0.10176364861428738
Loss 0.0932443499751389 Acc 0.9742299890518189 Perturbed Loss 0.10576999809592963
Loss 0.08453159879893064 Acc 0.9733591985702514 Perturbed Loss 0.09479467745870351
Loss 0.08924403924494982 Acc 0.977205023765564 Perturbed Loss 0.10004980444908142
Loss 0.08505507439374924 Acc 0.971979969739914 Perturbed Loss 0.09415217399597169
Epoch 6.0 val loss 0.06828606873750687 val acc 0.9772234559059143
Loss 0.09790501866489648 Acc 0.9744281947612763 Perturbed Loss 0.10736498031765222
Loss 0.09621417868882418 Acc 0.9759786558151246 Perturbed Loss 0.10396214138716459
Loss 0.08210220448672771 Acc 0.9748803651332856 Perturbed Loss 0.0900274745002389
Loss 0.07657196084037424 Acc 0.979915679693222 Perturbed Loss 0.08638859720900655
Loss 0.07866888171061874 Acc 0.9744602739810944 Perturbed Loss 0.08641432408243417
Loss 0.0851126484759152 Acc 0.9764482736587524 Perturbed Loss 0.09267919663339853
Loss 0.09045293148607016 Acc 0.9725190699100494 Perturbed Loss 0.10067533280700446
Loss 0.07237194132059813 Acc 0.978083678483963 Perturbed Loss 0.08010798882693053
Loss 0.08875408392399549 Acc 0.9753407776355744 Perturbed Loss 0.09852445930242539
Loss 0.0911193934455514 Acc 0.9757208502292634 Perturbed Loss 0.10003692749887705
Loss 0.08502327159047127 Acc 0.980505039691925 Perturbed Loss 0.09375226024538279
Loss 0.07740565398707985 Acc 0.9785540640354157 Perturbed Loss 0.08356214717030525
Loss 0.07583147790282965 Acc 0.9765179431438447 Perturbed Loss 0.08298774681985378
Loss 0.07699119381606578 Acc 0.9795966160297394 Perturbed Loss 0.08400616239756346
Loss 0.08657411243766547 Acc 0.9756226181983948 Perturbed Loss 0.09536237727850676
Epoch 7.0 val loss 0.06668023020029068 val acc 0.9775665998458862
Loss 0.07553002543747425 Acc 0.9761965775489807 Perturbed Loss 0.08392048794776201
Loss 0.0763542887289077 Acc 0.971885050535202 Perturbed Loss 0.0848447808623314
Loss 0.0769174948334694 Acc 0.9763398134708404 Perturbed Loss 0.08354054342955351
Loss 0.08394684877246618 Acc 0.9750266706943512 Perturbed Loss 0.09110743504017592
Loss 0.07692184267565608 Acc 0.9771716284751892 Perturbed Loss 0.08815696090459824
Loss 0.08648159187287092 Acc 0.97483811378479 Perturbed Loss 0.09494639225304127
Loss 0.07770520932972431 Acc 0.9750639700889587 Perturbed Loss 0.08556636903434992
Loss 0.07610328271985053 Acc 0.9758322584629059 Perturbed Loss 0.08192477442324161
Loss 0.079477275069803 Acc 0.9745180141925812 Perturbed Loss 0.08936718411743641
Loss 0.07751412464305758 Acc 0.9728025710582733 Perturbed Loss 0.08604880817234516
Loss 0.08425577200949191 Acc 0.9770576190948487 Perturbed Loss 0.09577683918178082
Loss 0.08453697808086873 Acc 0.9759385347366333 Perturbed Loss 0.0933422102406621
Loss 0.07779531698673964 Acc 0.9770066559314727 Perturbed Loss 0.08639965619891882
Loss 0.0859572290442884 Acc 0.9761539351940155 Perturbed Loss 0.09888451058417559
Loss 0.08891449492424726 Acc 0.97807213306427 Perturbed Loss 0.09660127276554703
Epoch 8.0 val loss 0.06992121785879135 val acc 0.9772180914878845
Loss 0.08480562906712294 Acc 0.973735305070877 Perturbed Loss 0.09427034579217435
Loss 0.08326612398028374 Acc 0.975855803489685 Perturbed Loss 0.09186742406338454
Loss 0.08592481233179569 Acc 0.9755188536643982 Perturbed Loss 0.0939402051642537
Loss 0.0671178587153554 Acc 0.9778872275352478 Perturbed Loss 0.07363658130168915
Loss 0.08156861808151007 Acc 0.973994824886322 Perturbed Loss 0.09278489783406257
Loss 0.08127123143523932 Acc 0.9752791929244995 Perturbed Loss 0.0896217006072402
Loss 0.0744677278213203 Acc 0.9792822659015655 Perturbed Loss 0.07999256525188685
Loss 0.08870092526078224 Acc 0.9769904935359954 Perturbed Loss 0.09605680674314498
Loss 0.07612048149108887 Acc 0.976275817155838 Perturbed Loss 0.08715460266917945
Loss 0.0786622892692685 Acc 0.9791033136844635 Perturbed Loss 0.087607052475214
Loss 0.07981068551540375 Acc 0.9773808884620666 Perturbed Loss 0.08912814509123564
Loss 0.07920453464612365 Acc 0.9771156299114228 Perturbed Loss 0.08583682278171181
Loss 0.07935352604836225 Acc 0.9753139805793762 Perturbed Loss 0.08740675710141659
Loss 0.09515115220099687 Acc 0.9736206603050231 Perturbed Loss 0.10522505559027195
Loss 0.08550910063087941 Acc 0.9747731447219848 Perturbed Loss 0.09533902615308762
Epoch 9.0 val loss 0.06593180447816849 val acc 0.9770351052284241
Loss 0.08041367007419467 Acc 0.9799550926685333 Perturbed Loss 0.09152910426259041
Loss 0.07799844931811094 Acc 0.9748167431354523 Perturbed Loss 0.08435726817697287
Loss 0.07820046417415143 Acc 0.9787922894954681 Perturbed Loss 0.08507937120273709
Loss 0.09102912349626421 Acc 0.9729010891914368 Perturbed Loss 0.09789456384256483
Loss 0.06916015753522516 Acc 0.9803947949409485 Perturbed Loss 0.07522363597527146
Loss 0.07249746213667095 Acc 0.9789794480800629 Perturbed Loss 0.07864651808515191
Loss 0.07323644112795591 Acc 0.976419483423233 Perturbed Loss 0.08092499125748873
Loss 0.0731169603858143 Acc 0.9815196537971497 Perturbed Loss 0.0793340563774109
Loss 0.06956033814698458 Acc 0.9752580010890961 Perturbed Loss 0.07888018131256104
Loss 0.07732863407582044 Acc 0.9755460631847381 Perturbed Loss 0.08627216659486293
Loss 0.0751651781052351 Acc 0.9774422335624695 Perturbed Loss 0.083051204867661
Loss 0.08266195748001337 Acc 0.9764796578884125 Perturbed Loss 0.09207987587898969
Loss 0.07064705301076174 Acc 0.9790753185749054 Perturbed Loss 0.07729617819190025
Loss 0.07372854012995958 Acc 0.9759196090698242 Perturbed Loss 0.08040596526116132
Loss 0.07361686050891876 Acc 0.977237708568573 Perturbed Loss 0.0807824806496501
Epoch 10.0 val loss 0.06527446210384369 val acc 0.9777621626853943
Loss 0.07848043480888009 Acc 0.977299518585205 Perturbed Loss 0.08829867705702782
Loss 0.07761060146614909 Acc 0.9795455050468445 Perturbed Loss 0.08651951840147376
Loss 0.07422008467838168 Acc 0.9779808652400971 Perturbed Loss 0.08106038151308895
Loss 0.07040458161383867 Acc 0.9777725636959076 Perturbed Loss 0.07723179247230291
Loss 0.07540910061448812 Acc 0.9767246079444886 Perturbed Loss 0.08205398447811603
Loss 0.07166315812617541 Acc 0.9770639371871949 Perturbed Loss 0.08107448793947697
Loss 0.07815139774233103 Acc 0.9756751489639283 Perturbed Loss 0.08652618415653705
Loss 0.08597060203552247 Acc 0.97591228723526 Perturbed Loss 0.09505408369004727
Loss 0.06906620252877474 Acc 0.9790343582630158 Perturbed Loss 0.0757062385417521
Loss 0.07439894795417785 Acc 0.9802393436431884 Perturbed Loss 0.08279031939804554
Loss 0.07826837241649627 Acc 0.9766321790218353 Perturbed Loss 0.08635906238108873
Loss 0.07881746277213096 Acc 0.9790994203090668 Perturbed Loss 0.0879404380172491
Loss 0.08913899846374988 Acc 0.9740981042385102 Perturbed Loss 0.09714713998138905
Loss 0.0716833994165063 Acc 0.9800329279899597 Perturbed Loss 0.08085935223847628
Loss 0.0685120933689177 Acc 0.9783855426311493 Perturbed Loss 0.0753889387845993
Epoch 11.0 val loss 0.06452985107898712 val acc 0.9777067303657532
Loss 0.08640035916119813 Acc 0.9768803083896637 Perturbed Loss 0.09309277158230543
Loss 0.08392093103379011 Acc 0.9758322095870972 Perturbed Loss 0.0922223125398159
Loss 0.07810349725186824 Acc 0.9817114627361297 Perturbed Loss 0.08376742590218783
Loss 0.07025993954390287 Acc 0.9785611367225647 Perturbed Loss 0.07981275718659163
Loss 0.068906843457371 Acc 0.982570503950119 Perturbed Loss 0.076451314445585
Loss 0.06869133895263076 Acc 0.9789405107498169 Perturbed Loss 0.07957766570150852
Loss 0.07865435501560569 Acc 0.9785307478904725 Perturbed Loss 0.08610100710764527
Loss 0.06817934302613139 Acc 0.9788438582420349 Perturbed Loss 0.07404533853754401
Loss 0.06922920655459165 Acc 0.9769139063358306 Perturbed Loss 0.07831611722707749
Loss 0.06855559518560767 Acc 0.9794734001159668 Perturbed Loss 0.07609056143090129
Loss 0.07819126376882196 Acc 0.978916026353836 Perturbed Loss 0.08663600821048022
Loss 0.07296875262632967 Acc 0.9733941864967346 Perturbed Loss 0.08004845840856432
Loss 0.09390403902158141 Acc 0.9787540781497955 Perturbed Loss 0.10281275874003767
Loss 0.07753534890711307 Acc 0.9793705403804779 Perturbed Loss 0.08615764442831278
Loss 0.07763418182730675 Acc 0.9741389775276184 Perturbed Loss 0.08467804495245218
Epoch 12.0 val loss 0.06346514075994492 val acc 0.9783207774162292
Loss 0.08219798909500241 Acc 0.9768819880485534 Perturbed Loss 0.09121574930846692
Loss 0.0852175124362111 Acc 0.9770660972595215 Perturbed Loss 0.09333453509956598
Loss 0.08215383142232895 Acc 0.9775340592861176 Perturbed Loss 0.08780515890568495
Loss 0.07300484508275985 Acc 0.9813165450096131 Perturbed Loss 0.08062805771827698
Loss 0.07062291074544191 Acc 0.9785560178756714 Perturbed Loss 0.07857284845784307
Loss 0.0748976743966341 Acc 0.9802355599403382 Perturbed Loss 0.07981605991721154
Loss 0.07841810565441847 Acc 0.9740513908863068 Perturbed Loss 0.0834936386719346
Loss 0.07482939342036843 Acc 0.9776315832138062 Perturbed Loss 0.08149423162452876
Loss 0.07757629983127118 Acc 0.9765620362758637 Perturbed Loss 0.08326759282499552
Loss 0.07096599398180842 Acc 0.9800544083118439 Perturbed Loss 0.07721247181296348
Loss 0.07966491233557463 Acc 0.9776728868484497 Perturbed Loss 0.0868175494670868
Loss 0.07711456634104252 Acc 0.9800087583065032 Perturbed Loss 0.08334268026053905
Loss 0.06953253669664264 Acc 0.9772013294696807 Perturbed Loss 0.07570833129808306
Loss 0.06332494819536805 Acc 0.9808489692211151 Perturbed Loss 0.07230684878304601
Loss 0.07296185094863177 Acc 0.9824159669876099 Perturbed Loss 0.08073686063289642
Epoch 13.0 val loss 0.064151830971241 val acc 0.9784114956855774
Loss 0.06746007025241851 Acc 0.979131338596344 Perturbed Loss 0.0730204302445054
Loss 0.08032650403678417 Acc 0.9766207277774811 Perturbed Loss 0.08856773588806391
Loss 0.07135717591270804 Acc 0.9794827485084534 Perturbed Loss 0.07591591462492943
Loss 0.07433313822373748 Acc 0.9764902472496033 Perturbed Loss 0.0802070764824748
Loss 0.0758267079293728 Acc 0.9770870280265808 Perturbed Loss 0.08383443616330624
Loss 0.06414109187200666 Acc 0.9805772590637207 Perturbed Loss 0.07032223962247372
Loss 0.06802824478596449 Acc 0.9801412796974183 Perturbed Loss 0.07420191425830126
Loss 0.06253345372155308 Acc 0.9796801900863648 Perturbed Loss 0.06911768972873687
Loss 0.06919162962585687 Acc 0.9810475528240203 Perturbed Loss 0.07571952383965254
Loss 0.07222519241273404 Acc 0.9751983892917633 Perturbed Loss 0.080842210277915
Loss 0.07683945041149855 Acc 0.9791473758220672 Perturbed Loss 0.08325914576649666
Loss 0.07142852921038866 Acc 0.9763558864593506 Perturbed Loss 0.07826631277799606
Loss 0.0760361303202808 Acc 0.9799656212329865 Perturbed Loss 0.08211964257061481
Loss 0.08086719192564487 Acc 0.9743264400959015 Perturbed Loss 0.08869004596024752
Loss 0.06949751980602742 Acc 0.9778088450431823 Perturbed Loss 0.0749909596517682
Epoch 14.0 val loss 0.06110972538590431 val acc 0.9786604046821594
Loss 0.07229372968897224 Acc 0.9754999220371247 Perturbed Loss 0.07801747666671872
Loss 0.07455470234155655 Acc 0.9799107885360718 Perturbed Loss 0.08273854169994593
Loss 0.07857857411727309 Acc 0.9736167395114899 Perturbed Loss 0.08684035938233137
Loss 0.07813397189602256 Acc 0.9783915174007416 Perturbed Loss 0.08692496430128813
Loss 0.06341472646221519 Acc 0.9799047553539276 Perturbed Loss 0.07104720624163746
Loss 0.0629498663591221 Acc 0.9810432744026184 Perturbed Loss 0.06869451923295855
Loss 0.07242181903682648 Acc 0.979147254228592 Perturbed Loss 0.07813099707476795
Loss 0.08916672660037875 Acc 0.9773113477230072 Perturbed Loss 0.0976970799267292
Loss 0.08167336717247962 Acc 0.9783886849880219 Perturbed Loss 0.09152300078421831
Loss 0.0785125028528273 Acc 0.9790897095203399 Perturbed Loss 0.0843458180502057
Loss 0.06755396943539381 Acc 0.982837462425232 Perturbed Loss 0.07262733537703753
Loss 0.07456954468041659 Acc 0.9771134054660797 Perturbed Loss 0.08077341590076685
Loss 0.06789046626538038 Acc 0.9814352726936341 Perturbed Loss 0.07379242796450854
Loss 0.06738973997533321 Acc 0.9812572526931763 Perturbed Loss 0.07397986270487308
Loss 0.07853545468300581 Acc 0.9780406665802002 Perturbed Loss 0.08525895535945892
Epoch 15.0 val loss 0.06188809126615524 val acc 0.978692352771759
Loss 0.0709870140440762 Acc 0.9779910457134247 Perturbed Loss 0.07744668630883098
Loss 0.07293998818844556 Acc 0.9769357776641846 Perturbed Loss 0.08166495431214571
Loss 0.08140531595796346 Acc 0.9787110376358032 Perturbed Loss 0.09044024664908648
Loss 0.0669130489230156 Acc 0.9795802295207977 Perturbed Loss 0.07155193313956261
Loss 0.06458446649834514 Acc 0.9797243547439575 Perturbed Loss 0.07110265988856554
Loss 0.07698437621816993 Acc 0.9796805489063263 Perturbed Loss 0.08325483841821552
Loss 0.07871899683028459 Acc 0.9802241110801697 Perturbed Loss 0.0844478915259242
Loss 0.0795930041000247 Acc 0.9782448589801789 Perturbed Loss 0.08621470052748918
Loss 0.07202650932595134 Acc 0.980123131275177 Perturbed Loss 0.07836875107139349
Loss 0.05942346664145589 Acc 0.9836628103256225 Perturbed Loss 0.06527738939970731
Loss 0.0733934336528182 Acc 0.9777771830558777 Perturbed Loss 0.07981664165854455
Loss 0.06543045916594564 Acc 0.9806162369251251 Perturbed Loss 0.07136748844757676
Loss 0.06803042709827423 Acc 0.9812886011600495 Perturbed Loss 0.07411726891994476
Loss 0.07026061089709401 Acc 0.9810808444023132 Perturbed Loss 0.07570182366296649
Loss 0.06218159165233374 Acc 0.9831711113452911 Perturbed Loss 0.06839380536228418
Epoch 16.0 val loss 0.060122326016426086 val acc 0.9790515303611755
Loss 0.07334853636100888 Acc 0.9804671788215638 Perturbed Loss 0.08009778123348951
Loss 0.07131416894495488 Acc 0.9819871020317078 Perturbed Loss 0.07834120698273182
Loss 0.06198682572692633 Acc 0.9798282241821289 Perturbed Loss 0.06799329198896885
Loss 0.07157161364331842 Acc 0.9792042994499206 Perturbed Loss 0.07960859332233668
Loss 0.0676945099234581 Acc 0.9800402522087097 Perturbed Loss 0.07367319460958242
Loss 0.06081677012145519 Acc 0.9797030174732209 Perturbed Loss 0.06809685006737709
Loss 0.07370290193706751 Acc 0.976602668762207 Perturbed Loss 0.08044073481112718
Loss 0.0691844505816698 Acc 0.9807066392898559 Perturbed Loss 0.07537094630300999
Loss 0.058203775733709336 Acc 0.9824935102462768 Perturbed Loss 0.06435774272307754
Loss 0.08006906673312188 Acc 0.9771367681026458 Perturbed Loss 0.08604029338806868
Loss 0.06559285081923008 Acc 0.9785496854782104 Perturbed Loss 0.0705806503072381
Loss 0.0726225734129548 Acc 0.9777860832214356 Perturbed Loss 0.0784073344245553
Loss 0.0648013429902494 Acc 0.9741231203079224 Perturbed Loss 0.07042077159509062
Loss 0.0682643069513142 Acc 0.9794434094429016 Perturbed Loss 0.07456355471163988
Loss 0.06674880117177963 Acc 0.9822569668293 Perturbed Loss 0.073339177146554
Epoch 17.0 val loss 0.06081641837954521 val acc 0.9788736701011658
Loss 0.07018716637045146 Acc 0.9801980459690094 Perturbed Loss 0.07702049095183611
Loss 0.07609087482094765 Acc 0.9806119120121002 Perturbed Loss 0.08389480214565992
Loss 0.07037012238055468 Acc 0.9767690205574036 Perturbed Loss 0.07624864624813199
Loss 0.06919679755344987 Acc 0.981974458694458 Perturbed Loss 0.07547035679221153
Loss 0.06520691383630037 Acc 0.9813300597667695 Perturbed Loss 0.07057532342150807
Loss 0.06056608684360981 Acc 0.9823029017448426 Perturbed Loss 0.06520888535305858
Loss 0.060208696871995926 Acc 0.9789765524864197 Perturbed Loss 0.06603655520826578
Loss 0.06381205223500729 Acc 0.9811763978004455 Perturbed Loss 0.07051206693053245
Loss 0.06954578852280974 Acc 0.980360233783722 Perturbed Loss 0.07427115121856331
Loss 0.06785884205251932 Acc 0.9787741482257843 Perturbed Loss 0.07269055154174567
Loss 0.06654570583254099 Acc 0.9783011198043823 Perturbed Loss 0.07306336648762227
Loss 0.07904364362359047 Acc 0.9748495602607727 Perturbed Loss 0.08503018744289875
Loss 0.0673485228419304 Acc 0.9787805747985839 Perturbed Loss 0.07408546656370163
Loss 0.07926995526999235 Acc 0.9782086622714996 Perturbed Loss 0.08569160137325525
Loss 0.06121308891102672 Acc 0.9786129963397979 Perturbed Loss 0.06633896162733435
Epoch 18.0 val loss 0.05970476567745209 val acc 0.9792196750640869
Loss 0.06900185618549586 Acc 0.97659135222435 Perturbed Loss 0.0743555823713541
Loss 0.07140697531402111 Acc 0.9787069153785706 Perturbed Loss 0.07798322323709726
Loss 0.06957489140331745 Acc 0.9794622194766999 Perturbed Loss 0.07530316282063723
Loss 0.058928305394947526 Acc 0.9791470181941986 Perturbed Loss 0.06420648116618395
Loss 0.06350449949502945 Acc 0.9825422620773315 Perturbed Loss 0.06839675277471542
Loss 0.06521329771727323 Acc 0.9785009074211121 Perturbed Loss 0.07199185773730278
Loss 0.08583559516817331 Acc 0.9756660759449005 Perturbed Loss 0.09389189027249813
Loss 0.06617955517023802 Acc 0.9797334754467011 Perturbed Loss 0.07157507792115211
Loss 0.06443227650597691 Acc 0.9806922817230225 Perturbed Loss 0.07036455513909459
Loss 0.06479718931019306 Acc 0.9803526246547699 Perturbed Loss 0.07138713967055083
Loss 0.07035222956910729 Acc 0.9791734850406647 Perturbed Loss 0.07594022097066044
Loss 0.06303775805979966 Acc 0.9780771148204803 Perturbed Loss 0.06872376743704081
Loss 0.06863218080252409 Acc 0.9793418335914612 Perturbed Loss 0.07273350037634373
Loss 0.07914673086255788 Acc 0.9802667045593262 Perturbed Loss 0.08685452099889517
Loss 0.0612779526039958 Acc 0.9825066828727722 Perturbed Loss 0.06589999491348862
Epoch 19.0 val loss 0.06001558527350426 val acc 0.9792072176933289
[09:44:57] INFO     `Trainer.fit` stopped: `max_epochs=20` reached.                                                                                                                         rank_zero.py:53
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750/750 0:03:45 • 0:00:00 3.35it/s train/loss: 0.061 val_loss: 0.06
[09:44:59] INFO     Created a temporary directory at /tmp/tmpv3ad_k4l                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmpv3ad_k4l/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
           INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
[09:45:00] INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
           INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
           INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
           INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
[09:45:01] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.0008, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.1, adaptive=True)
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.08760086830705405 Acc 0.9661770284175872 Perturbed Loss 0.10888714328408242
[09:45:31] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.07790008954703807 Acc 0.9717405462265014 Perturbed Loss 0.09326674014329911
Loss 0.08523494105786085 Acc 0.9773353517055512 Perturbed Loss 0.09857050120830536
Loss 0.08455773318186402 Acc 0.9740973317623138 Perturbed Loss 0.09659785468131304
Loss 0.08690622825175524 Acc 0.9764528894424438 Perturbed Loss 0.10026515267789364
Loss 0.09940097715705633 Acc 0.9642436408996582 Perturbed Loss 0.11715207330882549
Loss 0.08920016676187516 Acc 0.9696503400802612 Perturbed Loss 0.10474523428827524
Loss 0.08273123780265451 Acc 0.9781771123409271 Perturbed Loss 0.09455844957381487
Loss 0.09006535418331624 Acc 0.9734280097484589 Perturbed Loss 0.10241028241813183
Loss 0.0900546059012413 Acc 0.970229423046112 Perturbed Loss 0.10474463883787394
Loss 0.07645076010376214 Acc 0.9766138470172883 Perturbed Loss 0.08573491230607033
Loss 0.09261321540921927 Acc 0.9760047316551208 Perturbed Loss 0.1075378742441535
Loss 0.08657707324251533 Acc 0.9751362681388855 Perturbed Loss 0.10266707673668861
Loss 0.07936391398310662 Acc 0.9796141576766968 Perturbed Loss 0.09508208315819502
Loss 0.0852061403542757 Acc 0.9740135455131531 Perturbed Loss 0.09884669544175267
Epoch 0.0 val loss 0.05965382605791092 val acc 0.9785946011543274
Loss 0.0881114836037159 Acc 0.973985196352005 Perturbed Loss 0.0990876567363739
Loss 0.07750275563448668 Acc 0.973096033334732 Perturbed Loss 0.08807779438793659
Loss 0.082042725533247 Acc 0.968036743402481 Perturbed Loss 0.09668699622154237
Loss 0.08149755105376244 Acc 0.9742138016223908 Perturbed Loss 0.09302965626120567
Loss 0.08391209984198213 Acc 0.9743367063999177 Perturbed Loss 0.09492029272019863
Loss 0.0780196443013847 Acc 0.9763462638854981 Perturbed Loss 0.09019115217030048
Loss 0.08810154348611832 Acc 0.9753595292568207 Perturbed Loss 0.09935659226030111
Loss 0.07638461669906974 Acc 0.9774652063846588 Perturbed Loss 0.08479889951646329
Loss 0.07400106865912676 Acc 0.9788770186901092 Perturbed Loss 0.08315843263641
Loss 0.07814031008630991 Acc 0.9765884590148926 Perturbed Loss 0.09031289156526327
Loss 0.07986074035987258 Acc 0.9677813172340393 Perturbed Loss 0.09515980448573828
Loss 0.09947135709226132 Acc 0.970672013759613 Perturbed Loss 0.11243451688438653
Loss 0.08033448062837124 Acc 0.980011477470398 Perturbed Loss 0.08886820044368506
Loss 0.09753478003665805 Acc 0.9721492397785186 Perturbed Loss 0.10973436707630753
Loss 0.08454213675111533 Acc 0.9753514397144317 Perturbed Loss 0.09532472029328347
Epoch 1.0 val loss 0.06216580793261528 val acc 0.9784943461418152
Loss 0.07781849330291152 Acc 0.9751122832298279 Perturbed Loss 0.08645368641242385
Loss 0.09267609998583794 Acc 0.977556380033493 Perturbed Loss 0.10252221453934908
Loss 0.08167301818728447 Acc 0.977975240945816 Perturbed Loss 0.09417590200901031
Loss 0.07086095724254847 Acc 0.9819860446453095 Perturbed Loss 0.0812122654542327
Loss 0.0750506653264165 Acc 0.9803958129882813 Perturbed Loss 0.0836349906027317
Loss 0.06984620574861765 Acc 0.9777772760391236 Perturbed Loss 0.07838741522282362
Loss 0.08141150765120983 Acc 0.9792356240749359 Perturbed Loss 0.09260804701596498
Loss 0.07892638217657805 Acc 0.9811684656143188 Perturbed Loss 0.0928688245639205
Loss 0.08664592191576957 Acc 0.975108871459961 Perturbed Loss 0.09933160591870546
Loss 0.08891403403133154 Acc 0.9769036722183227 Perturbed Loss 0.10026257317513228
Loss 0.07375424142926931 Acc 0.9784942018985748 Perturbed Loss 0.08316520754247904
Loss 0.08498047042638063 Acc 0.9740410363674163 Perturbed Loss 0.09490995168685913
Loss 0.0900298485532403 Acc 0.9699063670635223 Perturbed Loss 0.1063763104379177
Loss 0.10395977810025216 Acc 0.9673300850391388 Perturbed Loss 0.11551879175007343
Loss 0.08972169920802116 Acc 0.9742755353450775 Perturbed Loss 0.10160610947757959
Epoch 2.0 val loss 0.06101052090525627 val acc 0.9789345860481262
Loss 0.07984576810151339 Acc 0.9756072187423706 Perturbed Loss 0.09035601541399955
Loss 0.07262829385697842 Acc 0.9779538238048553 Perturbed Loss 0.08128713738173246
Loss 0.08057941902428865 Acc 0.9782855927944183 Perturbed Loss 0.09317704003304243
Loss 0.08579044282436371 Acc 0.976988571882248 Perturbed Loss 0.09909042332321405
Loss 0.08774101249873638 Acc 0.9749894595146179 Perturbed Loss 0.10054785966873168
Loss 0.08696679193526506 Acc 0.9752132499217987 Perturbed Loss 0.10118084203451871
Loss 0.07629797987639904 Acc 0.9814789080619812 Perturbed Loss 0.08515070527791976
Loss 0.08263075407594442 Acc 0.9766968095302582 Perturbed Loss 0.09215441592037678
Loss 0.08643434714525938 Acc 0.9772119724750519 Perturbed Loss 0.09659628085792064
Loss 0.07654801439493894 Acc 0.9762097465991973 Perturbed Loss 0.0840938925743103
Loss 0.06553252140060067 Acc 0.9780901408195496 Perturbed Loss 0.0741496878117323
Loss 0.0932247356325388 Acc 0.9732522988319396 Perturbed Loss 0.10327232092618942
Loss 0.09154793083667755 Acc 0.9759581589698791 Perturbed Loss 0.10221458304673434
Loss 0.0791121387667954 Acc 0.9726717340946197 Perturbed Loss 0.0878702393360436
Loss 0.08203945152461528 Acc 0.9769829368591308 Perturbed Loss 0.0898186020925641
Epoch 3.0 val loss 0.05894492194056511 val acc 0.9785171151161194
Loss 0.06545350499451161 Acc 0.9815455532073974 Perturbed Loss 0.0737672184035182
Loss 0.07523965716362 Acc 0.9821079015731812 Perturbed Loss 0.08274212185293436
Loss 0.06649995502084494 Acc 0.9743081629276276 Perturbed Loss 0.07462636232376099
Loss 0.09132107096724212 Acc 0.9771806108951568 Perturbed Loss 0.10200635209679604
Loss 0.07989594852551818 Acc 0.9751293420791626 Perturbed Loss 0.08949588183313609
Loss 0.07652604976668954 Acc 0.9773672878742218 Perturbed Loss 0.08636536145582795
Loss 0.07272655211389065 Acc 0.9778884398937225 Perturbed Loss 0.0841771925240755
Loss 0.0754644687846303 Acc 0.9770408761501312 Perturbed Loss 0.0844088288396597
Loss 0.07835865974426269 Acc 0.9742262613773346 Perturbed Loss 0.09040973348543048
Loss 0.0729722922667861 Acc 0.9770806515216828 Perturbed Loss 0.08274605305865407
Loss 0.08478183466941118 Acc 0.9787123942375183 Perturbed Loss 0.09775797843933105
Loss 0.08255105681717395 Acc 0.9749005901813507 Perturbed Loss 0.0917469135671854
Loss 0.08505514478310942 Acc 0.9752869606018066 Perturbed Loss 0.09441593073308469
Loss 0.08037747249007225 Acc 0.9790181028842926 Perturbed Loss 0.0885175460204482
Loss 0.07407168803736568 Acc 0.9794604933261871 Perturbed Loss 0.08264338247478008
Epoch 4.0 val loss 0.061776477843523026 val acc 0.9791170358657837
Loss 0.07273514620959759 Acc 0.9780875813961029 Perturbed Loss 0.08064593601971864
Loss 0.08449547927826644 Acc 0.9793670678138733 Perturbed Loss 0.0936508559435606
Loss 0.0857355823740363 Acc 0.9764419126510621 Perturbed Loss 0.09572874907404184
Loss 0.08777463844045996 Acc 0.9734411287307739 Perturbed Loss 0.09881735814735293
Loss 0.07441023845225572 Acc 0.9779107010364533 Perturbed Loss 0.08550337679684163
Loss 0.08675823926925659 Acc 0.9748037266731262 Perturbed Loss 0.0967603562027216
Loss 0.06896649979054928 Acc 0.9787320971488953 Perturbed Loss 0.07931217450648546
Loss 0.07299002207815647 Acc 0.9770704007148743 Perturbed Loss 0.08125210966914892
Loss 0.08070136696100234 Acc 0.9795360743999482 Perturbed Loss 0.08786941692233086
Loss 0.07561912205070258 Acc 0.9769511461257935 Perturbed Loss 0.08646797277033329
Loss 0.07700364720076322 Acc 0.9780695641040802 Perturbed Loss 0.08453799329698086
Loss 0.08269614204764367 Acc 0.9743646121025086 Perturbed Loss 0.09339357133954763
Loss 0.08512384325265884 Acc 0.9781400656700134 Perturbed Loss 0.09424008835107088
Loss 0.07936793670058251 Acc 0.9784025168418884 Perturbed Loss 0.0875489617139101
Loss 0.07474769223481417 Acc 0.9766116070747376 Perturbed Loss 0.08395388172939419
Epoch 5.0 val loss 0.062385715544223785 val acc 0.9788395166397095
Loss 0.07634274743497371 Acc 0.9777818417549133 Perturbed Loss 0.0831166422367096
Loss 0.08061218738555909 Acc 0.9786568093299866 Perturbed Loss 0.09238055769354105
Loss 0.07238515242934226 Acc 0.9786937475204468 Perturbed Loss 0.08185231268405914
Loss 0.08652261413633823 Acc 0.9761150300502777 Perturbed Loss 0.0942165257781744
Loss 0.07524313932284712 Acc 0.9813683259487153 Perturbed Loss 0.08179135117679834
Loss 0.07593958381563425 Acc 0.9761448776721955 Perturbed Loss 0.08481406796723605
Loss 0.07146866753697395 Acc 0.9766777801513672 Perturbed Loss 0.0784043399989605
Loss 0.07534805119037628 Acc 0.9808222758769989 Perturbed Loss 0.08397907737642527
Loss 0.07294305648654699 Acc 0.9799325633049011 Perturbed Loss 0.08298515491187572
Loss 0.08506365019828081 Acc 0.9757446002960205 Perturbed Loss 0.09366528272628784
Loss 0.07724813885986805 Acc 0.9783111584186553 Perturbed Loss 0.08497204860672354
Loss 0.07527835194021464 Acc 0.9776779341697693 Perturbed Loss 0.08426066968590021
Loss 0.07738500015810132 Acc 0.9761786925792694 Perturbed Loss 0.08595247263088822
Loss 0.0795430800318718 Acc 0.9802672863006592 Perturbed Loss 0.08869999166578055
Loss 0.07744081802666188 Acc 0.973114310503006 Perturbed Loss 0.0868459251895547
Epoch 6.0 val loss 0.06027420982718468 val acc 0.9785828590393066
Loss 0.086170445214957 Acc 0.9754219496250153 Perturbed Loss 0.09508542478084564
Loss 0.09115402445197106 Acc 0.9766277527809143 Perturbed Loss 0.10080573040992022
Loss 0.07379395753145218 Acc 0.9772104454040528 Perturbed Loss 0.08042374368757009
Loss 0.06734801402315498 Acc 0.9815628588199615 Perturbed Loss 0.07516627572476864
Loss 0.07378946963697672 Acc 0.9764034426212311 Perturbed Loss 0.08229587551206351
Loss 0.07850504167377949 Acc 0.9770694327354431 Perturbed Loss 0.08692744445055724
Loss 0.07757446445524692 Acc 0.9744784748554229 Perturbed Loss 0.08574822701513768
Loss 0.06727965509518981 Acc 0.9800959694385528 Perturbed Loss 0.07550273422151804
Loss 0.07548142639920115 Acc 0.9774791586399079 Perturbed Loss 0.08315007470548152
Loss 0.08019259985536337 Acc 0.9780845272541047 Perturbed Loss 0.08723541021347046
Loss 0.08042703989893198 Acc 0.9809423303604126 Perturbed Loss 0.09037769522517919
Loss 0.0714350644312799 Acc 0.9790312576293946 Perturbed Loss 0.07855788668617607
Loss 0.06818185448646545 Acc 0.9774849855899811 Perturbed Loss 0.07483544833958149
Loss 0.07117359783500433 Acc 0.9802020180225373 Perturbed Loss 0.08035431265830993
Loss 0.08082326557487249 Acc 0.9769999456405639 Perturbed Loss 0.09167377576231957
Epoch 7.0 val loss 0.06084395945072174 val acc 0.9782704710960388
Loss 0.07172425080090761 Acc 0.9768484365940094 Perturbed Loss 0.08175680812448263
Loss 0.07114957788959146 Acc 0.9742682957649231 Perturbed Loss 0.08124411035329103
Loss 0.06535390179604292 Acc 0.9786594474315643 Perturbed Loss 0.0714287493005395
Loss 0.0752400491386652 Acc 0.9761465096473694 Perturbed Loss 0.0842820756137371
Loss 0.07031350173056125 Acc 0.9790119552612304 Perturbed Loss 0.07928703354671597
Loss 0.07194913954474032 Acc 0.977704815864563 Perturbed Loss 0.0791355662047863
Loss 0.06347642600536346 Acc 0.978079594373703 Perturbed Loss 0.0719993083178997
Loss 0.06766694154590368 Acc 0.9773943305015564 Perturbed Loss 0.0746826658770442
Loss 0.06974690325558186 Acc 0.9748194801807404 Perturbed Loss 0.08228429073467851
Loss 0.06803878923878073 Acc 0.9756710624694824 Perturbed Loss 0.075756103284657
Loss 0.07537267994135619 Acc 0.9784105539321899 Perturbed Loss 0.08488802876323462
Loss 0.0748945084400475 Acc 0.9795533013343811 Perturbed Loss 0.08471902251243592
Loss 0.07194968029856681 Acc 0.9781229329109192 Perturbed Loss 0.08160255718976259
Loss 0.07777633154764771 Acc 0.9780973744392395 Perturbed Loss 0.08777843814343214
Loss 0.07571842586621642 Acc 0.9817189180850983 Perturbed Loss 0.08245614813640714
Epoch 8.0 val loss 0.06129779666662216 val acc 0.9790077805519104
Loss 0.07609225921332836 Acc 0.9748489439487458 Perturbed Loss 0.08644934978336095
Loss 0.0732489849627018 Acc 0.9778804183006287 Perturbed Loss 0.08291862811893225
Loss 0.07301060054451228 Acc 0.9768533289432526 Perturbed Loss 0.08213568160310387
Loss 0.06465330727398395 Acc 0.9791973388195038 Perturbed Loss 0.07348829194903374
Loss 0.0736561893299222 Acc 0.976512268781662 Perturbed Loss 0.08715729780495167
Loss 0.07003294304013252 Acc 0.9762697231769562 Perturbed Loss 0.07876489017158747
Loss 0.06243659755215049 Acc 0.9811116051673889 Perturbed Loss 0.06982135321944952
Loss 0.08094504944980145 Acc 0.9792268002033233 Perturbed Loss 0.08752484660595655
Loss 0.06485530409961938 Acc 0.9791009044647216 Perturbed Loss 0.07158823180943727
Loss 0.07041724488139152 Acc 0.9819707369804382 Perturbed Loss 0.0777165687084198
Loss 0.06900102823972702 Acc 0.9804321491718292 Perturbed Loss 0.07840758115053177
Loss 0.07369559234008193 Acc 0.9782487034797669 Perturbed Loss 0.08214161142706872
Loss 0.07126548804342747 Acc 0.9775106525421142 Perturbed Loss 0.07741587035357952
Loss 0.0822342924401164 Acc 0.976107816696167 Perturbed Loss 0.09468871064484119
Loss 0.07755374442785978 Acc 0.9766483676433563 Perturbed Loss 0.08583330005407333
Epoch 9.0 val loss 0.05809959024190903 val acc 0.9790763854980469
Loss 0.07412418078631162 Acc 0.9820322501659393 Perturbed Loss 0.08220043618232012
Loss 0.07330902757123113 Acc 0.97646763920784 Perturbed Loss 0.07941354516893626
Loss 0.06726407507434487 Acc 0.9803247666358947 Perturbed Loss 0.07480270458385348
Loss 0.07761522855609655 Acc 0.9754069447517395 Perturbed Loss 0.08654926389455796
Loss 0.06149793973192572 Acc 0.9826889288425446 Perturbed Loss 0.066880151219666
Loss 0.06696513388305902 Acc 0.9789831864833832 Perturbed Loss 0.07453489374369383
Loss 0.06577644042670727 Acc 0.9783595418930053 Perturbed Loss 0.07287595052272082
Loss 0.06433450662530958 Acc 0.983304214477539 Perturbed Loss 0.07096387403085828
Loss 0.06665282532572746 Acc 0.9763606727123261 Perturbed Loss 0.07389991760253906
Loss 0.0727133148536086 Acc 0.9768634378910065 Perturbed Loss 0.07943719238042832
Loss 0.07220730546861887 Acc 0.9771149575710296 Perturbed Loss 0.08212152060121297
Loss 0.07925939697772265 Acc 0.9752427935600281 Perturbed Loss 0.08846276611089707
Loss 0.0699910073634237 Acc 0.9785665237903595 Perturbed Loss 0.07838202007114888
Loss 0.06950593437999487 Acc 0.977101182937622 Perturbed Loss 0.07755572125315666
Loss 0.06941053986549378 Acc 0.9777864193916321 Perturbed Loss 0.07651604648679494
Epoch 10.0 val loss 0.06068563088774681 val acc 0.978875994682312
Loss 0.07104939039796591 Acc 0.979557124376297 Perturbed Loss 0.08138745095580817
Loss 0.06958360243588686 Acc 0.9803405964374542 Perturbed Loss 0.07526913195848466
Loss 0.06622165458276869 Acc 0.9802273690700531 Perturbed Loss 0.0726759029366076
Loss 0.0627252054028213 Acc 0.97887282371521 Perturbed Loss 0.07270943637937308
Loss 0.0732127096876502 Acc 0.9766659832000733 Perturbed Loss 0.08389810889959336
Loss 0.06867497961968183 Acc 0.9776757454872131 Perturbed Loss 0.07941002011299134
Loss 0.07269022470340132 Acc 0.9792857468128204 Perturbed Loss 0.08142395125702023
Loss 0.0826424328237772 Acc 0.9768963479995727 Perturbed Loss 0.09098282128572464
Loss 0.06025328425690532 Acc 0.979884980916977 Perturbed Loss 0.06769372444599867
Loss 0.06543802306056022 Acc 0.9813177239894867 Perturbed Loss 0.0734875825047493
Loss 0.07390479374676943 Acc 0.9776014041900635 Perturbed Loss 0.08403718966990709
Loss 0.07230266243219376 Acc 0.9798754107952118 Perturbed Loss 0.07935050282627344
Loss 0.08151960548013448 Acc 0.9759670329093934 Perturbed Loss 0.08975027151405811
Loss 0.06751222301274538 Acc 0.9807252240180969 Perturbed Loss 0.07649803325533867
Loss 0.06486280679702759 Acc 0.9808292818069458 Perturbed Loss 0.07188544666394592
Epoch 11.0 val loss 0.05808543786406517 val acc 0.9785189032554626
Loss 0.08128120880573989 Acc 0.9789003503322601 Perturbed Loss 0.08823163952678442
Loss 0.07405182965099812 Acc 0.9766439020633697 Perturbed Loss 0.0822966193780303
Loss 0.07224101673811674 Acc 0.9815816056728363 Perturbed Loss 0.07909173280000686
Loss 0.06453044597059489 Acc 0.9804112660884857 Perturbed Loss 0.0708530217781663
Loss 0.06591689486056566 Acc 0.984018657207489 Perturbed Loss 0.0718415331095457
Loss 0.06321962930262089 Acc 0.980080817937851 Perturbed Loss 0.07043186036869883
Loss 0.06901892619207502 Acc 0.9791300821304322 Perturbed Loss 0.07720139071345329
Loss 0.06813207857310771 Acc 0.9799782824516297 Perturbed Loss 0.07433987250551581
Loss 0.06344687346369028 Acc 0.9778811192512512 Perturbed Loss 0.07022058352828026
Loss 0.06300698889419437 Acc 0.9813406097888947 Perturbed Loss 0.06940184189006686
Loss 0.07379321072250605 Acc 0.9805542016029358 Perturbed Loss 0.08062695923261344
Loss 0.06371180816553533 Acc 0.9772847199440002 Perturbed Loss 0.07018667982891202
Loss 0.07964732377789914 Acc 0.9811349737644196 Perturbed Loss 0.08857029519975185
Loss 0.06808070607483387 Acc 0.9807573425769806 Perturbed Loss 0.07732266295701265
Loss 0.06943825293332338 Acc 0.9749553024768829 Perturbed Loss 0.07638170577585697
Epoch 12.0 val loss 0.05739115551114082 val acc 0.9790357947349548
Loss 0.07087089559063316 Acc 0.977619651556015 Perturbed Loss 0.0825093524158001
Loss 0.07832647204399108 Acc 0.977513769865036 Perturbed Loss 0.08587869860231877
Loss 0.07410200092941523 Acc 0.9782174921035767 Perturbed Loss 0.08092178612947463
Loss 0.06395838923752308 Acc 0.9822666907310486 Perturbed Loss 0.0704189832881093
Loss 0.06787373157218099 Acc 0.9796241354942322 Perturbed Loss 0.07944527177140116
Loss 0.07081954959779978 Acc 0.9810548174381256 Perturbed Loss 0.0760925092548132
Loss 0.07311345092952251 Acc 0.9761663901805878 Perturbed Loss 0.07860857397317886
Loss 0.07135466207750142 Acc 0.9778803372383118 Perturbed Loss 0.07807292371056974
Loss 0.07002137783914804 Acc 0.9786133766174316 Perturbed Loss 0.07641376469284296
Loss 0.06739893389865756 Acc 0.9800095534324647 Perturbed Loss 0.07496488558128477
Loss 0.07511357199400663 Acc 0.9789719748497009 Perturbed Loss 0.08005923382937909
Loss 0.07026260107755661 Acc 0.9813653552532196 Perturbed Loss 0.07700207315385342
Loss 0.06151723656803369 Acc 0.9785455691814423 Perturbed Loss 0.06952594393864274
Loss 0.05849316991865635 Acc 0.9811848437786103 Perturbed Loss 0.06516913190484047
Loss 0.06849884942173957 Acc 0.9821495401859284 Perturbed Loss 0.07466535840183497
Epoch 13.0 val loss 0.05814658850431442 val acc 0.9794784188270569
Loss 0.06348480112850666 Acc 0.980683182477951 Perturbed Loss 0.0681672085262835
Loss 0.0734735113568604 Acc 0.9769295704364777 Perturbed Loss 0.08145374238491059
Loss 0.0696871690824628 Acc 0.9794426107406616 Perturbed Loss 0.07551668087020516
Loss 0.07364988099783659 Acc 0.977605562210083 Perturbed Loss 0.08204247243702412
Loss 0.0722191298007965 Acc 0.9784991335868836 Perturbed Loss 0.0790889810025692
Loss 0.060270197372883555 Acc 0.9819079577922821 Perturbed Loss 0.06825563685968518
Loss 0.062361663803458214 Acc 0.9813362848758698 Perturbed Loss 0.07028959970921278
Loss 0.05851083401590586 Acc 0.9803136587142944 Perturbed Loss 0.0651175182312727
Loss 0.06634139448404312 Acc 0.9815509605407715 Perturbed Loss 0.07321105713024735
Loss 0.06894528690725565 Acc 0.9756881785392761 Perturbed Loss 0.07867869108915329
Loss 0.07006669756025076 Acc 0.9790622186660767 Perturbed Loss 0.07683193985372781
Loss 0.06840424247086048 Acc 0.9765755164623261 Perturbed Loss 0.0751281950995326
Loss 0.07046559532172977 Acc 0.9804133224487305 Perturbed Loss 0.07957908641546965
Loss 0.07679031848907471 Acc 0.974196115732193 Perturbed Loss 0.085860192514956
Loss 0.06571146380156279 Acc 0.9799128246307373 Perturbed Loss 0.07229111656546593
Epoch 14.0 val loss 0.05736405402421951 val acc 0.9794449210166931
Loss 0.0696006685681641 Acc 0.975117027759552 Perturbed Loss 0.07698372103273869
Loss 0.07062661848962307 Acc 0.9798613059520721 Perturbed Loss 0.07720174051821233
Loss 0.07434910962358117 Acc 0.9745796954631806 Perturbed Loss 0.08250773463398219
Loss 0.06912989446893335 Acc 0.9792029523849487 Perturbed Loss 0.07552651230245828
Loss 0.055862639993429185 Acc 0.9814917850494385 Perturbed Loss 0.06103318667039275
Loss 0.05882333303336054 Acc 0.9821013879776 Perturbed Loss 0.06776264382526279
Loss 0.06639824356883764 Acc 0.980403755903244 Perturbed Loss 0.07225163217633962
Loss 0.08572824683040381 Acc 0.9786035549640656 Perturbed Loss 0.09453067665919662
Loss 0.07395159877836704 Acc 0.9795709300041199 Perturbed Loss 0.0864653318747878
Loss 0.07205296522006392 Acc 0.9804989206790924 Perturbed Loss 0.08017985060811043
Loss 0.06606371501460671 Acc 0.9835041058063507 Perturbed Loss 0.07047647446393966
Loss 0.06901349063962697 Acc 0.9779406821727753 Perturbed Loss 0.0760509106516838
Loss 0.06598436001688242 Acc 0.9811394834518432 Perturbed Loss 0.07275228425860406
Loss 0.06480261225253343 Acc 0.981626787185669 Perturbed Loss 0.07205408312380314
Loss 0.07462427534162998 Acc 0.9789805746078492 Perturbed Loss 0.08362380333244801
Epoch 15.0 val loss 0.05867405980825424 val acc 0.9791381359100342
Loss 0.06848506255075336 Acc 0.9786145079135895 Perturbed Loss 0.07461422326043249
Loss 0.0671230747923255 Acc 0.9774959003925323 Perturbed Loss 0.07419692412018776
Loss 0.07344604216516018 Acc 0.9801059782505035 Perturbed Loss 0.07995252810418606
Loss 0.06328898344188928 Acc 0.9803269302845001 Perturbed Loss 0.07050104174762964
Loss 0.0618157596886158 Acc 0.9800715637207031 Perturbed Loss 0.07114706330001354
Loss 0.07396427230909466 Acc 0.98032231092453 Perturbed Loss 0.07961690187454223
Loss 0.07463350392878056 Acc 0.9802130496501923 Perturbed Loss 0.07927324801683426
Loss 0.07350155089050531 Acc 0.9784532427787781 Perturbed Loss 0.08235068198293448
Loss 0.06213617159053683 Acc 0.9807511043548583 Perturbed Loss 0.06961893498897552
Loss 0.056611791159957646 Acc 0.9844896245002747 Perturbed Loss 0.062084416933357714
Loss 0.06798949036747218 Acc 0.9788943338394165 Perturbed Loss 0.07572971623390913
Loss 0.06430937591940164 Acc 0.9816705989837646 Perturbed Loss 0.07185478910803794
Loss 0.06253432318568229 Acc 0.9815244448184967 Perturbed Loss 0.07166718952357769
Loss 0.06790903843939304 Acc 0.9809909963607788 Perturbed Loss 0.0749704560264945
Loss 0.05999052919447422 Acc 0.9835174286365509 Perturbed Loss 0.0653460318595171
Epoch 16.0 val loss 0.05712805315852165 val acc 0.9795264005661011
Loss 0.06861332099884748 Acc 0.9803474974632264 Perturbed Loss 0.07733985636383295
Loss 0.07223370157182217 Acc 0.9821010291576385 Perturbed Loss 0.07948433421552181
Loss 0.05980297638103366 Acc 0.9802941465377808 Perturbed Loss 0.06610387813299895
Loss 0.07086760235950351 Acc 0.9792602837085724 Perturbed Loss 0.0773988681845367
Loss 0.06383373379707337 Acc 0.9806414008140564 Perturbed Loss 0.06977003209292888
Loss 0.060574045218527314 Acc 0.980337690114975 Perturbed Loss 0.06614274758845567
Loss 0.06896708969026805 Acc 0.9764627742767334 Perturbed Loss 0.07758411131799221
Loss 0.0672990737296641 Acc 0.9811239886283875 Perturbed Loss 0.07307211745530368
Loss 0.053736743219196796 Acc 0.983110294342041 Perturbed Loss 0.059922505002468825
Loss 0.07879722140729427 Acc 0.9778987324237823 Perturbed Loss 0.08523638457059861
Loss 0.06389993716031313 Acc 0.9794293010234832 Perturbed Loss 0.06937190437689424
Loss 0.06810895789414645 Acc 0.9787662327289581 Perturbed Loss 0.07720697443932295
Loss 0.06381868433207273 Acc 0.9756682145595551 Perturbed Loss 0.06896655956283211
Loss 0.06544098060578107 Acc 0.9794222295284272 Perturbed Loss 0.07353260051459073
Loss 0.06825543558225036 Acc 0.9826211297512054 Perturbed Loss 0.07460916299372912
Epoch 17.0 val loss 0.05748191848397255 val acc 0.979888916015625
Loss 0.06587156368419528 Acc 0.980591094493866 Perturbed Loss 0.07225601404905319
Loss 0.07082257222384214 Acc 0.9812196433544159 Perturbed Loss 0.07699627853929997
Loss 0.06745114477351308 Acc 0.9772696042060852 Perturbed Loss 0.07443306950852274
Loss 0.06386896865442396 Acc 0.9825699388980865 Perturbed Loss 0.06887938817963005
Loss 0.06398516210727394 Acc 0.9817107617855072 Perturbed Loss 0.07028732296079397
Loss 0.055778602911159395 Acc 0.9830563330650329 Perturbed Loss 0.060808164197951556
Loss 0.05838501363992691 Acc 0.9794754242897034 Perturbed Loss 0.06540743421763182
Loss 0.060482193576171996 Acc 0.9814288973808288 Perturbed Loss 0.06749357253313065
Loss 0.0680187181942165 Acc 0.9801924777030945 Perturbed Loss 0.07376754615455866
Loss 0.06488359902054071 Acc 0.9792773020267487 Perturbed Loss 0.07073622420430184
Loss 0.06184596471488476 Acc 0.978771721124649 Perturbed Loss 0.06807031445205211
Loss 0.07620783250778913 Acc 0.9752734923362731 Perturbed Loss 0.08290935218334199
Loss 0.0624127621948719 Acc 0.9792131650447845 Perturbed Loss 0.06961368188261986
Loss 0.07711005780845881 Acc 0.9790483033657074 Perturbed Loss 0.08313799612224101
Loss 0.06032113773748279 Acc 0.9784532070159913 Perturbed Loss 0.0650878825224936
Epoch 18.0 val loss 0.05641598999500275 val acc 0.9800712466239929
Loss 0.0667734544724226 Acc 0.9772808599472046 Perturbed Loss 0.07269740909337997
Loss 0.06900795122608543 Acc 0.9794882881641388 Perturbed Loss 0.07567426424473524
Loss 0.06771766550838948 Acc 0.9799806773662567 Perturbed Loss 0.07262986935675145
Loss 0.05663576539605856 Acc 0.9794930636882782 Perturbed Loss 0.06216448578983545
Loss 0.05994935393333435 Acc 0.9822444021701813 Perturbed Loss 0.06647349193692208
Loss 0.06222763566300273 Acc 0.9784379959106445 Perturbed Loss 0.0685120915621519
Loss 0.08422570010647178 Acc 0.9762642586231232 Perturbed Loss 0.09169827353209258
Loss 0.0627729231864214 Acc 0.9800517976284027 Perturbed Loss 0.0679266900010407
Loss 0.060660180412232874 Acc 0.9812992358207703 Perturbed Loss 0.06613418834283948
Loss 0.0633989917114377 Acc 0.9804347717761993 Perturbed Loss 0.06905503049492837
Loss 0.06918416410684586 Acc 0.9798059368133545 Perturbed Loss 0.07506883064284921
Loss 0.06240337274968624 Acc 0.9784912645816803 Perturbed Loss 0.06946256525814533
Loss 0.06589811615645885 Acc 0.9796688234806061 Perturbed Loss 0.071463304720819
Loss 0.07761994764208793 Acc 0.9801499378681183 Perturbed Loss 0.08583007682114839
Loss 0.059917098712176084 Acc 0.9825366079807282 Perturbed Loss 0.06581330988556147
Epoch 19.0 val loss 0.05686487630009651 val acc 0.9799706339836121
[11:08:53] INFO     `Trainer.fit` stopped: `max_epochs=20` reached.                                                                                                                         rank_zero.py:53
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750/750 0:03:45 • 0:00:00 3.36it/s train/loss: 0.06 val_loss: 0.057
[11:08:55] INFO     Created a temporary directory at /tmp/tmp9i6ios54                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmp9i6ios54/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
[11:08:56] INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
           INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
           INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
           INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
           INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
[11:08:57] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.0005, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.1, adaptive=True)
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.08873698312789202 Acc 0.9658801066875458 Perturbed Loss 0.11226693414151669
[11:09:27] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.07629242934286594 Acc 0.9711444461345673 Perturbed Loss 0.09057733859866858
Loss 0.0834772134758532 Acc 0.9775953805446624 Perturbed Loss 0.09869232712313533
Loss 0.08341529220342636 Acc 0.9741013050079346 Perturbed Loss 0.0937160920817405
Loss 0.0780846156924963 Acc 0.9768434333801269 Perturbed Loss 0.09160426937043667
Loss 0.0933249418437481 Acc 0.96691779255867 Perturbed Loss 0.1087401019409299
Loss 0.08220591124147177 Acc 0.9711815690994263 Perturbed Loss 0.10066585622727871
Loss 0.0823103443160653 Acc 0.9774446594715118 Perturbed Loss 0.09705647863447667
Loss 0.08896659936755896 Acc 0.9739593529701233 Perturbed Loss 0.10077833347022533
Loss 0.08478693179786205 Acc 0.9707601428031921 Perturbed Loss 0.0985345585271716
Loss 0.07492128126323223 Acc 0.9775606393814087 Perturbed Loss 0.08509351406246424
Loss 0.08238078985363245 Acc 0.9778889358043671 Perturbed Loss 0.09689259039238095
Loss 0.08076714094728231 Acc 0.9781178760528565 Perturbed Loss 0.09167801095172763
Loss 0.06643262792378664 Acc 0.9831275415420532 Perturbed Loss 0.07621268820017577
Loss 0.07875467786565422 Acc 0.9762286078929902 Perturbed Loss 0.0912393619120121
Epoch 0.0 val loss 0.056418225169181824 val acc 0.9793486595153809
Loss 0.07932024158537387 Acc 0.9750578892230988 Perturbed Loss 0.0908843832463026
Loss 0.07901432104408741 Acc 0.9729227018356323 Perturbed Loss 0.08749740310013294
Loss 0.07885399658232928 Acc 0.9674671399593353 Perturbed Loss 0.092755191847682
Loss 0.07600538171827793 Acc 0.9751040840148926 Perturbed Loss 0.08684031657874584
Loss 0.08237983770668507 Acc 0.9757730984687805 Perturbed Loss 0.09494503527879715
Loss 0.07640049651265145 Acc 0.976621744632721 Perturbed Loss 0.08696439560502768
Loss 0.08231139708310366 Acc 0.9764046704769135 Perturbed Loss 0.09272768184542655
Loss 0.07384797964245081 Acc 0.9790028250217437 Perturbed Loss 0.08463612459599971
Loss 0.07583175428211689 Acc 0.977173136472702 Perturbed Loss 0.08756159910932183
Loss 0.07960453372448682 Acc 0.9765667390823364 Perturbed Loss 0.09168737214058638
Loss 0.0765772458538413 Acc 0.9680408108234405 Perturbed Loss 0.08872014962136746
Loss 0.08940713476389646 Acc 0.9715046036243439 Perturbed Loss 0.10161536503583193
Loss 0.0752352574840188 Acc 0.980760931968689 Perturbed Loss 0.0836846312880516
Loss 0.08816685244441032 Acc 0.9728182637691498 Perturbed Loss 0.10164668675512076
Loss 0.0757177061215043 Acc 0.9765039825439453 Perturbed Loss 0.08514686714857816
Epoch 1.0 val loss 0.05587955564260483 val acc 0.9794214367866516
Loss 0.07270606275647878 Acc 0.9750996160507203 Perturbed Loss 0.08184085801243782
Loss 0.08741157088428736 Acc 0.9789349782466888 Perturbed Loss 0.09768370218575001
Loss 0.07673918105661869 Acc 0.978370771408081 Perturbed Loss 0.08777923807501793
Loss 0.071326849386096 Acc 0.9819074594974517 Perturbed Loss 0.0811821112036705
Loss 0.07382815666496753 Acc 0.9809096586704255 Perturbed Loss 0.08490875829011202
Loss 0.07229523649439215 Acc 0.9778675401210785 Perturbed Loss 0.08146895043551922
Loss 0.07585120350122451 Acc 0.9796851921081543 Perturbed Loss 0.08591382831335068
Loss 0.07207173146307469 Acc 0.9814223885536194 Perturbed Loss 0.08537302352488041
Loss 0.08148781679570676 Acc 0.9751401972770691 Perturbed Loss 0.09391849976032972
Loss 0.07606146922335029 Acc 0.979988478422165 Perturbed Loss 0.08526732299476862
Loss 0.07328867606818676 Acc 0.9794251024723053 Perturbed Loss 0.08424588114023208
Loss 0.0813511760160327 Acc 0.9744524323940277 Perturbed Loss 0.09118458978831769
Loss 0.08092780094593763 Acc 0.9725398290157318 Perturbed Loss 0.09267728295177222
Loss 0.09267851419746875 Acc 0.9681206834316254 Perturbed Loss 0.10274398546665907
Loss 0.07786733334884048 Acc 0.9767671239376068 Perturbed Loss 0.08935917131602764
Epoch 2.0 val loss 0.055902671068906784 val acc 0.9799574017524719
Loss 0.07197004199028015 Acc 0.9764317536354065 Perturbed Loss 0.08232097737491131
Loss 0.06590922996401787 Acc 0.9799645912647247 Perturbed Loss 0.07370337825268507
Loss 0.06954402297735214 Acc 0.9804236519336701 Perturbed Loss 0.079181003049016
Loss 0.07511577162891626 Acc 0.9801378691196442 Perturbed Loss 0.08372611287981271
Loss 0.07852306731045246 Acc 0.977834849357605 Perturbed Loss 0.09390956483781338
Loss 0.08128178749233485 Acc 0.9760829174518585 Perturbed Loss 0.09063238169997931
Loss 0.06849236231297255 Acc 0.9826079380512237 Perturbed Loss 0.07732060093432665
Loss 0.07725056726485491 Acc 0.9775857067108155 Perturbed Loss 0.0872900776565075
Loss 0.08424489047378302 Acc 0.978570898771286 Perturbed Loss 0.09277379639446735
Loss 0.0767289724573493 Acc 0.976882838010788 Perturbed Loss 0.08349867019802332
Loss 0.06250083422288298 Acc 0.9777177393436431 Perturbed Loss 0.07166928749531508
Loss 0.08542513970285653 Acc 0.9737127041816711 Perturbed Loss 0.09732868690043688
Loss 0.0858541489392519 Acc 0.9756239068508148 Perturbed Loss 0.09854694433510304
Loss 0.07339775433763862 Acc 0.9729002642631531 Perturbed Loss 0.08399490837007761
Loss 0.07864805113524198 Acc 0.9771363794803619 Perturbed Loss 0.08923434987664222
Epoch 3.0 val loss 0.05643800273537636 val acc 0.9793941974639893
Loss 0.06684478800743818 Acc 0.9813327181339264 Perturbed Loss 0.07647712003439665
Loss 0.0767234018445015 Acc 0.9818252575397491 Perturbed Loss 0.08859494909644126
Loss 0.06773018071427941 Acc 0.974162814617157 Perturbed Loss 0.07718499660491944
Loss 0.08570025493390858 Acc 0.9779832220077515 Perturbed Loss 0.10007428234443068
Loss 0.07960195699706674 Acc 0.9747679817676544 Perturbed Loss 0.08931291356682777
Loss 0.07483149126172066 Acc 0.9784651482105255 Perturbed Loss 0.08549023792147636
Loss 0.06535568937659264 Acc 0.979344277381897 Perturbed Loss 0.0738353631272912
Loss 0.0736545630171895 Acc 0.9791247379779816 Perturbed Loss 0.0831168058142066
Loss 0.07475397668778896 Acc 0.9753384876251221 Perturbed Loss 0.08382720660418272
Loss 0.06801040841266513 Acc 0.9771558022499085 Perturbed Loss 0.07872622108086944
Loss 0.07825409080833197 Acc 0.9792725956439972 Perturbed Loss 0.09008433859795333
Loss 0.08001839572563768 Acc 0.9752441942691803 Perturbed Loss 0.0893300573155284
Loss 0.0762284992262721 Acc 0.976647778749466 Perturbed Loss 0.08634072780609131
Loss 0.07539466939866543 Acc 0.9798109209537507 Perturbed Loss 0.08388419482856989
Loss 0.07073785416781903 Acc 0.9803619492053985 Perturbed Loss 0.07966820012778043
Epoch 4.0 val loss 0.05637960880994797 val acc 0.9795548915863037
Loss 0.0706618845462799 Acc 0.9778515946865082 Perturbed Loss 0.08024848770350218
Loss 0.07973706100136041 Acc 0.9799495708942413 Perturbed Loss 0.08857866093516349
Loss 0.08209739852696657 Acc 0.9771195197105408 Perturbed Loss 0.09135412808507681
Loss 0.08299723828211426 Acc 0.9734665167331695 Perturbed Loss 0.09235845308750867
Loss 0.07134477257728576 Acc 0.9791168451309205 Perturbed Loss 0.08067906260490418
Loss 0.08496194267645478 Acc 0.9757713890075683 Perturbed Loss 0.09497037582099438
Loss 0.06887859828770161 Acc 0.9795677554607392 Perturbed Loss 0.07630728781223298
Loss 0.06490321487188339 Acc 0.9780843019485473 Perturbed Loss 0.07223479427397252
Loss 0.07755847606807947 Acc 0.9798324596881867 Perturbed Loss 0.08552930932492017
Loss 0.07146747104823589 Acc 0.9781219041347504 Perturbed Loss 0.08045887630432844
Loss 0.07397380780428647 Acc 0.9780957746505737 Perturbed Loss 0.08156795173883438
Loss 0.07834831520915031 Acc 0.975198085308075 Perturbed Loss 0.08738658737391233
Loss 0.08025651767849923 Acc 0.9795243632793427 Perturbed Loss 0.09218914911150933
Loss 0.0770469356700778 Acc 0.9789395475387573 Perturbed Loss 0.08644416395574808
Loss 0.07146333189681173 Acc 0.9777743482589721 Perturbed Loss 0.08240844309329987
Epoch 5.0 val loss 0.05717352032661438 val acc 0.9795336127281189
Loss 0.07538225412368775 Acc 0.9778755509853363 Perturbed Loss 0.08310071341693401
Loss 0.071305974368006 Acc 0.9797168231010437 Perturbed Loss 0.0811686947569251
Loss 0.06809199530631303 Acc 0.9800573050975799 Perturbed Loss 0.07865256339311599
Loss 0.08109932653605938 Acc 0.9763661122322083 Perturbed Loss 0.09143351122736931
Loss 0.07159970248118043 Acc 0.9822373270988465 Perturbed Loss 0.07987626636400819
Loss 0.0778604600392282 Acc 0.9766075050830841 Perturbed Loss 0.08633019454777241
Loss 0.07091748785227538 Acc 0.9770493793487549 Perturbed Loss 0.07847743127495051
Loss 0.07381513234227896 Acc 0.9816722738742828 Perturbed Loss 0.08160791136324405
Loss 0.07055281974375248 Acc 0.9788840889930726 Perturbed Loss 0.07871948972344399
Loss 0.0826149552501738 Acc 0.9768979942798615 Perturbed Loss 0.09071933344006539
Loss 0.07228273287415504 Acc 0.9786403346061706 Perturbed Loss 0.07893206533044576
Loss 0.07308861692436039 Acc 0.9788817238807678 Perturbed Loss 0.0834317628107965
Loss 0.07351057890802622 Acc 0.9768087339401245 Perturbed Loss 0.08141265481710434
Loss 0.07671587336808443 Acc 0.9810999941825866 Perturbed Loss 0.08572640050202608
Loss 0.07500289347022772 Acc 0.9741482460498809 Perturbed Loss 0.08643293619155884
Epoch 6.0 val loss 0.05625889450311661 val acc 0.9792995452880859
Loss 0.0833548629283905 Acc 0.9761054527759552 Perturbed Loss 0.09186266897246241
Loss 0.08611976765096188 Acc 0.9780159199237823 Perturbed Loss 0.09657076412811876
Loss 0.07402573127299547 Acc 0.9774182677268982 Perturbed Loss 0.08335740201175212
Loss 0.06602487226948142 Acc 0.9821153104305267 Perturbed Loss 0.07774965647608041
Loss 0.0706834363937378 Acc 0.9766239511966706 Perturbed Loss 0.07780510980635881
Loss 0.07863271601498127 Acc 0.9779401981830597 Perturbed Loss 0.08559893030673266
Loss 0.07789073899388313 Acc 0.9755236160755157 Perturbed Loss 0.08783181387931109
Loss 0.06457056587561966 Acc 0.981100150346756 Perturbed Loss 0.07213668992742896
Loss 0.07544562648981809 Acc 0.9777199339866638 Perturbed Loss 0.0837538955360651
Loss 0.07795070443302393 Acc 0.9782725691795349 Perturbed Loss 0.08584520801901817
Loss 0.07524962332099676 Acc 0.9817059934139252 Perturbed Loss 0.08330333981662989
Loss 0.06876277903094888 Acc 0.9793888652324676 Perturbed Loss 0.07561475979164242
Loss 0.06637167900800706 Acc 0.9783780789375305 Perturbed Loss 0.07489474922418594
Loss 0.06764388021081685 Acc 0.9820322477817536 Perturbed Loss 0.07919483590871096
Loss 0.07514707304537296 Acc 0.9784211289882659 Perturbed Loss 0.08478739116340876
Epoch 7.0 val loss 0.05709781125187874 val acc 0.9787249565124512
Loss 0.06622917369008065 Acc 0.9766253924369812 Perturbed Loss 0.07342472121119499
Loss 0.06932637409307063 Acc 0.9747487676143646 Perturbed Loss 0.07861357126384974
Loss 0.06404507493600249 Acc 0.9782322990894318 Perturbed Loss 0.07170489564538002
Loss 0.07494826786220074 Acc 0.9762632381916047 Perturbed Loss 0.08207783482968807
Loss 0.06339617164805532 Acc 0.9794512891769409 Perturbed Loss 0.07280607393011451
Loss 0.07215493307448924 Acc 0.9779822611808777 Perturbed Loss 0.08014195596799255
Loss 0.06314340610057116 Acc 0.9781415903568268 Perturbed Loss 0.0717820742726326
Loss 0.06557562645524741 Acc 0.979025456905365 Perturbed Loss 0.07537927526980638
Loss 0.0691797417216003 Acc 0.9764845800399781 Perturbed Loss 0.08167626783251762
Loss 0.0661960506439209 Acc 0.9766499304771423 Perturbed Loss 0.07475338481366635
Loss 0.07412715792655945 Acc 0.9796356844902039 Perturbed Loss 0.0834261342138052
Loss 0.07091202523559331 Acc 0.9791445052623748 Perturbed Loss 0.07740784861147404
Loss 0.06440962232649326 Acc 0.9796311438083649 Perturbed Loss 0.07351083513349295
Loss 0.0746828205883503 Acc 0.9783228623867035 Perturbed Loss 0.0844113478437066
Loss 0.07430901678279042 Acc 0.9820367550849914 Perturbed Loss 0.08133031498640776
Epoch 8.0 val loss 0.05792940780520439 val acc 0.9796956181526184
Loss 0.06907512161880731 Acc 0.976492782831192 Perturbed Loss 0.07732518531382084
Loss 0.06893356494605542 Acc 0.9789812576770782 Perturbed Loss 0.07684549272060394
Loss 0.07043368915095925 Acc 0.9780679547786713 Perturbed Loss 0.07943962506949902
Loss 0.05994493067264557 Acc 0.9797545754909516 Perturbed Loss 0.06685513243079186
Loss 0.07131897866725921 Acc 0.977902899980545 Perturbed Loss 0.07871059957891703
Loss 0.06949922773987055 Acc 0.9771259582042694 Perturbed Loss 0.07681544248014688
Loss 0.06462912710383534 Acc 0.9811030101776123 Perturbed Loss 0.07057335317134857
Loss 0.07747056290507316 Acc 0.9797338879108429 Perturbed Loss 0.08598574817180633
Loss 0.06589378390461206 Acc 0.977853307723999 Perturbed Loss 0.07614109877496958
Loss 0.06544457167387009 Acc 0.9822226107120514 Perturbed Loss 0.07352135241031647
Loss 0.06585355993360281 Acc 0.9798360848426819 Perturbed Loss 0.07371592938899994
Loss 0.0702731223590672 Acc 0.9792108428478241 Perturbed Loss 0.07962483819574118
Loss 0.07209527783095837 Acc 0.9781703853607178 Perturbed Loss 0.07821236234158277
Loss 0.07961334798485041 Acc 0.9758090937137603 Perturbed Loss 0.09188760451972484
Loss 0.07515281915664673 Acc 0.9772075843811036 Perturbed Loss 0.08333183243870736
Epoch 9.0 val loss 0.055392730981111526 val acc 0.9799196720123291
Loss 0.07289908457547427 Acc 0.9826904177665711 Perturbed Loss 0.07977186020463706
Loss 0.0713128960877657 Acc 0.977192052602768 Perturbed Loss 0.0777655417099595
Loss 0.06501099562272429 Acc 0.9814911222457886 Perturbed Loss 0.07206475388258696
Loss 0.07539536038413644 Acc 0.9757424521446229 Perturbed Loss 0.08503683792427182
Loss 0.0603825481235981 Acc 0.9827537870407105 Perturbed Loss 0.06758192801848054
Loss 0.06443231038749218 Acc 0.979591017961502 Perturbed Loss 0.07243302793242037
Loss 0.0665421510860324 Acc 0.9787783265113831 Perturbed Loss 0.07614092856645584
Loss 0.06192489353939891 Acc 0.9833980917930603 Perturbed Loss 0.06861661225557328
Loss 0.06227785680443049 Acc 0.9785244190692901 Perturbed Loss 0.06853596813976764
Loss 0.06772975817322731 Acc 0.9776587498188019 Perturbed Loss 0.07675007030367852
Loss 0.0663427072390914 Acc 0.9784902024269104 Perturbed Loss 0.07413769450038671
Loss 0.07652235340327024 Acc 0.976808819770813 Perturbed Loss 0.0860392877086997
Loss 0.0667809031624347 Acc 0.980590705871582 Perturbed Loss 0.0752154747210443
Loss 0.06759842541068792 Acc 0.9781352591514587 Perturbed Loss 0.07900580257177353
Loss 0.06645297668874264 Acc 0.9782846915721893 Perturbed Loss 0.0747730515152216
Epoch 10.0 val loss 0.055842768400907516 val acc 0.9798092246055603
Loss 0.0720177759602666 Acc 0.9797111189365387 Perturbed Loss 0.08056042594835162
Loss 0.06920836685225368 Acc 0.9815241396427155 Perturbed Loss 0.07505233414471149
Loss 0.06504593936726451 Acc 0.9799502348899841 Perturbed Loss 0.0720061306282878
Loss 0.06039211580529809 Acc 0.9790567684173584 Perturbed Loss 0.06747039292007685
Loss 0.0697930758073926 Acc 0.9782540035247803 Perturbed Loss 0.07827827805653215
Loss 0.0636339645087719 Acc 0.9782580995559692 Perturbed Loss 0.07032901331782342
Loss 0.06960588669404387 Acc 0.9793168067932129 Perturbed Loss 0.07927291475236416
Loss 0.076416954100132 Acc 0.9787565016746521 Perturbed Loss 0.08400726418942213
Loss 0.059068777430802584 Acc 0.9804842221736908 Perturbed Loss 0.06609638625755906
Loss 0.06455903347581625 Acc 0.9816512000560761 Perturbed Loss 0.07182327762246132
Loss 0.0710232487693429 Acc 0.978068288564682 Perturbed Loss 0.07989007890224457
Loss 0.06931462958455085 Acc 0.9805215382575989 Perturbed Loss 0.07638311117887497
Loss 0.08019294176250696 Acc 0.9758020436763764 Perturbed Loss 0.08758529752492905
Loss 0.0646180135384202 Acc 0.9812576270103455 Perturbed Loss 0.07080241825431585
Loss 0.06361930519342422 Acc 0.9811643731594085 Perturbed Loss 0.06892970256507397
Epoch 11.0 val loss 0.05449018254876137 val acc 0.9795383810997009
Loss 0.0777816404402256 Acc 0.9789576518535614 Perturbed Loss 0.0855122246220708
Loss 0.07294615898281336 Acc 0.9771582746505737 Perturbed Loss 0.08056131366640329
Loss 0.06846196029335261 Acc 0.9821847248077392 Perturbed Loss 0.07648033894598484
Loss 0.06201561963185668 Acc 0.9795697963237763 Perturbed Loss 0.07047754164785147
Loss 0.06331146754324436 Acc 0.9845928251743317 Perturbed Loss 0.06917158598080278
Loss 0.06186155973002314 Acc 0.9797537660598755 Perturbed Loss 0.06956173727288842
Loss 0.06699064699932933 Acc 0.9797219789028168 Perturbed Loss 0.0733463842049241
Loss 0.06526445651426911 Acc 0.9801835465431213 Perturbed Loss 0.07142899481579662
Loss 0.06230179131031036 Acc 0.9781965291500092 Perturbed Loss 0.0690674090385437
Loss 0.06129471844062209 Acc 0.9814904773235321 Perturbed Loss 0.07207005212083459
Loss 0.07276245389133691 Acc 0.979323900938034 Perturbed Loss 0.08034162629395723
Loss 0.06274837888777256 Acc 0.9774564111232757 Perturbed Loss 0.06952948104590177
Loss 0.0760518374480307 Acc 0.9821723651885986 Perturbed Loss 0.0854528955835849
Loss 0.06397097490727902 Acc 0.9805466413497925 Perturbed Loss 0.07177375316619873
Loss 0.06760614033788442 Acc 0.9753438067436219 Perturbed Loss 0.07575089294463395
Epoch 12.0 val loss 0.0552595891058445 val acc 0.9799925684928894
Loss 0.07078541519120335 Acc 0.9791145217418671 Perturbed Loss 0.07943926742300392
Loss 0.07619834061712026 Acc 0.9774362254142761 Perturbed Loss 0.08392609391361475
Loss 0.07531244564801455 Acc 0.9775011789798737 Perturbed Loss 0.08387309812009335
Loss 0.06297305796295405 Acc 0.9829684841632843 Perturbed Loss 0.06802204068750144
Loss 0.06457190064713358 Acc 0.9799727702140808 Perturbed Loss 0.07318147854879499
Loss 0.07126553375273943 Acc 0.9813914942741394 Perturbed Loss 0.07758796103298664
Loss 0.07210019960999489 Acc 0.9764801979064941 Perturbed Loss 0.07842387028038501
Loss 0.06955048962496221 Acc 0.9782551491260528 Perturbed Loss 0.07780790637247265
Loss 0.07169756246730685 Acc 0.9785617017745971 Perturbed Loss 0.07987746704369783
Loss 0.06679510010406375 Acc 0.9806604659557343 Perturbed Loss 0.07516229851171374
Loss 0.07225598551332951 Acc 0.9793486714363098 Perturbed Loss 0.07877279054373502
Loss 0.06986413702368736 Acc 0.9810342669487 Perturbed Loss 0.07713272389024496
Loss 0.0606206994317472 Acc 0.9785295915603638 Perturbed Loss 0.06807944286614656
Loss 0.05954105112701655 Acc 0.980928966999054 Perturbed Loss 0.06779480341821909
Loss 0.06688307970762253 Acc 0.9823632216453553 Perturbed Loss 0.07263658419251443
Epoch 13.0 val loss 0.05525650829076767 val acc 0.9799632430076599
Loss 0.06322258155792952 Acc 0.9801623046398162 Perturbed Loss 0.06821667943149805
Loss 0.07101708542555571 Acc 0.9781598567962646 Perturbed Loss 0.07839276369661093
Loss 0.06792503898963333 Acc 0.97977818608284 Perturbed Loss 0.07252209192141891
Loss 0.07105614271014929 Acc 0.9778425681591034 Perturbed Loss 0.08014551291242242
Loss 0.0703973039612174 Acc 0.9789032053947448 Perturbed Loss 0.07625458594411612
Loss 0.058667005971074104 Acc 0.9820143568515778 Perturbed Loss 0.06491096783429384
Loss 0.06173477567732334 Acc 0.9816264367103577 Perturbed Loss 0.06919076319783926
Loss 0.057766707073897125 Acc 0.9812296390533447 Perturbed Loss 0.06504612576216459
Loss 0.0639349622093141 Acc 0.9817949938774109 Perturbed Loss 0.06891623876988888
Loss 0.06419704299420119 Acc 0.9747052085399628 Perturbed Loss 0.07452152464538812
Loss 0.06956151012331248 Acc 0.9797990643978118 Perturbed Loss 0.07786557357758284
Loss 0.06781313903629779 Acc 0.9765496695041657 Perturbed Loss 0.0747036537155509
Loss 0.07018057581037283 Acc 0.9809401857852936 Perturbed Loss 0.07706316279247404
Loss 0.07338224785402417 Acc 0.9742263114452362 Perturbed Loss 0.0810110923461616
Loss 0.06440670911222696 Acc 0.9805533456802368 Perturbed Loss 0.07085407488048076
Epoch 14.0 val loss 0.053980953991413116 val acc 0.9804090857505798
Loss 0.06985336414538323 Acc 0.9752176642417908 Perturbed Loss 0.0787222458422184
Loss 0.06806728169322014 Acc 0.9799931907653808 Perturbed Loss 0.07468198649585248
Loss 0.07469066252931952 Acc 0.9744898068904877 Perturbed Loss 0.08226024342700838
Loss 0.06962279871106147 Acc 0.9793063282966614 Perturbed Loss 0.07737210068851709
Loss 0.056249878518283364 Acc 0.9812200748920441 Perturbed Loss 0.06138874623924494
Loss 0.059738691253587606 Acc 0.9817987489700317 Perturbed Loss 0.06530948301777244
Loss 0.06474492988549173 Acc 0.9806256270408631 Perturbed Loss 0.07207705571316182
Loss 0.08536529500037432 Acc 0.9791062450408936 Perturbed Loss 0.09589540150016546
Loss 0.07639259804040194 Acc 0.9798935186862946 Perturbed Loss 0.08256727628409863
Loss 0.06994100615382194 Acc 0.980678528547287 Perturbed Loss 0.07698694035410882
Loss 0.06492318603210151 Acc 0.9838191890716552 Perturbed Loss 0.07186375664547086
Loss 0.06909192956984044 Acc 0.9777672469615937 Perturbed Loss 0.07559352789074182
Loss 0.06478459171950818 Acc 0.9814383447170257 Perturbed Loss 0.07196873929351569
Loss 0.06265009630471469 Acc 0.9820205318927765 Perturbed Loss 0.06839196376502514
Loss 0.07739102598279715 Acc 0.977793174982071 Perturbed Loss 0.08707954369485378
Epoch 15.0 val loss 0.05507836118340492 val acc 0.980074405670166
Loss 0.06737599728628993 Acc 0.9780505013465881 Perturbed Loss 0.07424067401327193
Loss 0.06699913389980792 Acc 0.9775172817707062 Perturbed Loss 0.07299232807010413
Loss 0.07213314846158028 Acc 0.980853990316391 Perturbed Loss 0.07904546042904258
Loss 0.0625773949176073 Acc 0.9801729476451874 Perturbed Loss 0.07029848966747522
Loss 0.061758229210972786 Acc 0.9803589594364166 Perturbed Loss 0.07137632558122277
Loss 0.07204566851258278 Acc 0.9807159304618835 Perturbed Loss 0.0794604092463851
Loss 0.0731114137172699 Acc 0.9802498090267181 Perturbed Loss 0.07979762222617864
Loss 0.07659126199781895 Acc 0.9786726629734039 Perturbed Loss 0.08525886010378599
Loss 0.0630667482316494 Acc 0.9807541620731354 Perturbed Loss 0.06987632231786847
Loss 0.056086934115737674 Acc 0.9844085705280304 Perturbed Loss 0.06168100569397211
Loss 0.06619831271469594 Acc 0.9787219297885895 Perturbed Loss 0.07324628990143538
Loss 0.06425438695587218 Acc 0.9816907668113708 Perturbed Loss 0.07109480917453766
Loss 0.059670108892023566 Acc 0.9814427661895752 Perturbed Loss 0.0667787554860115
Loss 0.06866380110383034 Acc 0.9807457029819489 Perturbed Loss 0.07692303344607353
Loss 0.05809887586161494 Acc 0.9839342415332795 Perturbed Loss 0.06375943295657635
Epoch 16.0 val loss 0.053905025124549866 val acc 0.9802243113517761
Loss 0.06876386873424054 Acc 0.9800421953201294 Perturbed Loss 0.07832603592425585
Loss 0.0718328957259655 Acc 0.981848896741867 Perturbed Loss 0.07820729028433561
Loss 0.05996612779796123 Acc 0.979969185590744 Perturbed Loss 0.06593706171959639
Loss 0.06845250017940999 Acc 0.979319155216217 Perturbed Loss 0.0758154583722353
Loss 0.06304145289584995 Acc 0.9813129997253418 Perturbed Loss 0.07258556064218283
Loss 0.05957128405570984 Acc 0.9801331031322479 Perturbed Loss 0.06611684020608663
Loss 0.0702542038448155 Acc 0.9769189298152924 Perturbed Loss 0.0801384661719203
Loss 0.06659350592643022 Acc 0.9810705268383026 Perturbed Loss 0.0731620530039072
Loss 0.05406056635081768 Acc 0.9832057940959931 Perturbed Loss 0.05976935857906938
Loss 0.07833434594795108 Acc 0.9777567672729492 Perturbed Loss 0.08577628336846828
Loss 0.06392220163717865 Acc 0.979245890378952 Perturbed Loss 0.06976018480956554
Loss 0.0694767503067851 Acc 0.9790198063850403 Perturbed Loss 0.07845276165753604
Loss 0.065223593339324 Acc 0.9751870000362396 Perturbed Loss 0.07215732548385859
Loss 0.06379754705354572 Acc 0.9792466402053833 Perturbed Loss 0.07189992917701601
Loss 0.06687490893527866 Acc 0.9830598473548889 Perturbed Loss 0.07392858136445284
Epoch 17.0 val loss 0.05479472130537033 val acc 0.9804856181144714
Loss 0.06692498564720153 Acc 0.9803933942317963 Perturbed Loss 0.07548688568174838
Loss 0.07057168409228325 Acc 0.9803773880004882 Perturbed Loss 0.0791596706956625
Loss 0.06524236809462308 Acc 0.9772638046741485 Perturbed Loss 0.07083233337849379
Loss 0.06365838326513767 Acc 0.9823125064373016 Perturbed Loss 0.06988601399585605
Loss 0.06415215473622084 Acc 0.9815935325622559 Perturbed Loss 0.07108214253559708
Loss 0.054938960429280995 Acc 0.9829145205020905 Perturbed Loss 0.06217578586190939
Loss 0.059500271640717986 Acc 0.9793662750720977 Perturbed Loss 0.06672696713358164
Loss 0.059785020649433133 Acc 0.9810908770561219 Perturbed Loss 0.06763636616989971
Loss 0.06627821192145347 Acc 0.9800918459892273 Perturbed Loss 0.07293411824852228
Loss 0.0644135944917798 Acc 0.9793862688541413 Perturbed Loss 0.07104890257120132
Loss 0.06210509864613414 Acc 0.9787715029716492 Perturbed Loss 0.06870625592768193
Loss 0.07586837638169527 Acc 0.975352703332901 Perturbed Loss 0.0828099212795496
Loss 0.06007441066205502 Acc 0.9795609092712403 Perturbed Loss 0.06821794494986534
Loss 0.07914297152310609 Acc 0.9786425876617432 Perturbed Loss 0.08691664710640908
Loss 0.05911690359935164 Acc 0.9784938728809357 Perturbed Loss 0.06383845882490277
Epoch 18.0 val loss 0.05411463603377342 val acc 0.9804025292396545
Loss 0.0677374166995287 Acc 0.9769280326366424 Perturbed Loss 0.07427875705063343
Loss 0.06982915677130222 Acc 0.9789594745635987 Perturbed Loss 0.07636707581579685
Loss 0.06861333657056093 Acc 0.9796269333362579 Perturbed Loss 0.07432023834437132
Loss 0.05562581989914179 Acc 0.9793757462501526 Perturbed Loss 0.06221113134175539
Loss 0.060751459393650294 Acc 0.9823633635044098 Perturbed Loss 0.06685681750997902
Loss 0.06231229210272431 Acc 0.9778430759906769 Perturbed Loss 0.06706068102270364
Loss 0.08406053114682437 Acc 0.9764025902748108 Perturbed Loss 0.09173795789480209
Loss 0.06407874479889869 Acc 0.9801918745040894 Perturbed Loss 0.07168291153386236
Loss 0.06026105545461178 Acc 0.9811388266086578 Perturbed Loss 0.06612125063315034
Loss 0.06280946481972932 Acc 0.9798858845233918 Perturbed Loss 0.06939830146729946
Loss 0.06917584080249072 Acc 0.9790237128734589 Perturbed Loss 0.07524985071271657
Loss 0.06217275951057673 Acc 0.9787425374984742 Perturbed Loss 0.06751583974808455
Loss 0.0657099187374115 Acc 0.9794449710845947 Perturbed Loss 0.07188095215708018
Loss 0.07412239775061608 Acc 0.9801278972625732 Perturbed Loss 0.08118806600570679
Loss 0.060947432909160854 Acc 0.982318354845047 Perturbed Loss 0.06689239172264934
Epoch 19.0 val loss 0.05445842817425728 val acc 0.9804424047470093
[12:32:46] INFO     `Trainer.fit` stopped: `max_epochs=20` reached.                                                                                                                         rank_zero.py:53
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750/750 0:03:45 • 0:00:00 3.36it/s train/loss: 0.061 val_loss: 0.054
[12:32:48] INFO     Created a temporary directory at /tmp/tmpga6pd8qu                                                                                                                    instantiator.py:21
           INFO     Writing /tmp/tmpga6pd8qu/_remote_module_non_scriptable.py                                                                                                            instantiator.py:76
           INFO     Global seed set to 304                                                                                                                                                       seed.py:54
           INFO     Using dummy logger. Metrics for this run will not be saved.                                                                                                         logger_config.py:51
           WARNING  /home/alexli/git/JupiterCVML/kore/configs/third_party/lightning_config.py:71: RuntimeWarning: Unable to save checkpoints to W&B folder since you are not logging to     warnings.py:109
                    W&B. Saving to default location.                                                                                                                                                       
                      warnings.warn(                                                                                                                                                                       
                                                                                                                                                                                                           
           INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default        rank_zero.py:53
                    `ModelSummary` callback.                                                                                                                                                               
           INFO     GPU available: True (cuda), used: True                                                                                                                                  rank_zero.py:53
           INFO     TPU available: False, using: 0 TPU cores                                                                                                                                rank_zero.py:53
           INFO     IPU available: False, using: 0 IPUs                                                                                                                                     rank_zero.py:53
           INFO     HPU available: False, using: 0 HPUs                                                                                                                                     rank_zero.py:53
Config: /home/alexli/git/JupiterCVML/kore/SegTrainingConfig_None.gen.yaml
[12:32:49] INFO     Loading model weights from /home/alexli/logs/data/epoch=99-val_loss=0.096904.ckpt for finetuning                                                                        rank_zero.py:53
           INFO     Prepare dataset: world_size=1, local_rank=0                                                                                                              jupiter_seg_data_module.py:139
           INFO     cutnpaste_augmentation_classes=['Humans', 'Tractors or Vehicles']                                                                                        jupiter_seg_data_module.py:143
           INFO     Train dataframe size: 3000                                                                                                                                              rank_zero.py:53
           INFO     Validation dataframe size: 1000                                                                                                                                         rank_zero.py:53
           INFO     Adjusting sampling weights                                                                                                                                 seg_weighted_sampling.py:158
           INFO     [rank: 0] Global seed set to 304                                                                                                                                             seed.py:54
           INFO     Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1                                                                                                                distributed.py:257
           INFO     Added key: store_based_barrier_key:1 to store for rank: 0                                                                                                       distributed_c10d.py:228
           INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.                                                                           distributed_c10d.py:262
           INFO     ----------------------------------------------------------------------------------------------------                                                                    rank_zero.py:53
                    distributed_backend=nccl                                                                                                                                                               
                    All distributed processes registered. Starting with 1 processes                                                                                                                        
                    ----------------------------------------------------------------------------------------------------                                                                                   
                                                                                                                                                                                                           
           INFO     You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' rank_zero.py:53
                    | 'high')` which will trade-off precision for performance. For more details, read                                                                                                      
                    https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision                                                                   
[12:32:50] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory                   warnings.py:109
                    /home/alexli/git/scripts/checkpoints exists and is not empty.                                                                                                                          
                      rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")                                                                                                           
                                                                                                                                                                                                           
           INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                    cuda.py:58
SAMConfig(lr=0.00025, weight_decay=0.0001, betas=(0.9, 0.999), eps=1e-12, rho=0.1, adaptive=True)
           WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s)       warnings.py:109
                    ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.                                                                     
                      rank_zero_warn(                                                                                                                                                                      
                                                                                                                                                                                                           
Loss 0.09131826147437096 Acc 0.9652931296825409 Perturbed Loss 0.1156975668668747
[12:33:20] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not          warnings.py:109
                    necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the                    
                    closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case:                                             
                    https://github.com/pytorch/pytorch/issues/new/choose.                                                                                                                                  
                      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)                                                                                                                                
                                                                                                                                                                                                           
Loss 0.07750817142426968 Acc 0.9704683434963226 Perturbed Loss 0.09364928796887398
Loss 0.08564816508442163 Acc 0.9760064828395844 Perturbed Loss 0.10338648796081543
Loss 0.08319983708672225 Acc 0.9733236181735992 Perturbed Loss 0.09602938700467348
Loss 0.07983405889943242 Acc 0.9758918905258178 Perturbed Loss 0.09221040185540914
Loss 0.09236895088106394 Acc 0.9666785418987274 Perturbed Loss 0.10819073714315891
Loss 0.0798987627774477 Acc 0.9706519019603729 Perturbed Loss 0.09317170094698668
Loss 0.07900056043639779 Acc 0.9776601481437683 Perturbed Loss 0.09301144741475582
Loss 0.08348343700170517 Acc 0.9730456674098968 Perturbed Loss 0.0950338289886713
Loss 0.08410682093352079 Acc 0.9701745855808258 Perturbed Loss 0.0983235328644514
Loss 0.07391665898263454 Acc 0.9766755890846253 Perturbed Loss 0.0828891596198082
Loss 0.08195773802697659 Acc 0.9762193179130554 Perturbed Loss 0.09305926356464625
Loss 0.075784524474293 Acc 0.978096866607666 Perturbed Loss 0.08824699589982629
Loss 0.0681824554130435 Acc 0.9826847410202026 Perturbed Loss 0.08048339039087296
Loss 0.08002209132537245 Acc 0.9755454051494599 Perturbed Loss 0.09247644605115056
Epoch 0.0 val loss 0.05380687117576599 val acc 0.9795572757720947
Loss 0.08088633265346289 Acc 0.972582221031189 Perturbed Loss 0.09397621922194958
Loss 0.07574395563453436 Acc 0.9729838740825653 Perturbed Loss 0.08678084509447218
Loss 0.07698140855878592 Acc 0.9669383263587952 Perturbed Loss 0.09159194990992546
Loss 0.0764261468872428 Acc 0.9740820872783661 Perturbed Loss 0.08809267152100801
Loss 0.08176028601825237 Acc 0.9747347497940063 Perturbed Loss 0.09458088895305991
Loss 0.07599549872800708 Acc 0.9765522837638855 Perturbed Loss 0.08564509972929954
Loss 0.0820825831964612 Acc 0.9746342194080353 Perturbed Loss 0.09217808429151773
Loss 0.07220772344619036 Acc 0.9791851329803467 Perturbed Loss 0.08209174770861864
Loss 0.0748528733663261 Acc 0.9763133895397186 Perturbed Loss 0.08470181925222278
Loss 0.07761880675330758 Acc 0.9761428761482239 Perturbed Loss 0.09009483199566602
Loss 0.07619404722005128 Acc 0.9684469079971314 Perturbed Loss 0.0895028336532414
Loss 0.08848470877856016 Acc 0.9728400444984436 Perturbed Loss 0.10392783720046282
Loss 0.07416720006614924 Acc 0.9805682706832886 Perturbed Loss 0.08325710348784923
Loss 0.0917995454929769 Acc 0.9717753791809082 Perturbed Loss 0.10736262004822493
Loss 0.07630442336201668 Acc 0.976396211385727 Perturbed Loss 0.09064817458391189
Epoch 1.0 val loss 0.05384708195924759 val acc 0.9795397520065308
Loss 0.06984710255637765 Acc 0.9740522003173828 Perturbed Loss 0.07923818930983544
Loss 0.08417916931211948 Acc 0.9780256164073944 Perturbed Loss 0.09207021616399289
Loss 0.0712367221340537 Acc 0.9786517333984375 Perturbed Loss 0.0824645622819662
Loss 0.06486894823610782 Acc 0.9824393427371979 Perturbed Loss 0.07353580962866545
Loss 0.07214195672422648 Acc 0.9808663702011109 Perturbed Loss 0.0836404649168253
Loss 0.07109783217310905 Acc 0.9769415402412415 Perturbed Loss 0.07957127951085567
Loss 0.0776800829730928 Acc 0.9791799747943878 Perturbed Loss 0.09096803724765777
Loss 0.06985171597450972 Acc 0.9819485318660736 Perturbed Loss 0.08077297896146775
Loss 0.07632776591926813 Acc 0.9771526062488556 Perturbed Loss 0.08707739226520061
Loss 0.07548024883493781 Acc 0.9797522127628326 Perturbed Loss 0.08389198791235686
Loss 0.07092519287019967 Acc 0.9797795307636261 Perturbed Loss 0.07867268491536379
Loss 0.07770610235631466 Acc 0.9749148905277252 Perturbed Loss 0.08570483349263668
Loss 0.07837101019918918 Acc 0.9725696218013763 Perturbed Loss 0.09120438687503338
Loss 0.09479852300137281 Acc 0.9672779655456543 Perturbed Loss 0.10640945713967084
Loss 0.07455396004021168 Acc 0.9754313492774963 Perturbed Loss 0.08607290014624595
Epoch 2.0 val loss 0.05378413945436478 val acc 0.9802327156066895
Loss 0.0724698492512107 Acc 0.9751578271389008 Perturbed Loss 0.08303524155169725
Loss 0.06326770007610322 Acc 0.9805646991729736 Perturbed Loss 0.07345886275172234
Loss 0.0684801309928298 Acc 0.9806433427333832 Perturbed Loss 0.0781882631778717
Loss 0.07233231578022242 Acc 0.9804541146755219 Perturbed Loss 0.08362919472157955
Loss 0.08134624928236008 Acc 0.9782608759403228 Perturbed Loss 0.09300563037395478
Loss 0.07774087151512504 Acc 0.9760377025604248 Perturbed Loss 0.08993691155686974
Loss 0.06416365560144185 Acc 0.9837047171592712 Perturbed Loss 0.07310497418045997
Loss 0.07756892457604408 Acc 0.9769956994056702 Perturbed Loss 0.08712781116366386
Loss 0.08152047470211983 Acc 0.978316740989685 Perturbed Loss 0.09014685943722725
Loss 0.07385508073493838 Acc 0.9777162718772888 Perturbed Loss 0.08153616139665246
Loss 0.06335612943395973 Acc 0.9775609040260315 Perturbed Loss 0.07239057824015617
Loss 0.08191417787224055 Acc 0.9731978964805603 Perturbed Loss 0.09072294495999814
Loss 0.08311898957937956 Acc 0.9768539702892304 Perturbed Loss 0.094000792093575
Loss 0.07478487808257342 Acc 0.9711570239067078 Perturbed Loss 0.08356422405689955
Loss 0.07492634244263172 Acc 0.9779370594024658 Perturbed Loss 0.08578119985759258
Epoch 3.0 val loss 0.05439447984099388 val acc 0.9798543453216553
Loss 0.06318988280370831 Acc 0.9813790905475617 Perturbed Loss 0.07517728686332703
Loss 0.0752249700948596 Acc 0.9822805941104888 Perturbed Loss 0.08486813075840473
Loss 0.0647527476400137 Acc 0.9748631978034973 Perturbed Loss 0.07257193770259619
Loss 0.08240144714713096 Acc 0.9792306530475616 Perturbed Loss 0.0951525255665183
Loss 0.07349524909630417 Acc 0.9763920068740845 Perturbed Loss 0.08265219705179333
Loss 0.07137051533907651 Acc 0.978816248178482 Perturbed Loss 0.0799107950553298
Loss 0.0641912630572915 Acc 0.9794912326335907 Perturbed Loss 0.07325487203896046
Loss 0.06888436824083329 Acc 0.9795929145812988 Perturbed Loss 0.07534992538392543
Loss 0.06819394750520587 Acc 0.9757296049594879 Perturbed Loss 0.0786736067198217
Loss 0.06479572979733347 Acc 0.9771634709835052 Perturbed Loss 0.0776753706485033
Loss 0.07722894370555877 Acc 0.9793983829021454 Perturbed Loss 0.08933056868612767
Loss 0.07952257793396711 Acc 0.9758553075790405 Perturbed Loss 0.08889962378889323
Loss 0.07586969804018735 Acc 0.9758787846565247 Perturbed Loss 0.08852219190448522
Loss 0.0721875424310565 Acc 0.9797500491142273 Perturbed Loss 0.08278460118919612
Loss 0.07209393970668315 Acc 0.9798948097229004 Perturbed Loss 0.08190536379814148
Epoch 4.0 val loss 0.05460808053612709 val acc 0.9798495173454285
Loss 0.07253349885344505 Acc 0.9771619439125061 Perturbed Loss 0.08263228934258222
Loss 0.07591161351650953 Acc 0.9798541450500489 Perturbed Loss 0.08660677712410689
Loss 0.07931648679077626 Acc 0.9770811319351196 Perturbed Loss 0.08840471480041742
Loss 0.08254501521587372 Acc 0.9726480758190155 Perturbed Loss 0.09397181160748005
Loss 0.06939927510917186 Acc 0.9790021193027496 Perturbed Loss 0.07972134198993444
Loss 0.08057576511055231 Acc 0.9750688946247101 Perturbed Loss 0.0944454801082611
Loss 0.06638861209154129 Acc 0.9802140319347381 Perturbed Loss 0.0727506347000599
Loss 0.06609663426876068 Acc 0.978190838098526 Perturbed Loss 0.07704487927258015
Loss 0.07440742902457714 Acc 0.9790594077110291 Perturbed Loss 0.08413393508642912
Loss 0.06962489552795886 Acc 0.9775654900074006 Perturbed Loss 0.0788924902677536
Loss 0.07381509050726891 Acc 0.9778258335590363 Perturbed Loss 0.08485032375901938
Loss 0.08294898603111506 Acc 0.9744216203689575 Perturbed Loss 0.0933272897079587
Loss 0.0762738872691989 Acc 0.9802351641654968 Perturbed Loss 0.08430019106715918
Loss 0.0750515802577138 Acc 0.9789155495166778 Perturbed Loss 0.08580847710371017
Loss 0.06874594213441014 Acc 0.9777681422233582 Perturbed Loss 0.07673247447237372
Epoch 5.0 val loss 0.05384158715605736 val acc 0.9800739288330078
Loss 0.07142011603340506 Acc 0.9783186519145965 Perturbed Loss 0.08004342421889304
Loss 0.073798858076334 Acc 0.9794216167926788 Perturbed Loss 0.08445828355848789
Loss 0.06310141243040562 Acc 0.9806300485134125 Perturbed Loss 0.0728573191165924
Loss 0.07905624680221081 Acc 0.9768888747692108 Perturbed Loss 0.0895701728016138
Loss 0.07151919739320874 Acc 0.9825930190086365 Perturbed Loss 0.07918131001293659
Loss 0.07369257669895887 Acc 0.9776709103584289 Perturbed Loss 0.0843679242581129
Loss 0.0708007413521409 Acc 0.9762272357940673 Perturbed Loss 0.07858807392418385
Loss 0.07148648645728826 Acc 0.9815746772289277 Perturbed Loss 0.08038778584450483
Loss 0.06763375017791987 Acc 0.9789549899101258 Perturbed Loss 0.07692063983529807
Loss 0.08075043620541691 Acc 0.9769262337684631 Perturbed Loss 0.09021355155855418
Loss 0.07196981070563196 Acc 0.9787305748462677 Perturbed Loss 0.08226770099252462
Loss 0.07035576194524765 Acc 0.9790690433979035 Perturbed Loss 0.08059493036009371
Loss 0.07310772047378122 Acc 0.9768549597263336 Perturbed Loss 0.08271165817975998
Loss 0.0710958170890808 Acc 0.9813751995563507 Perturbed Loss 0.08032692980021239
Loss 0.07526575677096843 Acc 0.9746352052688598 Perturbed Loss 0.08599289003759622
Epoch 6.0 val loss 0.05444645509123802 val acc 0.9798972606658936
Loss 0.08086439704522491 Acc 0.9747153413295746 Perturbed Loss 0.08981208398938179
Loss 0.08128265814855695 Acc 0.9766900110244751 Perturbed Loss 0.09064470011740923
Loss 0.07086868207901716 Acc 0.9785291600227356 Perturbed Loss 0.07719363790005446
Loss 0.06300338933244348 Acc 0.9826939129829406 Perturbed Loss 0.07253180952742695
Loss 0.06906626256182789 Acc 0.9777746891975403 Perturbed Loss 0.0758627550676465
Loss 0.07381446048617363 Acc 0.9787080466747284 Perturbed Loss 0.08122469712048769
Loss 0.07641697403043508 Acc 0.9756795060634613 Perturbed Loss 0.08766423195600509
Loss 0.06152654528617859 Acc 0.9811322033405304 Perturbed Loss 0.06930789161473512
Loss 0.07259277354925871 Acc 0.9771793854236602 Perturbed Loss 0.08259625636041164
Loss 0.07646331179887056 Acc 0.9789024877548218 Perturbed Loss 0.08324022341519594
Loss 0.07424119297415017 Acc 0.982188481092453 Perturbed Loss 0.086059440523386
Loss 0.06911824498325586 Acc 0.9792668914794922 Perturbed Loss 0.07604425173252821
Loss 0.06493803020566702 Acc 0.9786227297782898 Perturbed Loss 0.07402797259390353
Loss 0.0688327618688345 Acc 0.9813432240486145 Perturbed Loss 0.07601500663906335
Loss 0.07403596341609955 Acc 0.9777825808525086 Perturbed Loss 0.08382521133869886
Epoch 7.0 val loss 0.05291753262281418 val acc 0.9800783395767212
Loss 0.0640810739248991 Acc 0.9765459418296814 Perturbed Loss 0.0711970616877079
Loss 0.06803485814481974 Acc 0.9746018445491791 Perturbed Loss 0.07617901109158992
Loss 0.06338110448792576 Acc 0.9786682307720185 Perturbed Loss 0.07341100851073862
Loss 0.0715579817816615 Acc 0.9771414780616761 Perturbed Loss 0.07909255109727382
Loss 0.06174802880734205 Acc 0.9799082136154175 Perturbed Loss 0.06976676501333713
Loss 0.07076417587697506 Acc 0.9781011748313904 Perturbed Loss 0.07893912615254521
Loss 0.06049380805343389 Acc 0.9783982908725739 Perturbed Loss 0.07080762319266797
Loss 0.06464116100221873 Acc 0.978326187133789 Perturbed Loss 0.0743171814084053
Loss 0.06867072936147452 Acc 0.9769126224517822 Perturbed Loss 0.0780310033261776
Loss 0.06398258838802576 Acc 0.9769836950302124 Perturbed Loss 0.07169548980891705
Loss 0.07432895805686712 Acc 0.9789375019073486 Perturbed Loss 0.08515134539455176
Loss 0.07016389595344663 Acc 0.9794356763362885 Perturbed Loss 0.07752511171624064
Loss 0.06610471993684769 Acc 0.9788710367679596 Perturbed Loss 0.07641320683062076
Loss 0.07397290404886007 Acc 0.9765572738647461 Perturbed Loss 0.0844273455068469
Loss 0.07279350206255913 Acc 0.9813165581226349 Perturbed Loss 0.07995697986334563
Epoch 8.0 val loss 0.05446401238441467 val acc 0.980283796787262
Loss 0.06987329497933388 Acc 0.9757439112663269 Perturbed Loss 0.07981885600835086
Loss 0.0675034368596971 Acc 0.9786681067943573 Perturbed Loss 0.07585431344807148
Loss 0.07249983198940754 Acc 0.9771204316616058 Perturbed Loss 0.08116920977830887
Loss 0.06213323082774878 Acc 0.9791840255260468 Perturbed Loss 0.07233682498335839
Loss 0.06989488188177347 Acc 0.9773843264579773 Perturbed Loss 0.07710246849805116
Loss 0.06812402926385402 Acc 0.9768945598602294 Perturbed Loss 0.07559824775904417
Loss 0.0625181733816862 Acc 0.981783686876297 Perturbed Loss 0.07034857489168644
Loss 0.0764533805474639 Acc 0.9803219139575958 Perturbed Loss 0.08367170237004756
Loss 0.06267212696373463 Acc 0.9801603031158447 Perturbed Loss 0.07146355096250773
Loss 0.0644912464171648 Acc 0.982479190826416 Perturbed Loss 0.07576954293996095
Loss 0.06677496943622828 Acc 0.9806144118309021 Perturbed Loss 0.07334888465702534
Loss 0.06968675578013063 Acc 0.978080278635025 Perturbed Loss 0.07757407074794173
Loss 0.06892156846821308 Acc 0.978897032737732 Perturbed Loss 0.07593824833631516
Loss 0.0765003171376884 Acc 0.9763020622730255 Perturbed Loss 0.08847456365823746
Loss 0.07281110011041164 Acc 0.9777583956718445 Perturbed Loss 0.08171693950891495
Epoch 9.0 val loss 0.05265191197395325 val acc 0.9802151918411255
Loss 0.0699474841542542 Acc 0.982634528875351 Perturbed Loss 0.07919193509966135
Loss 0.0701795895025134 Acc 0.9776821613311768 Perturbed Loss 0.07681578401476145
Loss 0.062446257658302785 Acc 0.9817140662670135 Perturbed Loss 0.0701270547695458
Loss 0.07669261660426856 Acc 0.9750258100032806 Perturbed Loss 0.08597778661176562
Loss 0.061074084285646674 Acc 0.9829490232467651 Perturbed Loss 0.06973705146461726
Loss 0.06462491404265165 Acc 0.9787662410736084 Perturbed Loss 0.07490635097026825
Loss 0.06637294605374336 Acc 0.9776490676403046 Perturbed Loss 0.07446343146264553
Loss 0.06119131832383573 Acc 0.9838839471340179 Perturbed Loss 0.06800267281010747
Loss 0.06326946713030339 Acc 0.9783152651786804 Perturbed Loss 0.07234046604484319
Loss 0.0685378685593605 Acc 0.9767317163944245 Perturbed Loss 0.07544826865196227
Loss 0.06467889741063118 Acc 0.9787881004810334 Perturbed Loss 0.07287177201360465
Loss 0.0750927022472024 Acc 0.9767914271354675 Perturbed Loss 0.08516747951507568
Loss 0.06731457340531051 Acc 0.9795699143409728 Perturbed Loss 0.0771969280205667
Loss 0.06526089053601027 Acc 0.9783240675926208 Perturbed Loss 0.07504554431885481
Loss 0.06536308813840151 Acc 0.9773419940471649 Perturbed Loss 0.07360129915177822
Epoch 10.0 val loss 0.053256671875715256 val acc 0.9802795648574829
Loss 0.07009314726106823 Acc 0.9805136680603027 Perturbed Loss 0.07728507444262504
Loss 0.06947730341926217 Acc 0.9821466386318207 Perturbed Loss 0.0776356315612793
Loss 0.06452138707041741 Acc 0.9805598318576813 Perturbed Loss 0.07194244982674718
Loss 0.060499584618955854 Acc 0.9792829763889312 Perturbed Loss 0.06877566836774349
Loss 0.07095765329897404 Acc 0.9784776210784912 Perturbed Loss 0.07905306814238429
Loss 0.0635791441053152 Acc 0.9780298697948456 Perturbed Loss 0.07102891404181719
Loss 0.06817095268517732 Acc 0.9786287033557892 Perturbed Loss 0.07948129737749696
[13:20:55] WARNING  /home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/l warnings.py:109
                    ightning/pytorch/trainer/call.py:53: UserWarning: Detected                      
                    KeyboardInterrupt, attempting graceful shutdown...                              
                      rank_zero_warn("Detected KeyboardInterrupt, attempting                        
                    graceful shutdown...")                                                          
                                                                                                    
Epoch 11/19 ━━━━━━━━━━━━━╸             394/750 0:01:59 • 0:01:47 3.35it/s train/loss: 0.068         
                                                                          val_loss: 0.053           
