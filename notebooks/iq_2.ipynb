{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dl.utils.io_utils import normalize_image\n",
    "\n",
    "%matplotlib inline\n",
    "from cv.core.image_quality_server_side import ImageQuality\n",
    "\n",
    "# from cv.core.image_quality_server_side_halo import ImageQuality\n",
    "from dl.utils.config import DEFAULT_TONEMAP_PARAMS\n",
    "import tqdm\n",
    "from dl.utils.mask_utils import get_mask\n",
    "from cv.core.image_quality_schema import (\n",
    "    Bad_Depth,\n",
    "    Bright,\n",
    "    Dark,\n",
    "    ImageQualityClasses,\n",
    "    ImageQualityFeatures,\n",
    "    ImageQualityParameters,\n",
    "    Smudge,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please update the default location as you deem fit\n",
    "cvml_path = '/home/alex.li/git/JupiterCVML/europa/base/src/europa'\n",
    "halo_mask_dir = cvml_path + \"/dl/config/halo_masks\"\n",
    "dataset_idx = 1\n",
    "directory = ['/data/jupiter/datasets/bad_iq_halo_labelbox_plus_exposure', '/data2/jupiter/datasets/20231017_halo_rgb_labeled_excluded_bad_iq', '/data/jupiter/datasets/iq_2023_v5_anno'][dataset_idx]\n",
    "csv_name = ['654a5bb2e89875bddc714dd2_master_annotations.csv', '653a7a0a3c2d8ab221f6d915_master_annotations.csv','64dfcc1de5a41169c7deb205_master_annotations.csv'][dataset_idx]\n",
    "\n",
    "dset_name = directory.split('/')[-1]\n",
    "stereo_df_full = pd.read_csv(os.path.join(directory, csv_name), low_memory=False)\n",
    "df = stereo_df_full.drop_duplicates(['id'])[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halo_masks = {}\n",
    "for file in os.listdir(halo_mask_dir):\n",
    "    if not file.endswith(\".png\"):\n",
    "        continue\n",
    "    name = file.split(\"_\")[0] + \"_\" + file.split(\"_\")[1]\n",
    "    halo_masks[name] = get_mask(os.path.join(halo_mask_dir, file))\n",
    "def mask_image(image, camera_location):\n",
    "    mask_name = camera_location + \"_\" + str(image.shape[1])\n",
    "    if mask_name in halo_masks.keys():\n",
    "        return halo_masks[mask_name]\n",
    "    return np.zeros_like(image, dtype=np.uint8)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = os.listdir(directory)[0]\n",
    "# obj = np.load(directory + file_name)\n",
    "# im_l = normalize_image(obj['left'], row['hdr_mode']) * 255\n",
    "# depth = obj['point_cloud'][..., 2]\n",
    "# sky_mask = np.zeros_like(depth, dtype=np.uint8)\n",
    "# sky_mask[depth > 50] = 1\n",
    "# sky_mask = cv2.resize(sky_mask, (im_l.shape[1], im_l.shape[0]))\n",
    "# ego_mask = mask_image(im_l, row['camera_location'])\n",
    "# mask = sky_mask | ego_mask\n",
    "# left_gray_img = np.int32(cv2.cvtColor(im_l, cv2.COLOR_RGB2GRAY))\n",
    "# left_hsl_img = np.int32(cv2.cvtColor(im_l, code=cv2.COLOR_RGB2HSV)[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQ parameteres\n",
    "def get_image_and_mask(row):\n",
    "    folder_path  = directory + \"/processed/images/\" + row['id'] + \"/\"\n",
    "    file_name = os.listdir(folder_path)[0]\n",
    "    obj = np.load(folder_path + file_name)\n",
    "    im_l = normalize_image(obj['left'], row['hdr_mode'], return_8_bit=True)\n",
    "    im_r = normalize_image(obj['right'], row['hdr_mode'], return_8_bit=True)\n",
    "    depth = obj['point_cloud'][..., 2]\n",
    "    sky_mask = np.zeros_like(depth, dtype=np.uint8)\n",
    "    sky_mask[depth > 50] = 1\n",
    "    sky_mask[im_l.shape[0]//2:,:] = 0 # bottom should never be sky no matter what the depth says\n",
    "    sky_mask = cv2.resize(sky_mask, (im_l.shape[1], im_l.shape[0]))\n",
    "    ego_mask = mask_image(im_l, row['camera_location'])\n",
    "    mask = (1 - sky_mask | ego_mask)\n",
    "    return {\n",
    "        'im_l_hdr': obj['left'],\n",
    "        'im_l': im_l,\n",
    "        'im_r': im_r,\n",
    "        'mask': mask\n",
    "    }\n",
    "def get_binary_image(gray_img, row):\n",
    "    binary_image = cv2.medianBlur(gray_img, Smudge.BINARY_KERNEL_SIZE)\n",
    "    if row['operation_time'] == \"daytime\":\n",
    "        threshold_type = cv2.THRESH_BINARY\n",
    "    else:\n",
    "        threshold_type = cv2.THRESH_BINARY_INV\n",
    "\n",
    "    binary_image = cv2.adaptiveThreshold(\n",
    "        binary_image,\n",
    "        ImageQualityParameters.MAX_RANGE,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        threshold_type,\n",
    "        Smudge.BINARY_KERNEL_SIZE,\n",
    "        2,\n",
    "        )\n",
    "    return binary_image\n",
    "\n",
    "def diff_in_grid(img_l: np.ndarray, img_r: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Stats on every DEFAULT_GRID_SIZE x DEFAULT_GRID_SIZE square of the l/r image pair\"\"\"\n",
    "    l_cum = np.cumsum(np.cumsum(img_l, axis=1, dtype=np.int32), axis=0)\n",
    "    r_cum = np.cumsum(np.cumsum(img_r, axis=1, dtype=np.int32), axis=0)\n",
    "    S = 128 #DEFAULT_GRID_SIZE\n",
    "    # left_sum[i,j] = np.sum(img_l[i:i+S,j:j+S])\n",
    "    left_sum = l_cum[128:,128:] + l_cum[:-128,:-128] - l_cum[128:,:-128] - l_cum[:-128,128:]\n",
    "    right_sum = r_cum[128:,128:] + r_cum[:-128,:-128] - r_cum[128:,:-128] - r_cum[:-128,128:]\n",
    "    diff_grid = abs(left_sum - right_sum) // (S * S)\n",
    "    return diff_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SAVED = False\n",
    "if USE_SAVED:\n",
    "    sub_df = pd.read_parquet('~/logs/iq_analysis.parquet')\n",
    "else:\n",
    "    sub_df = df.copy()[1::10]\n",
    "    brightness_gray_at_p = []\n",
    "    brightness_hdr_at_p = []\n",
    "    brightness_hdr_lo_at_p = []\n",
    "    grayscale_max_diff = []\n",
    "    binary_max_diff = []\n",
    "    adaptive_thresh_max_cc = []\n",
    "    for i in range(100):\n",
    "        brightness_gray_at_p.append([])\n",
    "        brightness_hdr_at_p.append([])\n",
    "        brightness_hdr_lo_at_p.append([])\n",
    "    for _, row in tqdm.tqdm(iterable=sub_df.iterrows(), total=len(sub_df)):\n",
    "        res  = get_image_and_mask(row)\n",
    "        im_l_hdr = res['im_l_hdr']\n",
    "        im_l = res['im_l']\n",
    "        im_r = res['im_r']\n",
    "        mask = res['mask'] == 1 # the ==1 will convert to correct dtype\n",
    "        left_gray_img = cv2.cvtColor(im_l, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # BRIGHTNESS\n",
    "        for i, val in enumerate(iterable=list(np.percentile(left_gray_img[mask], range(100)))):\n",
    "            brightness_gray_at_p[i].append(val)\n",
    "        hdr_gray = im_l_hdr[:,:,0] * .2126 + im_l_hdr[:,:,1] * .7152 + im_l_hdr[:,:,2] * .0722\n",
    "        for i, val in enumerate(iterable=list(np.percentile(hdr_gray[mask], range(100)))):\n",
    "            brightness_hdr_at_p[i].append(val)\n",
    "\n",
    "        ## SMUDGE\n",
    "        # Grayscale difference\n",
    "        right_gray_img = cv2.cvtColor(im_r, cv2.COLOR_RGB2GRAY)\n",
    "        diff_grid = diff_in_grid(left_gray_img * mask, right_gray_img * mask)\n",
    "\n",
    "        # Binary difference\n",
    "        left_binary_img = get_binary_image(left_gray_img, row)\n",
    "        right_binary_img = get_binary_image(right_gray_img, row)\n",
    "        binary_diff_grid = diff_in_grid(left_binary_img * mask, right_binary_img * mask)\n",
    "        grayscale_max_diff.append(np.max(diff_grid))\n",
    "        binary_max_diff.append(np.max(binary_diff_grid))\n",
    "\n",
    "        # # Adaptive threshold\n",
    "        left_binary_img_adaptive = np.logical_and(left_binary_img, mask)\n",
    "        kernel = np.ones(\n",
    "            (\n",
    "                Smudge.ADAPTIVE_THRESHOLD_KERNEL_SIZE,\n",
    "                Smudge.ADAPTIVE_THRESHOLD_KERNEL_SIZE,\n",
    "            ),\n",
    "            np.uint8,\n",
    "        )\n",
    "        left_binary_img_adaptive = cv2.erode(left_binary_img_adaptive.astype(np.uint8), kernel)\n",
    "        left_binary_img_adaptive = cv2.medianBlur(\n",
    "            left_binary_img_adaptive, Smudge.ADAPTIVE_THRESHOLD_BLUR_KERNEL_SIZE\n",
    "        )\n",
    "        totalLabels, _, values, _ = cv2.connectedComponentsWithStats(\n",
    "            left_binary_img_adaptive, Smudge.CONNECTIVITY_WAY, cv2.CV_32S\n",
    "        )\n",
    "        smudge_areas = []\n",
    "        # Loop through each component\n",
    "        for j in range(1, totalLabels):\n",
    "            # Area of the component\n",
    "            smudge_areas.append(values[j, cv2.CC_STAT_AREA])\n",
    "        smudge_areas = [a for a in smudge_areas if a < Smudge.CONNECTED_COMPONENTS_MAX_AREA]\n",
    "        biggest_smudge = max(smudge_areas +[0])\n",
    "        adaptive_thresh_max_cc.append(biggest_smudge)\n",
    "\n",
    "    for i in range(100):\n",
    "        sub_df[f'gray_{i}'] = brightness_gray_at_p[i]\n",
    "        sub_df[f'hdr_{i}'] = brightness_hdr_at_p[i]\n",
    "    sub_df['gray_diff'] = grayscale_max_diff\n",
    "    sub_df['binary_diff'] = binary_max_diff\n",
    "    sub_df['adaptive'] = adaptive_thresh_max_cc\n",
    "    \n",
    "    sub_df = sub_df.copy()\n",
    "    sub_df.to_parquet('~/logs/iq_analysis.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(cats, bright_quantity, percentile):\n",
    "    ncols = 20\n",
    "    cols_per_row = 5\n",
    "    rows_per_cat = (cols_per_row - 1 + ncols) // cols_per_row\n",
    "    nrows = len(cats) * rows_per_cat\n",
    "    fig, ax = plt.subplots(nrows, cols_per_row, figsize=(cols_per_row * 3.2, nrows * 4))\n",
    "    for i, subdf in enumerate(cats):\n",
    "        for j in range(ncols):\n",
    "            if j >= len(subdf):\n",
    "                break\n",
    "            folder_path  = directory + \"/processed/images/\" + subdf.iloc[j]['id'] + \"/\"\n",
    "            file_name = os.listdir(folder_path)[0]\n",
    "            obj = np.load(folder_path + file_name)\n",
    "            im = normalize_image(obj['left'], subdf.iloc[j]['hdr_mode'])\n",
    "            ax[i * rows_per_cat + j // cols_per_row][j % cols_per_row].imshow(im)\n",
    "            ax[i * rows_per_cat + j // cols_per_row][j % cols_per_row].set_title(f\"{bright_quantity}@{percentile}%:{subdf.iloc[j][f'{bright_quantity}_{percentile}']:.2}\")\n",
    "            ax[i * rows_per_cat + j // cols_per_row][j % cols_per_row].set_title(\n",
    "                f\"{subdf.iloc[j]['hdr_12']:.2f}g{int(subdf.iloc[j]['gray_70'])}g{int(subdf.iloc[j]['gray_20'])}w{subdf.iloc[j]['w']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_BRIGHT = True\n",
    "if SHOW_BRIGHT:\n",
    "    # is_bright = (sub_df['hdr_10'] > 1.2e4) & (sub_df['hdrlo_55'] > 1e4) & (sub_df['gray_70'] > 180) & (sub_df['gray_20'] > 75)\n",
    "    w = sub_df['hdr_12'] / 1000 + np.maximum(sub_df['gray_70'] - 170, 0) + np.maximum(sub_df['gray_20'] - 75, 0) / 2\n",
    "    w[sub_df['hdr_80'] < 1000] -= 100\n",
    "    sub_df['w'] = w\n",
    "    is_bright = w > 75\n",
    "    bright_images = sub_df[is_bright]\n",
    "    sub_df = sub_df.sort_values('w')\n",
    "    show_images([sub_df[is_bright], sub_df[~is_bright][::-1]], 'hdr', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_smudge(df):\n",
    "    assert len(df) <= 10\n",
    "    nrows = len(df)\n",
    "    cols_per_row = 6\n",
    "    fig, ax = plt.subplots(nrows, cols_per_row, figsize=(cols_per_row * 3.2, nrows * 4))\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        artifacts = get_image_and_mask(row)\n",
    "        mask = artifacts['mask']\n",
    "        ax[i][0].imshow(artifacts['im_l'] / 255)\n",
    "        ax[i][1].imshow(artifacts['im_r'] / 255)\n",
    "\n",
    "        # Grayscale difference\n",
    "        left_gray_img = cv2.cvtColor(artifacts['im_l'], cv2.COLOR_RGB2GRAY)\n",
    "        right_gray_img = cv2.cvtColor(artifacts['im_r'], cv2.COLOR_RGB2GRAY)\n",
    "        diff_grid = diff_in_grid(left_gray_img * mask, right_gray_img * mask)\n",
    "\n",
    "        # Binary difference\n",
    "        left_binary_img = get_binary_image(left_gray_img, row)\n",
    "        right_binary_img = get_binary_image(right_gray_img, row)\n",
    "        binary_diff_grid = diff_in_grid(left_binary_img, right_binary_img)\n",
    "\n",
    "        # Adaptive threshold\n",
    "        left_binary_img_adaptive = np.logical_and(left_binary_img, mask)\n",
    "        kernel = np.ones(\n",
    "            (\n",
    "                Smudge.ADAPTIVE_THRESHOLD_KERNEL_SIZE,\n",
    "                Smudge.ADAPTIVE_THRESHOLD_KERNEL_SIZE,\n",
    "            ),\n",
    "            np.uint8,\n",
    "        )\n",
    "        left_binary_img_adaptive = cv2.erode(left_binary_img_adaptive.astype(np.uint8), kernel)\n",
    "        left_binary_img_adaptive = cv2.medianBlur(\n",
    "            left_binary_img_adaptive, Smudge.ADAPTIVE_THRESHOLD_BLUR_KERNEL_SIZE\n",
    "        )\n",
    "        totalLabels, _, values, _ = cv2.connectedComponentsWithStats(\n",
    "            left_binary_img_adaptive, Smudge.CONNECTIVITY_WAY, cv2.CV_32S\n",
    "        )\n",
    "        smudge_areas = []\n",
    "        # Loop through each component\n",
    "        for j in range(1, totalLabels):\n",
    "            # Area of the component\n",
    "            smudge_areas.append(values[j, cv2.CC_STAT_AREA])\n",
    "        smudge_areas = sorted(smudge_areas)[-5:]\n",
    "\n",
    "        ax[i][2].imshow(diff_grid)\n",
    "        ax[i][2].set_title(np.max(diff_grid))\n",
    "        ax[i][3].imshow(binary_diff_grid)\n",
    "        ax[i][3].set_title(np.max(binary_diff_grid))\n",
    "        ax[i][4].imshow(left_binary_img_adaptive)\n",
    "        ax[i][4].set_title(smudge_areas)\n",
    "        ax[i][5].imshow(mask)\n",
    "        ax[i][5].set_title(\"sky_mask | ego_mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbright_df = sub_df[~is_bright].copy()\n",
    "unbright_df['high_thresh'] = np.where(unbright_df['operation_time'] == 'daytime', 98, 108)\n",
    "unbright_df['lo_thresh'] = np.where(unbright_df['operation_time'] == 'daytime', 55, 65)\n",
    "has_smudge = unbright_df['gray_diff'] > unbright_df['high_thresh']\n",
    "no_smudge = unbright_df['gray_diff'] < unbright_df['lo_thresh']\n",
    "has_smudge = has_smudge | (~no_smudge & (unbright_df['binary_diff'] > Smudge.BINARY_SMUDGE_THRESHOLD))\n",
    "no_smudge = no_smudge | (unbright_df['binary_diff'] < Smudge.BINARY_NOT_A_SMUDGE_THRESHOLD)\n",
    "has_smudge = has_smudge | (~no_smudge & (unbright_df['adaptive'] > Smudge.CONNECTED_COMPONENTS_MIN_AREA))\n",
    "\n",
    "plot_image_smudge(unbright_df[has_smudge][:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
