{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "import datetime\n",
    "import io\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import imageio\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from dl.config.label_map_helper import LabelMapHelper, LabelConversion\n",
    "import json\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=12, progress_bar=True)\n",
    "import seaborn as sns\n",
    "\n",
    "from brtdevkit.core.db.athena import AthenaClient\n",
    "from brtdevkit.data import Dataset\n",
    "from timezonefinder import TimezoneFinderL\n",
    "import pytz\n",
    "import cv2\n",
    "from brtdevkit.util.aws.s3 import S3\n",
    "client = S3()\n",
    "\n",
    "from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataset\n",
    "from aletheia_dataset_creator.config.dataset_config import LEFT_CAMERAS, ALL_CAMERA_PAIRS_LIST\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "athena = AthenaClient()\n",
    "s3 = boto3.resource('s3')\n",
    "tf = TimezoneFinderL()\n",
    "from pathlib import Path\n",
    "home = Path(os.path.expanduser('~'))\n",
    "data_path = home / 'data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/sandbox1/alex.li/set3_image_ids.csv', 'r') as f:\n",
    "    imids = f.readline().split(',')\n",
    "print(len(imids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1245 human\n",
    "# 12515 vehicle\n",
    "data_dir = \"/data/jupiter/datasets/vehicles_driving_in_dust/\"\n",
    "df = pd.read_csv(data_dir + '/64dfb36ebe1e14d37b7287d8_master_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 716\n",
    "# # 5893\n",
    "# data_dir=\"/data/jupiter/li.yu/data/Jupiter_2023_may_loamy731_vehicle_dust_human_stereo/\"\n",
    "# path =data_dir + \"/master_annotations.csv\"\n",
    "# df_unlabled_1 = pd.read_csv(path)\n",
    "\n",
    "# # 533\n",
    "# # 6622\n",
    "# data_dir=\"/data/jupiter/li.yu/data/Jupiter_2023_may_loamy731_vehicle_dust_human_stereo_part2/\"\n",
    "# path =data_dir + \"/master_annotations.csv\"\n",
    "# df_unlabled_2 = pd.read_csv(path)\n",
    "# df_unlabled = pd.concat([df_unlabled_1, df_unlabled_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = LabelMapHelper(\"/home/alex.li/git/JupiterCVML/europa/base/src/europa/dl/config/label_maps/four_class_train.csv\")\n",
    "lc = LabelConversion(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_thing(row):\n",
    "    label = np.load(os.path.join(data_dir, row.rectified_label_save_path))['left']\n",
    "    label = lc.convert_label_for_driveable_terrain(\n",
    "        label,\n",
    "        json.loads(row['label_map']))\n",
    "    if 'rear' in row['camera_location']:\n",
    "        has_vehicle = np.sum(label == helper.get_vehicle_label()) > 30\n",
    "        has_human = np.sum(label == helper.get_human_label()) > 30\n",
    "    else:\n",
    "        has_vehicle = np.sum(label == helper.get_vehicle_label()) > 100\n",
    "        has_human = np.sum(label == helper.get_human_label()) > 100\n",
    "    return [has_human, has_vehicle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['has_human', 'has_vehicle']] \n",
    "result= df.parallel_apply(has_thing, axis=1, result_type='expand')\n",
    "# df.loc[:, ['has_human', 'has_vehicle']] = df[['has_human']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(result[0])) # has human\n",
    "print(sum(result[1])) # has vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import logging\n",
    "from datetime import timedelta\n",
    "\n",
    "def get_runs(df: pd.DataFrame, trim: bool=True) -> List[pd.DataFrame]:\n",
    "    \"\"\"Split all consecutive videos of a dataframe \n",
    "    Returns the minimal list of dataframes such that no two dataframes have\n",
    "    images within 5 seconds of each other\n",
    "    \n",
    "    If trim is true, then we do not consider images with no ground truth stop\n",
    "    detected when selecting the start/end times for the videos, which may\n",
    "    result in some removed data.\n",
    "    \"\"\"\n",
    "    df['collected_on_dt'] = pd.to_datetime(df.collected_on)\n",
    "    df = df.sort_values('collected_on_dt')\n",
    "    if trim:\n",
    "        # merged_runs = df[result[1]]\n",
    "        merged_runs = df[result[1]]\n",
    "\n",
    "    else:\n",
    "        merged_runs = df\n",
    "    if len(merged_runs) == 0:\n",
    "        logging.error(\"Did not find any runs with any labeled stop class\")\n",
    "        return []\n",
    "    merged_runs = merged_runs.sort_values('collected_on_dt')\n",
    "\n",
    "    delta = timedelta(seconds=5)\n",
    "    start_t = merged_runs.iloc[0].collected_on_dt\n",
    "    runs = []\n",
    "    for i in range(1, len(merged_runs)):\n",
    "        end_t = merged_runs.iloc[i - 1].collected_on_dt\n",
    "        next_t = merged_runs.iloc[i].collected_on_dt\n",
    "        if next_t - end_t > delta or i == len(merged_runs) - 1:\n",
    "            if i == len(merged_runs) - 1:\n",
    "                next_t += timedelta(microseconds=1)\n",
    "            runs.append(df.loc[(start_t <= df['collected_on_dt']) & (df['collected_on_dt'] <= end_t)])\n",
    "            start_t = next_t\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_images(runs):\n",
    "    return sum(len(run) for run in runs)\n",
    "\n",
    "print(len(df))\n",
    "trimmed_runs = get_runs(df, True)\n",
    "print(len(trimmed_runs))\n",
    "print(get_n_images(trimmed_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_len_time = [(i, len(run), max(run['collected_on_dt']) - min(run['collected_on_dt'])) for i, run in enumerate(trimmed_runs)]\n",
    "trimmed_runs = [trimmed_runs[i] for i, _, time in run_len_time if (time > timedelta(seconds=5) and time < timedelta(minutes=5))]\n",
    "run_len_time = [(i, len(run), max(run['collected_on_dt']) - min(run['collected_on_dt'])) for i, run in enumerate(trimmed_runs)]\n",
    "run_len_time = sorted(run_len_time, key=lambda x : x[2])\n",
    "print(run_len_time)\n",
    "print(len(trimmed_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_times = np.load('/home/alex.li/logs/operation_time_for_2023_April_sequence_data.npz', allow_pickle=True)\n",
    "for k, v in op_times.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(op_times.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_times_dict = {\n",
    "    'daytime': op_times['Day'].tolist(),\n",
    "    'dawn_dusk': op_times['Dusk'].tolist(),\n",
    "    'nightime': op_times['Night'].tolist(),\n",
    "}\n",
    "for i, run in enumerate(trimmed_runs):\n",
    "    run_time = 'unknown'\n",
    "    times = set(run[run['operation_time'] != 'unknown']['operation_time'])\n",
    "    if len(times) != 1:\n",
    "        time = 'daytime'\n",
    "        print(i, times)\n",
    "    else:\n",
    "        assert len(times) == 1, len(times)\n",
    "        time = list(times)[0]\n",
    "    print(time)\n",
    "    print(min(run['collected_on_dt']))\n",
    "    run_times_dict[time].append(list(run['id']))\n",
    "for k, v in run_times_dict.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in run_times_dict.items():\n",
    "    run_times_dict[k] = np.array(v, dtype=object)\n",
    "for k, v in run_times_dict.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('/home/alex.li/logs/operation_time_for_2023_April_sequence_data_with_seq3.npz', **run_times_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_image_ids))\n",
    "imageids_to_dataset(all_image_ids,\n",
    "    dataset_name='vehicles_driving_through_dust_1_2',\n",
    "    dataset_description=f\"Sequences of vehicles driving through dust ({len(all_image_ids)} images)\",\n",
    "    dataset_kind=Dataset.KIND_ANNOTATION,\n",
    "    production_dataset=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set5_anno = pd.read_csv('/data/jupiter/datasets/suv_driving_through_rear_dust_anno/64cd53a3748e0a51e1a72774_master_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_ids.extend(list(set5_anno['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_image_ids))\n",
    "all_image_ids = list(set(all_image_ids))\n",
    "print(len(all_image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageids_to_dataset(all_image_ids,\n",
    "    dataset_name='vehicles_driving_through_dust_1_2_5',\n",
    "    dataset_description=f\"Sequences of vehicles driving through dust. ({len(all_image_ids)} images)\",\n",
    "    dataset_kind=Dataset.KIND_ANNOTATION,\n",
    "    production_dataset=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for dust threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_df = pd.read_csv('/data/jupiter/alex.li/results/vehicles_driving_in_dust/results_4class/dust_ratio.csv')\n",
    "dust_df = pd.merge(dust_df, df,on='id')\n",
    "dust_df['collected_on'] = pd.to_datetime(dust_df['collected_on'])\n",
    "dust_df = dust_df.sort_values('collected_on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seq(seq):\n",
    "    for camera_location in set(seq['camera_location']):\n",
    "        cam_seq = seq[seq['camera_location'] == camera_location]\n",
    "        plt.scatter(cam_seq['collected_on'], cam_seq['total_averaged_dust_conf'], s=1, label=camera_location)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seq(dust_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = datetime.datetime(2023, 4, 1)\n",
    "hi = datetime.datetime(2023, 4, 27, 13, 5)\n",
    "plot_seq(dust_df[(lo < dust_df['collected_on']) & (dust_df['collected_on'] < hi)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = datetime.datetime(2023, 5, 4, 1)\n",
    "hi = datetime.datetime(2023, 5, 4, 1, 20)\n",
    "plot_seq(dust_df[(lo < dust_df['collected_on']) & (dust_df['collected_on'] < hi)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = datetime.datetime(2023, 5, 4, 1, 55)\n",
    "hi = datetime.datetime(2023, 5,5)\n",
    "plot_seq(dust_df[(lo < dust_df['collected_on']) & (dust_df['collected_on'] < hi)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
