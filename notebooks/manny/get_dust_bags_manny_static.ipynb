{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "import datetime\n",
    "import io\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import imageio\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from brtdevkit.core.db.athena import AthenaClient\n",
    "from brtdevkit.data import Dataset\n",
    "from timezonefinder import TimezoneFinderL\n",
    "import pytz\n",
    "import cv2\n",
    "from brtdevkit.util.aws.s3 import S3\n",
    "client = S3()\n",
    "\n",
    "from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataset\n",
    "from aletheia_dataset_creator.config.dataset_config import LEFT_CAMERAS, ALL_CAMERA_PAIRS_LIST\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "athena = AthenaClient()\n",
    "s3 = boto3.resource('s3')\n",
    "tf = TimezoneFinderL()\n",
    "home = Path(os.path.expanduser('~'))\n",
    "data_path = Path(os.environ['OUTPUT_PATH']) / \"manny_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_drive_names = ['JUPD-061_2023-8-21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://bluerivertechnology.atlassian.net/wiki/spaces/JUPT/pages/3029106724/JQA-408+Post+Test+Report\n",
    "if os.path.exists(data_path / 'df_dusty_man.parquet'):\n",
    "    df_dusty = pd.read_parquet(data_path / 'df_dusty_man.parquet')\n",
    "else:\n",
    "    print(\"Cache miss\")\n",
    "    query = \"\"\"SELECT ij.id, hard_drive_name, robot_name, collected_on,\n",
    "        bag_name, operating_field_name, operation_time, latitude, longitude, geohash, camera_location, \n",
    "        bundle, group_id, s3_bucket, s3_key, special_notes\n",
    "    FROM image_jupiter AS ij\n",
    "    JOIN \"image_artifact_jupiter\" ON ij.\"id\" = \"image_artifact_jupiter\".\"image\"\n",
    "    WHERE \"hard_drive_name\" IN ('JUPD-061_2023-8-21') AND image_artifact_jupiter.kind = 'debayeredrgb' AND camera_location LIKE '%left'\n",
    "    \"\"\"\n",
    "    df_dusty: pd.DataFrame = athena.get_df(query) # type: ignore\n",
    "    df_dusty.to_parquet(data_path / 'df_dusty_man.parquet')\n",
    "df_dusty['image_id'] = df_dusty['id']\n",
    "df_dusty = df_dusty.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look through sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_id(df_row):\n",
    "    try:\n",
    "        return int(df_row['special_notes'].split(\" \")[-1])\n",
    "    except ValueError:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(df_row, collected_on: str, folder_name: str):\n",
    "    if len(df_row) == 0:\n",
    "        whiteFrame = 255 * np.ones((604, 964, 3), np.uint8)\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        whiteFrame = cv2.putText(whiteFrame, collected_on, (50, 400), font, 5, (0,0,0), 5)\n",
    "        return whiteFrame\n",
    "    elif isinstance(df_row, pd.DataFrame):\n",
    "        assert len(df_row) == 1\n",
    "        df_row = df_row.iloc[0]\n",
    "    file_name = Path(data_path) / folder_name / (str(df_row.image_id) + '.png')\n",
    "    if not os.path.exists(file_name):\n",
    "        client.download_file(df_row['s3_bucket'], df_row['s3_key'], file_name)\n",
    "    im = cv2.imread(str(file_name))\n",
    "    return im\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_frames(file_prefix: str, base_df: pd.DataFrame, folder_name: str):\n",
    "    \"\"\"\n",
    "    Given dictionary with image paths creates concatenated image and video and saves to output_dir.\n",
    "    \"\"\"\n",
    "    video_dir = Path(data_path) / 'videos' / str(file_prefix) \n",
    "    os.makedirs(video_dir, exist_ok=True)\n",
    "    video_name = video_dir / \"video.mp4\"\n",
    "    if os.path.exists(video_name):\n",
    "        return\n",
    "    writer = imageio.get_writer(video_name, fps=1)\n",
    "    k_df = base_df.sort_values('collected_on')\n",
    "    k_groups = base_df.groupby('group_id').groups\n",
    "    seen = set()\n",
    "    print(len(k_df))\n",
    "    for row in tqdm(k_df.iterrows()):\n",
    "        gid = row[1]['group_id']\n",
    "        if gid in seen:\n",
    "            continue\n",
    "        seen.add(gid)\n",
    "        values = k_groups[gid]\n",
    "        group = k_df.loc[values]\n",
    "        collected_on_str = str(group.iloc[0].collected_on)[11:19]\n",
    "        # try:\n",
    "        # concatenate image Horizontally\n",
    "        front_pod = np.concatenate(\n",
    "            (\n",
    "                get_image(group[group['camera_location'] == 'front-left-left'], collected_on_str, folder_name),\n",
    "                get_image(group[group['camera_location'] == 'front-center-left'], collected_on_str, folder_name),\n",
    "                get_image(group[group['camera_location'] == 'front-right-left'], collected_on_str, folder_name),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        rear_pod = np.concatenate(\n",
    "            (\n",
    "                get_image(group[group['camera_location'] == 'side-left-left'], collected_on_str, folder_name),\n",
    "                get_image(group[group['camera_location'] == 'rear-left'], collected_on_str, folder_name),\n",
    "                get_image(group[group['camera_location'] == 'side-right-left'], collected_on_str, folder_name),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        # concatenate image vertically\n",
    "        all_cameras = np.concatenate((front_pod, rear_pod), axis=0)[::4, ::4, ::-1]\n",
    "        # save concatenated image file\n",
    "        full_img_name = f\"{collected_on_str}.png\"\n",
    "        file_path = os.path.join(video_dir, full_img_name)\n",
    "        plt.imsave(file_path, all_cameras)\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "        writer.append_data(imageio.imread(file_path))\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Skipping frame. Exception occurred: {e}\")\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look through dusty human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(df_dusty['special_notes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import pretty\n",
    "pretty.install()\n",
    "df_dusty = df_dusty[df_dusty['special_notes'].notna()]\n",
    "# https://bluerivertechnology.atlassian.net/wiki/spaces/JUPT/pages/3029106724/JQA-408+Post+Test+Report\n",
    "valid_notes = [\n",
    "    'dust-Night-pos-1',\n",
    "    'dust-Night-pos-2',\n",
    "    'dust-Night-pos-3',\n",
    "    'dust-Night-pos-4',\n",
    "    'dust-Night-pos-5',\n",
    "    'dust-Night-pos-6',\n",
    "    'dust-Night-pos-7',\n",
    "    'dust-Night-pos-8',\n",
    "    'dust-Night-pos-9',\n",
    "    'dust-Night-pos-10',\n",
    "    'dust-dusk-pos1',\n",
    "    'dust-dusk-pos2',\n",
    "    'dust-dusk-pos3',\n",
    "    'dust-dusk-pos4',\n",
    "    'dust-dusk-pos5',\n",
    "    'dust_pos6',\n",
    "    'dust_pos6-atmp-2',\n",
    "    'dust_pos7',\n",
    "    'dust_pos8',\n",
    "    'dust_pos9',\n",
    "    'dust_pos9-atmp-2',\n",
    "    'dust_pos10',\n",
    "    'dust_pos10-atmp-2'\n",
    "]\n",
    "print(len(valid_notes))\n",
    "df_dusty = df_dusty[df_dusty['special_notes'].isin(valid_notes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dusty = df_dusty.sort_values('collected_on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_dusty.sort_values('collected_on')))\n",
    "print(set(df_dusty['camera_location']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second(pddatetime):\n",
    "    return pddatetime.strftime('%Y/%m/%d %H:%M:%S')\n",
    "df_dusty['collected_second'] = df_dusty['collected_on'].apply(get_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_groups = df_dusty.groupby(['collected_second', 'camera_location']).first()['group_id']\n",
    "df_dusty_subset = df_dusty[df_dusty['group_id'].isin(ok_groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dusty_subset.groupby(['collected_second', 'camera_location']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_dusty))\n",
    "print(len(df_dusty_subset))\n",
    "df_dusty = df_dusty_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in valid_notes:\n",
    "    folder_name = Path(data_path) / 'humans_in_dust' / key\n",
    "    if os.path.exists(data_path / 'videos' / key / 'video.mp4'):\n",
    "        continue\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    base_df = df_dusty[df_dusty['special_notes'] == key]\n",
    "    for id, df_row in tqdm(base_df.iterrows(), total=len(base_df)):\n",
    "        file_name = folder_name / str(id + '.png')\n",
    "        if not os.path.exists(file_name):\n",
    "            client.download_file(df_row['s3_bucket'], df_row['s3_key'], file_name)\n",
    "    create_video_frames(key, base_df=base_df, folder_name=f'humans_in_dust/{key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_notes = [\n",
    "    'dust-Night-pos-1',\n",
    "    'dust-Night-pos-2',\n",
    "    'dust-Night-pos-3',\n",
    "    'dust-Night-pos-4',\n",
    "    'dust-Night-pos-5',\n",
    "    'dust-Night-pos-6',\n",
    "    'dust-Night-pos-7',\n",
    "    'dust-Night-pos-8',\n",
    "    'dust-Night-pos-9',\n",
    "    'dust-Night-pos-10',\n",
    "    'dust-dusk-pos1',\n",
    "    'dust-dusk-pos2',\n",
    "    'dust-dusk-pos3',\n",
    "    'dust-dusk-pos4',\n",
    "    'dust-dusk-pos5',\n",
    "    'dust_pos6',\n",
    "    'dust_pos6-atmp-2',\n",
    "    'dust_pos7',\n",
    "    'dust_pos8',\n",
    "    'dust_pos9',\n",
    "    'dust_pos9-atmp-2',\n",
    "    'dust_pos10',\n",
    "    'dust_pos10-atmp-2'\n",
    "]\n",
    "\n",
    "only_human_images = {\n",
    "    'dust-Night-pos-1': {\n",
    "        'front-left-left': [('05:02:00', '05:02:30'), ('05:06:00', '05:07:00'), ('05:07:20', '05:07:30')],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [('05:02:00', '05:02:30')],\n",
    "        'side-right-left': [],\n",
    "        'rear-left': []\n",
    "    },\n",
    "    'dust-Night-pos-2': {\n",
    "        'front-left-left': [('05:07:30', '05:08:30')],\n",
    "        'front-center-left': [('05:11:30', '05:11:40'),('05:12:40', '05:13:10') ],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-Night-pos-3': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [('05:13:15', '05:13:40'), ('05:17:00', '05:18:40')],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-Night-pos-4': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [('05:18:00', '05:19:05'), ('05:22:30', '05:22:50')],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-Night-pos-5': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [('05:23:45', '05:27:00')],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [('05:29:10', '05:31:10')],\n",
    "        'rear-left': [],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-Night-pos-6': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [('05:31:11', '05:32:30'), ('05:33:05', '05:34:50')],\n",
    "        'rear-left': [('05:33:05', '05:34:50')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-Night-pos-7': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [('05:49:32', '05:51:30')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-Night-pos-8': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [('05:51:30', '05:51:40'), ('05:53:10', '05:54:20'), ('05:59:00', '05:59:59')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-Night-pos-9': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [('05:59:20', '06:03:00'), ('06:04:50', '06:06:35')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-Night-pos-10': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [('06:07:50', '06:09:40')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-dusk-pos1': {\n",
    "        'front-left-left': [('02:09:00','02:17:30')],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [('02:09:00','02:12:30')],\n",
    "        'rear-left': [],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-dusk-pos2': {\n",
    "        'front-left-left': [('02:17:28','02:20:30')],\n",
    "        'front-center-left': [('02:20:21', '02:23:45')],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-dusk-pos3': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [('02:23:40', '02:26:00'), ('02:26:00', '02:35:00')],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-dusk-pos4': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [('02:34:00', '02:40:45')],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust-dusk-pos5': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [('02:40:45', '02:42:25')],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust_pos6': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [('22:57:03', '22:58:59')],\n",
    "        'rear-left': [],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust_pos6-atmp-2': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [('23:04:00', '23:06:00')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust_pos7': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [('23:18:02', '23:20:00')],\n",
    "        'rear-left': [('23:18:02','23:27:00')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust_pos8': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [('23:27:00', '23:31:00')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust_pos9': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [('23:31:00', '23:34:43')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust_pos9-atmp-2': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [('23:34:43', '23:44:00')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust_pos10': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [('23:44:00', '23:59:59')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "    'dust_pos10-atmp-2': {\n",
    "        'front-left-left': [],\n",
    "        'front-center-left': [],\n",
    "        'front-right-left': [],\n",
    "        'side-left-left': [],\n",
    "        'rear-left': [('23:58:00', '23:59:59')],\n",
    "        'side-right-left': [],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def filter_movie(movie, start_t, end_t):\n",
    "    timestamp = movie.iloc[0]['collected_on']\n",
    "    s_hour, s_minute, s_second = map(int, start_t.split(':'))\n",
    "    e_hour, e_minute, e_second = map(int, end_t.split(':'))\n",
    "    y, m, d = timestamp.year, timestamp.month, timestamp.day\n",
    "    tzinfo = movie['collected_on'].iloc[0].tzinfo\n",
    "    start_dt = datetime(y, m, d, s_hour, s_minute, s_second, tzinfo=tzinfo)\n",
    "    end_dt = datetime(y, m, d, e_hour, e_minute, e_second, tzinfo=tzinfo)\n",
    "    return movie[(start_dt < movie['collected_on']) & (movie['collected_on'] < end_dt)]\n",
    "\n",
    "cleaned_human_runs = []\n",
    "for notes in valid_notes:\n",
    "    for camera_location in ['front-left-left', 'front-center-left', 'front-right-left', 'side-left-left', 'rear-left', 'side-right-left']:\n",
    "        times = only_human_images[notes][camera_location]\n",
    "        for start_t, end_t in times:\n",
    "            sequence = df_dusty.loc[(df_dusty['special_notes'] == notes) & (df_dusty['camera_location'] == camera_location)]\n",
    "            filtered = filter_movie(sequence, start_t, end_t)\n",
    "            # print(len(filtered))\n",
    "            if not len(filtered):\n",
    "                print(notes, start_t, end_t) # oops\n",
    "            cleaned_human_runs.append(filtered)\n",
    "human_dusty_df = pd.concat(cleaned_human_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.create(\n",
    "    name='mannequin_in_dust_night_dawn_10pos',\n",
    "    description=\"sequences of a mannequin with dust blowing around it from 10 positions at night and dusk. All images contain a mannequin. Collected Aug 22 2023. Left cameras only (7375 images)\",\n",
    "    kind=Dataset.KIND_IMAGE,\n",
    "    image_ids=list(human_dusty_df['image_id']),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create annotated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aletheia_ds = Dataset.retrieve(name='mannequin_in_dust')\n",
    "aletheia_df_1 = aletheia_ds.to_dataframe()\n",
    "print(aletheia_df_1.shape)\n",
    "# retrieve dataset from aletheia\n",
    "aletheia_ds = Dataset.retrieve(name='mannequin_in_dust_night_dawn_10pos')\n",
    "aletheia_df_2 = aletheia_ds.to_dataframe()\n",
    "print(aletheia_df_2.shape)\n",
    "aletheia_df = pd.concat([aletheia_df_1, aletheia_df_2])\n",
    "print(aletheia_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aletheia_df['image_id'] = aletheia_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_slow(from_df, name, description, kind='image') -> None:\n",
    "    imids = list(from_df['image_id'])\n",
    "    desc = f\"{description} ({len(from_df['image_id'])} images)\"\n",
    "    print(len(imids))\n",
    "    from_df.to_parquet(data_path / '{name}.parquet', index=False)\n",
    "    imageids_to_dataset(imids, name, dataset_description=desc, dataset_kind=kind, production_dataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dataset_slow(from_df=aletheia_df, \n",
    "    name='mannequin_in_dust_v0',\n",
    "    description=\"A mannequin with dust billowing around. All images contain a mannequin.\",\n",
    "    kind=Dataset.KIND_ANNOTATION,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
