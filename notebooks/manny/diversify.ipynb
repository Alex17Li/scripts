{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alexli/miniconda3/envs/cvml/lib/python3.10/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from brtdevkit.data import Dataset\n",
    "from email.mime import image\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset as torchDataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from pathlib import Path \n",
    "from sklearn.decomposition import PCA\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aletheia_ds = Dataset.retrieve(name='mannequin_in_dust_v0')\n",
    "aletheia_df = aletheia_ds.to_dataframe()\n",
    "dataset_save_dir =os.environ['DATASET_PATH'] + \"/mannequin_in_dust\"\n",
    "if not os.path.exists(dataset_save_dir):\n",
    "    os.makedirs(name=dataset_save_dir)\n",
    "    aletheia_ds.download(dataset_save_dir)\n",
    "# df = pd.merge(pd.read_csv(filepath_or_buffer=\"/home/alexli/logs/summary_manny_0.csv\"), aletheia_df, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A mannequin with dust billowing around. All images contain a mannequin. (9025 images)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aletheia_ds['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# types: for 4-class, 1 is human, 2 is vehicle\n",
    "def n_pixels_in_grid(details, types = [1]):\n",
    "    total_size = 0\n",
    "    for k, v in ast.literal_eval(details).items():\n",
    "        if k in types:\n",
    "            total_size += sum(vi['object_size'] for vi in v)\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby('group_id')\n",
    "all_sizes = []\n",
    "ok_ids = []\n",
    "for group_id, group_df in groups:\n",
    "    best_ind = 0\n",
    "    best = n_pixels_in_grid(df['label_grid_details'].iloc[best_ind])\n",
    "    for i in range(1, len(group_df)):\n",
    "        cur = n_pixels_in_grid(details=group_df['label_grid_details'].iloc[i])\n",
    "        if cur > best:\n",
    "            best = cur\n",
    "    ok_ids.append(group_df.iloc[best_ind]['id'])\n",
    "    all_sizes.append(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['id'].isin(ok_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasetpreparer(torchDataset):    \n",
    "        def __init__(self, data, preprocess=None, transform=None, device=\"cuda\"):\n",
    "            self.data = data\n",
    "            self.transform =  transform \n",
    "            self.preprocess = preprocess\n",
    "            self.device = device \n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_path = self.data.loc[idx, 'image_path']\n",
    "            img_pil = self.transform(Image.fromarray(imageio.imread(img_path)))\n",
    "            # Download and open the image        \n",
    "            img_pil = self.preprocess(img_pil).to(self.device)\n",
    "            return img_pil, img_path\n",
    "\n",
    "class ImageSimilarity: \n",
    "    def __init__(self, images_full_path, data_base_path, dataset_name='image_list', overwrite=False):\n",
    "        self.data_base_path = data_base_path\n",
    "        os.makedirs(self.data_base_path, exist_ok=True)\n",
    "        self.images_base_path = data_base_path + \"/images\"\n",
    "        self.images_full_path = images_full_path\n",
    "        \n",
    "        self.image_path_df = None \n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((224,224))])\n",
    "        \n",
    "        self.inference_set = None \n",
    "        self.embeddings_np = None\n",
    "        self.image_paths = None \n",
    "        self.image_paths_df = None\n",
    "        self.embeddings_save_name = f\"{dataset_name}_embeddings\"\n",
    "        self.embeddings_image_paths = Path(self.data_base_path) / f\"{dataset_name}_embeddings_image_paths.csv\"\n",
    "        self.embeddings_save_loc = Path(self.data_base_path) / self.embeddings_save_name\n",
    "        self.overwrite = overwrite \n",
    "        self.model = None \n",
    "        self.preprocessor = None \n",
    "        self.sorted_scores = None \n",
    "        self.sorted_scores_save_loc = data_base_path \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.load_model()\n",
    "        \n",
    "    def prepare_images_path_df(self): \n",
    "        self.image_path_df = pd.DataFrame(data=self.images_full_path, columns=['image_path'])\n",
    "        return self.image_path_df\n",
    "    \n",
    "    def prepare_dataloader(self): \n",
    "        self.inference_set = Datasetpreparer(data=self.image_path_df, preprocess=self.preprocessor, transform=self.transform, device=self.device)\n",
    "        inference_loader = DataLoader(self.inference_set, batch_size=64, shuffle=False, num_workers=0, drop_last=True)\n",
    "        self.total = len(self.image_path_df) / 64\n",
    "        return inference_loader\n",
    " \n",
    "    def load_model(self): \n",
    "        self.model, self.preprocessor = clip.load(\"ViT-B/32\", device=self.device)\n",
    "        return self.model, self.preprocessor\n",
    "\n",
    "    def build_embeddings(self): \n",
    "        outputs = []\n",
    "        image_paths = []\n",
    "        if (os.path.isfile(self.embeddings_save_loc)==True) or (self.overwrite==False): \n",
    "            self.embeddings_np, self.image_paths = self.load_embeddings()\n",
    "            return self.embeddings_np, self.image_paths \n",
    "        else:\n",
    "            inference_loader = self.prepare_dataloader()\n",
    "            for idx, batch in tqdm(enumerate(inference_loader), total=self.total): \n",
    "                batch, paths = batch[0], batch[1]\n",
    "                with torch.no_grad():\n",
    "                        batch = batch.to(self.device)\n",
    "                        image_features = self.model.encode_image(batch)\n",
    "                        outputs.append(image_features)  \n",
    "                        image_paths.extend(paths)\n",
    "            outputs = torch.cat(outputs, dim=0)\n",
    "            self.image_paths = image_paths \n",
    "            self.embeddings_np = outputs.detach().cpu().numpy()\n",
    "            return self.embeddings_np, self.image_paths\n",
    "            \n",
    "    def save_embeddings(self): \n",
    "            np.savez(self.embeddings_save_loc, self.embeddings_np) \n",
    "            image_paths_df = pd.DataFrame(data=self.image_paths, columns=['image_path'])\n",
    "            image_paths_df.to_csv(self.embeddings_image_paths, index=False)\n",
    "            return None \n",
    "        \n",
    "    def load_embeddings(self): \n",
    "        embeddings_save_loc = str(self.embeddings_save_loc) +\".npz\"\n",
    "        embeddings = np.load(embeddings_save_loc)\n",
    "        self.embeddings_np = embeddings[embeddings.files[0]]       \n",
    "        self.image_paths_df= pd.read_csv(self.embeddings_image_paths )\n",
    "        return self.embeddings_np, self.image_paths_df \n",
    "\n",
    "    def get_image_embedding(self, image_path): \n",
    "        transformed_image = self.transform(Image.open(image_path))\n",
    "        img = self.preprocessor(transformed_image).unsqueeze(0).to(self.device)\n",
    "        embedding = self.model.encode_image(img)\n",
    "        embeddings_np = embedding.detach().cpu().numpy()\n",
    "        return embeddings_np\n",
    "    \n",
    "    def get_similar_images(self, image_path, calcuate_embeddings=False, images_base_path=None): \n",
    "        if images_base_path==None:\n",
    "            images_base_path = self.images_base_path\n",
    "        full_image_path = os.path.join(images_base_path, image_path)\n",
    "        embeddings_np, image_paths_df = self.load_embeddings()\n",
    "        image_paths = image_paths_df['image_path'].tolist()\n",
    "        if calcuate_embeddings==True:\n",
    "            reference_embedding = self.get_image_embedding(full_image_path)\n",
    "        else :\n",
    "            embedding_index = image_paths_df[image_paths_df['image_path'] == full_image_path].index[0]\n",
    "            reference_embedding = embeddings_np[embedding_index, :]\n",
    "        \n",
    "        similarity_score = np.dot(reference_embedding, embeddings_np.T)/(np.linalg.norm(reference_embedding)*np.linalg.norm( embeddings_np, axis=1))\n",
    "        score_df = pd.DataFrame(data=list(similarity_score.T), columns=['similarity_score'])\n",
    "        score_df['image_path'] = image_paths \n",
    "        self.sorted_scores = score_df.sort_values(by='similarity_score', ascending=False)\n",
    "        image_name = image_path.split(\"/\")[-1].replace(\".png\",\"\")\n",
    "        save_loc_sorted_scores = Path(self.sorted_scores_save_loc) / f\"{image_name}.csv\"\n",
    "        self.sorted_scores.to_csv(save_loc_sorted_scores, index=False)\n",
    "        return self.sorted_scores\n",
    "    \n",
    "    def similar_images_with_text(self, text_prompt):\n",
    "        \n",
    "        embeddings_np, image_paths_df = self.load_embeddings()\n",
    "        image_paths = image_paths_df['image_path'].tolist()\n",
    "        text = clip.tokenize(text_prompt).to(self.device)\n",
    "        text_features = self.model.encode_text(text)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features.detach().cpu().numpy()\n",
    "        reference_embedding = text_features\n",
    "            \n",
    "        similarity_score = np.dot(reference_embedding, embeddings_np.T)/(np.linalg.norm(reference_embedding)*np.linalg.norm( embeddings_np, axis=1))\n",
    "        score_df = pd.DataFrame(data=list(similarity_score.T), columns=['similarity_score'])\n",
    "        score_df['image_path'] = image_paths \n",
    "        self.sorted_scores = score_df.sort_values(by='similarity_score', ascending=False)\n",
    "        image_name = text_prompt.replace(\" \",\"_\")\n",
    "        save_loc_sorted_scores = Path(self.sorted_scores_save_loc) / f\"{image_name}.csv\"\n",
    "        self.sorted_scores.to_csv(save_loc_sorted_scores, index=False)\n",
    "        return self.sorted_scores\n",
    "        \n",
    "        \n",
    "    def plot_image_grid(self, image_paths_df, tail=0  ,nrows=5, ncols=2):\n",
    "        \n",
    "        # Assume image_paths is your list of image file paths\n",
    "        if tail > 0:\n",
    "            image_paths_df = image_paths_df.tail(tail)\n",
    "        image_paths = image_paths_df['image_path'].tolist()\n",
    "        n_rows = min(nrows, int(image_paths_df.shape[0] // 2 ))\n",
    "        fig, axes = plt.subplots(n_rows, ncols, figsize=(10, nrows*5))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            if i < len(image_paths)-1:\n",
    "                image_path = image_paths[i]\n",
    "                title = image_path.split(\"/\")[-1]\n",
    "                img = Image.open(image_path)\n",
    "                ax.imshow(img)\n",
    "                ax.set_title(f'{title}  indx: {i}', fontsize=6)\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def extract_embeddings(self): \n",
    "        self.prepare_images_path_df()\n",
    "        self.prepare_dataloader()\n",
    "        self.overwrite = True\n",
    "        self.build_embeddings()\n",
    "        self.save_embeddings()\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(save_dir):\n",
    "    save_dir = Path(save_dir)\n",
    "    dirs = [save_dir / d for d in df[df['label_human']].id]\n",
    "    image_paths = itertools.chain(*[[str(dir / p) for p in os.listdir(dir) if 'debayeredrgb' in p] for dir in dirs])\n",
    "    return image_paths\n",
    "images_full_path = list(get_images(dataset_save_dir + '/images'))\n",
    "print(len(images_full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = ImageSimilarity(images_full_path=images_full_path, data_base_path=dataset_save_dir, dataset_name=\"mannequin_in_dust\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.extract_embeddings()\n",
    "embeddings_np, paths_df = sim.load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_images_final = 2000\n",
    "kmeans = KMeans(n_clusters=n_images_final, random_state=0, n_init=\"auto\")\n",
    "kmeans.fit(embeddings_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_paths = [None for _ in range(n_images_final)]\n",
    "\n",
    "for i, l in enumerate(kmeans.labels_):\n",
    "    if final_paths[l] == None:\n",
    "        final_paths[l] = paths_df.image_path.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imids = [p.split('_')[-1][:-4] for p in final_paths]\n",
    "fin_df = df[df.id.isin(imids)]\n",
    "print(len(fin_df))\n",
    "print(len(imids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataset\n",
    "\n",
    "desc = f\"Mannequins standing in dust, diversified. ({len(imids)} images)\"\n",
    "imageids_to_dataset(image_ids=imids, dataset_name=\"mannequin_in_dust_v0_diverse\", dataset_description=desc, dataset_kind=Dataset.KIND_ANNOTATION, production_dataset=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
