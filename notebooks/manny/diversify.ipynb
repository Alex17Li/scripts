{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from brtdevkit.data import Dataset\n",
    "from email.mime import image\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset as torchDataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from pathlib import Path \n",
    "from sklearn.decomposition import PCA\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# types: for 4-class, 1 is human, 2 is vehicle\n",
    "def n_pixels_in_grid(details, types = [1]):\n",
    "    total_size = 0\n",
    "    for k, v in ast.literal_eval(details).items():\n",
    "        if k in types:\n",
    "            total_size += sum(vi['object_size'] for vi in v)\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups = df.groupby('group_id')\n",
    "# all_sizes = []\n",
    "# ok_ids = []\n",
    "# for group_id, group_df in groups:\n",
    "#     best_ind = 0\n",
    "#     best = n_pixels_in_grid(df['label_grid_details'].iloc[best_ind])\n",
    "#     for i in range(1, len(group_df)):\n",
    "#         cur = n_pixels_in_grid(details=group_df['label_grid_details'].iloc[i])\n",
    "#         if cur > best:\n",
    "#             best = cur\n",
    "#     ok_ids.append(group_df.iloc[best_ind]['id'])\n",
    "#     all_sizes.append(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasetpreparer(torchDataset):    \n",
    "        def __init__(self, data, preprocess=None, transform=None, device=\"cuda\"):\n",
    "            self.data = data\n",
    "            self.transform =  transform \n",
    "            self.preprocess = preprocess\n",
    "            self.device = device \n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_path = self.data.loc[idx, 'image_path']\n",
    "            img_pil = self.transform(Image.fromarray(imageio.imread(img_path)))\n",
    "            # Download and open the image        \n",
    "            img_pil = self.preprocess(img_pil).to(self.device)\n",
    "            return img_pil, img_path\n",
    "\n",
    "class ImageSimilarity: \n",
    "    def __init__(self, images_full_path, data_base_path, dataset_name='image_list', overwrite=False):\n",
    "        self.data_base_path = data_base_path\n",
    "        os.makedirs(self.data_base_path, exist_ok=True)\n",
    "        self.images_base_path = data_base_path + \"/images\"\n",
    "        self.images_full_path = images_full_path\n",
    "        \n",
    "        self.image_path_df = None \n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((224,224))])\n",
    "        \n",
    "        self.inference_set = None \n",
    "        self.embeddings_np = None\n",
    "        self.image_paths = None \n",
    "        self.image_paths_df = None\n",
    "        self.embeddings_save_name = f\"{dataset_name}_embeddings\"\n",
    "        self.embeddings_image_paths = Path(self.data_base_path) / f\"{dataset_name}_embeddings_image_paths.csv\"\n",
    "        self.embeddings_save_loc = Path(self.data_base_path) / self.embeddings_save_name\n",
    "        self.overwrite = overwrite \n",
    "        self.model = None \n",
    "        self.preprocessor = None \n",
    "        self.sorted_scores = None \n",
    "        self.sorted_scores_save_loc = data_base_path \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.load_model()\n",
    "        \n",
    "    def prepare_images_path_df(self): \n",
    "        self.image_path_df = pd.DataFrame(data=self.images_full_path, columns=['image_path'])\n",
    "        return self.image_path_df\n",
    "    \n",
    "    def prepare_dataloader(self): \n",
    "        self.inference_set = Datasetpreparer(data=self.image_path_df, preprocess=self.preprocessor, transform=self.transform, device=self.device)\n",
    "        inference_loader = DataLoader(self.inference_set, batch_size=64, shuffle=False, num_workers=0, drop_last=True)\n",
    "        self.total = len(self.image_path_df) / 64\n",
    "        return inference_loader\n",
    " \n",
    "    def load_model(self): \n",
    "        self.model, self.preprocessor = clip.load(\"ViT-B/32\", device=self.device)\n",
    "        return self.model, self.preprocessor\n",
    "\n",
    "    def build_embeddings(self): \n",
    "        outputs = []\n",
    "        image_paths = []\n",
    "        if (os.path.isfile(self.embeddings_save_loc)==True) or (self.overwrite==False): \n",
    "            self.embeddings_np, self.image_paths = self.load_embeddings()\n",
    "            return self.embeddings_np, self.image_paths \n",
    "        else:\n",
    "            inference_loader = self.prepare_dataloader()\n",
    "            for idx, batch in tqdm(enumerate(inference_loader), total=self.total): \n",
    "                batch, paths = batch[0], batch[1]\n",
    "                with torch.no_grad():\n",
    "                        batch = batch.to(self.device)\n",
    "                        image_features = self.model.encode_image(batch)\n",
    "                        outputs.append(image_features)  \n",
    "                        image_paths.extend(paths)\n",
    "            outputs = torch.cat(outputs, dim=0)\n",
    "            self.image_paths = image_paths \n",
    "            self.embeddings_np = outputs.detach().cpu().numpy()\n",
    "            return self.embeddings_np, self.image_paths\n",
    "            \n",
    "    def save_embeddings(self): \n",
    "            np.savez(self.embeddings_save_loc, self.embeddings_np) \n",
    "            image_paths_df = pd.DataFrame(data=self.image_paths, columns=['image_path'])\n",
    "            image_paths_df.to_csv(self.embeddings_image_paths, index=False)\n",
    "            return None \n",
    "        \n",
    "    def load_embeddings(self): \n",
    "        embeddings_save_loc = str(self.embeddings_save_loc) +\".npz\"\n",
    "        embeddings = np.load(embeddings_save_loc)\n",
    "        self.embeddings_np = embeddings[embeddings.files[0]]       \n",
    "        self.image_paths_df= pd.read_csv(self.embeddings_image_paths )\n",
    "        return self.embeddings_np, self.image_paths_df \n",
    "\n",
    "    def get_image_embedding(self, image_path): \n",
    "        transformed_image = self.transform(Image.open(image_path))\n",
    "        img = self.preprocessor(transformed_image).unsqueeze(0).to(self.device)\n",
    "        embedding = self.model.encode_image(img)\n",
    "        embeddings_np = embedding.detach().cpu().numpy()\n",
    "        return embeddings_np\n",
    "    \n",
    "    def get_similar_images(self, image_path, calcuate_embeddings=False, images_base_path=None): \n",
    "        if images_base_path==None:\n",
    "            images_base_path = self.images_base_path\n",
    "        full_image_path = os.path.join(images_base_path, image_path)\n",
    "        embeddings_np, image_paths_df = self.load_embeddings()\n",
    "        image_paths = image_paths_df['image_path'].tolist()\n",
    "        if calcuate_embeddings==True:\n",
    "            reference_embedding = self.get_image_embedding(full_image_path)\n",
    "        else :\n",
    "            embedding_index = image_paths_df[image_paths_df['image_path'] == full_image_path].index[0]\n",
    "            reference_embedding = embeddings_np[embedding_index, :]\n",
    "        \n",
    "        similarity_score = np.dot(reference_embedding, embeddings_np.T)/(np.linalg.norm(reference_embedding)*np.linalg.norm( embeddings_np, axis=1))\n",
    "        score_df = pd.DataFrame(data=list(similarity_score.T), columns=['similarity_score'])\n",
    "        score_df['image_path'] = image_paths \n",
    "        self.sorted_scores = score_df.sort_values(by='similarity_score', ascending=False)\n",
    "        image_name = image_path.split(\"/\")[-1].replace(\".png\",\"\")\n",
    "        save_loc_sorted_scores = Path(self.sorted_scores_save_loc) / f\"{image_name}.csv\"\n",
    "        self.sorted_scores.to_csv(save_loc_sorted_scores, index=False)\n",
    "        return self.sorted_scores\n",
    "    \n",
    "    def similar_images_with_text(self, text_prompt):\n",
    "        \n",
    "        embeddings_np, image_paths_df = self.load_embeddings()\n",
    "        image_paths = image_paths_df['image_path'].tolist()\n",
    "        text = clip.tokenize(text_prompt).to(self.device)\n",
    "        text_features = self.model.encode_text(text)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features.detach().cpu().numpy()\n",
    "        reference_embedding = text_features\n",
    "            \n",
    "        similarity_score = np.dot(reference_embedding, embeddings_np.T)/(np.linalg.norm(reference_embedding)*np.linalg.norm( embeddings_np, axis=1))\n",
    "        score_df = pd.DataFrame(data=list(similarity_score.T), columns=['similarity_score'])\n",
    "        score_df['image_path'] = image_paths \n",
    "        self.sorted_scores = score_df.sort_values(by='similarity_score', ascending=False)\n",
    "        image_name = text_prompt.replace(\" \",\"_\")\n",
    "        save_loc_sorted_scores = Path(self.sorted_scores_save_loc) / f\"{image_name}.csv\"\n",
    "        self.sorted_scores.to_csv(save_loc_sorted_scores, index=False)\n",
    "        return self.sorted_scores\n",
    "        \n",
    "        \n",
    "    def plot_image_grid(self, image_paths_df, tail=0  ,nrows=5, ncols=2):\n",
    "        \n",
    "        # Assume image_paths is your list of image file paths\n",
    "        if tail > 0:\n",
    "            image_paths_df = image_paths_df.tail(tail)\n",
    "        image_paths = image_paths_df['image_path'].tolist()\n",
    "        n_rows = min(nrows, int(image_paths_df.shape[0] // 2 ))\n",
    "        fig, axes = plt.subplots(n_rows, ncols, figsize=(10, nrows*5))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            if i < len(image_paths)-1:\n",
    "                image_path = image_paths[i]\n",
    "                title = image_path.split(\"/\")[-1]\n",
    "                img = Image.open(image_path)\n",
    "                ax.imshow(img)\n",
    "                ax.set_title(f'{title}  indx: {i}', fontsize=6)\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def extract_embeddings(self): \n",
    "        self.prepare_images_path_df()\n",
    "        self.prepare_dataloader()\n",
    "        self.overwrite = True\n",
    "        self.build_embeddings()\n",
    "        self.save_embeddings()\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnauthorizedSSOTokenError",
     "evalue": "The SSO session associated with this profile has expired or is otherwise invalid. To refresh this SSO session run aws sso login with the corresponding profile.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnauthorizedException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/credentials.py:2124\u001b[0m, in \u001b[0;36mSSOCredentialFetcher._get_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2123\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2124\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mget_role_credentials(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2125\u001b[0m \u001b[39mexcept\u001b[39;00m client\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mUnauthorizedException:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/client.py:535\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/client.py:980\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    979\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 980\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mUnauthorizedException\u001b[0m: An error occurred (UnauthorizedException) when calling the GetRoleCredentials operation: Session token not found or invalid",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnauthorizedSSOTokenError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dsetname \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmannequin_in_dust_v0_diverse_1500\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m aletheia_ds \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mretrieve(name\u001b[39m=\u001b[39mdsetname)\n\u001b[0;32m----> 3\u001b[0m aletheia_df \u001b[39m=\u001b[39m aletheia_ds\u001b[39m.\u001b[39;49mto_dataframe()\n\u001b[1;32m      4\u001b[0m dataset_save_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mDATASET_PATH\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m dsetname\n\u001b[1;32m      5\u001b[0m \u001b[39m# if not os.path.exists(dataset_save_dir):\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m#     os.makedirs(name=dataset_save_dir)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m#     aletheia_ds.download(dataset_save_dir)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/brtdevkit/data/core/dataset.py:502\u001b[0m, in \u001b[0;36mDataset.to_dataframe\u001b[0;34m(self, cache, artifact_query)\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mInvalidRequestError(\n\u001b[1;32m    497\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m not ready to be converted to Dataframe yet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mplease try again after sometime | current state: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    500\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    501\u001b[0m     \u001b[39m# download metadata json and load it into dataframe\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve_data()])\n\u001b[1;32m    503\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_from_series_to_dataframe(data, artifact_query)\n\u001b[1;32m    504\u001b[0m     \u001b[39mif\u001b[39;00m cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/brtdevkit/data/core/dataset.py:117\u001b[0m, in \u001b[0;36mDataset.retrieve_data\u001b[0;34m(self, chunksize)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m# download metadata json and load it into dataframe\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m# TODO (erin): test performance when using an in memory buffer\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mwith\u001b[39;00m tempfile\u001b[39m.\u001b[39mNamedTemporaryFile() \u001b[39mas\u001b[39;00m tmp_metadata:\n\u001b[0;32m--> 117\u001b[0m     s3_client\u001b[39m.\u001b[39;49mdownload_file(\n\u001b[1;32m    118\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata_s3_bucket,\n\u001b[1;32m    119\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata_s3_key,\n\u001b[1;32m    120\u001b[0m         tmp_metadata\u001b[39m.\u001b[39;49mname\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m pd\u001b[39m.\u001b[39mread_json(\n\u001b[1;32m    123\u001b[0m             tmp_metadata\u001b[39m.\u001b[39mname, typ\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m'\u001b[39m, lines\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, chunksize\u001b[39m=\u001b[39mchunksize):\n\u001b[1;32m    124\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/brtdevkit/util/aws/s3.py:101\u001b[0m, in \u001b[0;36mS3.download_file\u001b[0;34m(self, bucket_name, key, target_path)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Download a file object from an S3 bucket to a local target path.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m    bool - Whether the download was successful or not.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mdownload_file(Bucket\u001b[39m=\u001b[39;49mbucket_name, Key\u001b[39m=\u001b[39;49mkey, Filename\u001b[39m=\u001b[39;49mtarget_path)\n\u001b[1;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mexcept\u001b[39;00m botocore\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mClientError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/boto3/s3/inject.py:190\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39mUsage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39m    transfer.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39mwith\u001b[39;00m S3Transfer(\u001b[39mself\u001b[39m, Config) \u001b[39mas\u001b[39;00m transfer:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m transfer\u001b[39m.\u001b[39;49mdownload_file(\n\u001b[1;32m    191\u001b[0m         bucket\u001b[39m=\u001b[39;49mBucket,\n\u001b[1;32m    192\u001b[0m         key\u001b[39m=\u001b[39;49mKey,\n\u001b[1;32m    193\u001b[0m         filename\u001b[39m=\u001b[39;49mFilename,\n\u001b[1;32m    194\u001b[0m         extra_args\u001b[39m=\u001b[39;49mExtraArgs,\n\u001b[1;32m    195\u001b[0m         callback\u001b[39m=\u001b[39;49mCallback,\n\u001b[1;32m    196\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/boto3/s3/transfer.py:326\u001b[0m, in \u001b[0;36mS3Transfer.download_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    322\u001b[0m future \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager\u001b[39m.\u001b[39mdownload(\n\u001b[1;32m    323\u001b[0m     bucket, key, filename, extra_args, subscribers\n\u001b[1;32m    324\u001b[0m )\n\u001b[1;32m    325\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 326\u001b[0m     future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    327\u001b[0m \u001b[39m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[39m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[39m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[39m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# their own retries.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/s3transfer/futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     99\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         \u001b[39m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[39m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[39m# out of this and propagate the exception.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coordinator\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    104\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    105\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/s3transfer/futures.py:266\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# final result.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m--> 266\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/s3transfer/tasks.py:269\u001b[0m, in \u001b[0;36mSubmissionTask._main\u001b[0;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_coordinator\u001b[39m.\u001b[39mset_status_to_running()\n\u001b[1;32m    267\u001b[0m     \u001b[39m# Call the submit method to start submitting tasks to execute the\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[39m# transfer.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_submit(transfer_future\u001b[39m=\u001b[39;49mtransfer_future, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    270\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    271\u001b[0m     \u001b[39m# If there was an exception raised during the submission of task\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[39m# there is a chance that the final task that signals if a transfer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \n\u001b[1;32m    282\u001b[0m     \u001b[39m# Set the exception, that caused the process to fail.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_and_set_exception(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/s3transfer/download.py:354\u001b[0m, in \u001b[0;36mDownloadSubmissionTask._submit\u001b[0;34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[39m:param client: The client associated with the transfer manager\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39m    downloading streams\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m transfer_future\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39msize \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     \u001b[39m# If a size was not provided figure out the size for the\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     \u001b[39m# user.\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mhead_object(\n\u001b[1;32m    355\u001b[0m         Bucket\u001b[39m=\u001b[39;49mtransfer_future\u001b[39m.\u001b[39;49mmeta\u001b[39m.\u001b[39;49mcall_args\u001b[39m.\u001b[39;49mbucket,\n\u001b[1;32m    356\u001b[0m         Key\u001b[39m=\u001b[39;49mtransfer_future\u001b[39m.\u001b[39;49mmeta\u001b[39m.\u001b[39;49mcall_args\u001b[39m.\u001b[39;49mkey,\n\u001b[1;32m    357\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtransfer_future\u001b[39m.\u001b[39;49mmeta\u001b[39m.\u001b[39;49mcall_args\u001b[39m.\u001b[39;49mextra_args,\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    359\u001b[0m     transfer_future\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mprovide_transfer_size(\n\u001b[1;32m    360\u001b[0m         response[\u001b[39m'\u001b[39m\u001b[39mContentLength\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    361\u001b[0m     )\n\u001b[1;32m    363\u001b[0m download_output_manager \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_download_output_manager_cls(\n\u001b[1;32m    364\u001b[0m     transfer_future, osutil\n\u001b[1;32m    365\u001b[0m )(osutil, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_coordinator, io_executor)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/client.py:535\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    532\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    534\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/client.py:963\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    959\u001b[0m     maybe_compress_request(\n\u001b[1;32m    960\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mconfig, request_dict, operation_model\n\u001b[1;32m    961\u001b[0m     )\n\u001b[1;32m    962\u001b[0m     apply_request_checksum(request_dict)\n\u001b[0;32m--> 963\u001b[0m     http, parsed_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    964\u001b[0m         operation_model, request_dict, request_context\n\u001b[1;32m    965\u001b[0m     )\n\u001b[1;32m    967\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mevents\u001b[39m.\u001b[39memit(\n\u001b[1;32m    968\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mafter-call.\u001b[39m\u001b[39m{service_id}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{operation_name}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    969\u001b[0m         service_id\u001b[39m=\u001b[39mservice_id, operation_name\u001b[39m=\u001b[39moperation_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    974\u001b[0m     context\u001b[39m=\u001b[39mrequest_context,\n\u001b[1;32m    975\u001b[0m )\n\u001b[1;32m    977\u001b[0m \u001b[39mif\u001b[39;00m http\u001b[39m.\u001b[39mstatus_code \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m300\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/client.py:986\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\u001b[39mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 986\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_endpoint\u001b[39m.\u001b[39;49mmake_request(operation_model, request_dict)\n\u001b[1;32m    987\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    988\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mevents\u001b[39m.\u001b[39memit(\n\u001b[1;32m    989\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mafter-call-error.\u001b[39m\u001b[39m{service_id}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{operation_name}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    990\u001b[0m                 service_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_service_model\u001b[39m.\u001b[39mservice_id\u001b[39m.\u001b[39mhyphenize(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    994\u001b[0m             context\u001b[39m=\u001b[39mrequest_context,\n\u001b[1;32m    995\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/endpoint.py:119\u001b[0m, in \u001b[0;36mEndpoint.make_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_request\u001b[39m(\u001b[39mself\u001b[39m, operation_model, request_dict):\n\u001b[1;32m    114\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMaking request for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m with params: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m         operation_model,\n\u001b[1;32m    117\u001b[0m         request_dict,\n\u001b[1;32m    118\u001b[0m     )\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(request_dict, operation_model)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/endpoint.py:198\u001b[0m, in \u001b[0;36mEndpoint._send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    196\u001b[0m context \u001b[39m=\u001b[39m request_dict[\u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    197\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_retries_context(context, attempts)\n\u001b[0;32m--> 198\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_request(request_dict, operation_model)\n\u001b[1;32m    199\u001b[0m success_response, exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_response(\n\u001b[1;32m    200\u001b[0m     request, operation_model, context\n\u001b[1;32m    201\u001b[0m )\n\u001b[1;32m    202\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needs_retry(\n\u001b[1;32m    203\u001b[0m     attempts,\n\u001b[1;32m    204\u001b[0m     operation_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m     exception,\n\u001b[1;32m    208\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/endpoint.py:134\u001b[0m, in \u001b[0;36mEndpoint.create_request\u001b[0;34m(self, params, operation_model)\u001b[0m\n\u001b[1;32m    130\u001b[0m     service_id \u001b[39m=\u001b[39m operation_model\u001b[39m.\u001b[39mservice_model\u001b[39m.\u001b[39mservice_id\u001b[39m.\u001b[39mhyphenize()\n\u001b[1;32m    131\u001b[0m     event_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrequest-created.\u001b[39m\u001b[39m{service_id}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{op_name}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    132\u001b[0m         service_id\u001b[39m=\u001b[39mservice_id, op_name\u001b[39m=\u001b[39moperation_model\u001b[39m.\u001b[39mname\n\u001b[1;32m    133\u001b[0m     )\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_emitter\u001b[39m.\u001b[39;49memit(\n\u001b[1;32m    135\u001b[0m         event_name,\n\u001b[1;32m    136\u001b[0m         request\u001b[39m=\u001b[39;49mrequest,\n\u001b[1;32m    137\u001b[0m         operation_name\u001b[39m=\u001b[39;49moperation_model\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    138\u001b[0m     )\n\u001b[1;32m    139\u001b[0m prepared_request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_request(request)\n\u001b[1;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m prepared_request\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/hooks.py:412\u001b[0m, in \u001b[0;36mEventAliaser.emit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39memit\u001b[39m(\u001b[39mself\u001b[39m, event_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    411\u001b[0m     aliased_event_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_alias_event_name(event_name)\n\u001b[0;32m--> 412\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_emitter\u001b[39m.\u001b[39;49memit(aliased_event_name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/hooks.py:256\u001b[0m, in \u001b[0;36mHierarchicalEmitter.emit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39memit\u001b[39m(\u001b[39mself\u001b[39m, event_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    246\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39m    Emit an event by name with arguments passed as keyword args.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39m             handlers.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_emit(event_name, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/hooks.py:239\u001b[0m, in \u001b[0;36mHierarchicalEmitter._emit\u001b[0;34m(self, event_name, kwargs, stop_on_response)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers_to_call:\n\u001b[1;32m    238\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39mEvent \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling handler \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, event_name, handler)\n\u001b[0;32m--> 239\u001b[0m     response \u001b[39m=\u001b[39m handler(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    240\u001b[0m     responses\u001b[39m.\u001b[39mappend((handler, response))\n\u001b[1;32m    241\u001b[0m     \u001b[39mif\u001b[39;00m stop_on_response \u001b[39mand\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/signers.py:105\u001b[0m, in \u001b[0;36mRequestSigner.handler\u001b[0;34m(self, operation_name, request, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(\u001b[39mself\u001b[39m, operation_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, request\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    101\u001b[0m     \u001b[39m# This is typically hooked up to the \"request-created\" event\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[39m# from a client's event emitter.  When a new request is created\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[39m# this method is invoked to sign the request.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[39m# Don't call this method directly.\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msign(operation_name, request)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/signers.py:180\u001b[0m, in \u001b[0;36mRequestSigner.sign\u001b[0;34m(self, operation_name, request, region_name, signing_type, expires_in, signing_name)\u001b[0m\n\u001b[1;32m    178\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39msigning_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m signing_context[\u001b[39m'\u001b[39m\u001b[39msigning_name\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    179\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m     auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_auth_instance(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    181\u001b[0m \u001b[39mexcept\u001b[39;00m UnknownSignatureVersionError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    182\u001b[0m     \u001b[39mif\u001b[39;00m signing_type \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstandard\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/signers.py:284\u001b[0m, in \u001b[0;36mRequestSigner.get_auth_instance\u001b[0;34m(self, signing_name, region_name, signature_version, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m frozen_credentials \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_credentials \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     frozen_credentials \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_credentials\u001b[39m.\u001b[39;49mget_frozen_credentials()\n\u001b[1;32m    285\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mcredentials\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m frozen_credentials\n\u001b[1;32m    286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mREQUIRES_REGION:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/credentials.py:610\u001b[0m, in \u001b[0;36mRefreshableCredentials.get_frozen_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_frozen_credentials\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    577\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return immutable credentials.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \n\u001b[1;32m    579\u001b[0m \u001b[39m    The ``access_key``, ``secret_key``, and ``token`` properties\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m \n\u001b[1;32m    609\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 610\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_refresh()\n\u001b[1;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_frozen_credentials\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/credentials.py:498\u001b[0m, in \u001b[0;36mRefreshableCredentials._refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    495\u001b[0m     is_mandatory_refresh \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefresh_needed(\n\u001b[1;32m    496\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mandatory_refresh_timeout\n\u001b[1;32m    497\u001b[0m     )\n\u001b[0;32m--> 498\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_protected_refresh(is_mandatory\u001b[39m=\u001b[39;49mis_mandatory_refresh)\n\u001b[1;32m    499\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/credentials.py:514\u001b[0m, in \u001b[0;36mRefreshableCredentials._protected_refresh\u001b[0;34m(self, is_mandatory)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_protected_refresh\u001b[39m(\u001b[39mself\u001b[39m, is_mandatory):\n\u001b[1;32m    511\u001b[0m     \u001b[39m# precondition: this method should only be called if you've acquired\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[39m# the self._refresh_lock.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 514\u001b[0m         metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_refresh_using()\n\u001b[1;32m    515\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m         period_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmandatory\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m is_mandatory \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39madvisory\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/credentials.py:661\u001b[0m, in \u001b[0;36mCachedCredentialFetcher.fetch_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch_credentials\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 661\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cached_credentials()\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/credentials.py:671\u001b[0m, in \u001b[0;36mCachedCredentialFetcher._get_cached_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_from_cache()\n\u001b[1;32m    670\u001b[0m \u001b[39mif\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 671\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_credentials()\n\u001b[1;32m    672\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write_to_cache(response)\n\u001b[1;32m    673\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/botocore/credentials.py:2126\u001b[0m, in \u001b[0;36mSSOCredentialFetcher._get_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2124\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mget_role_credentials(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   2125\u001b[0m \u001b[39mexcept\u001b[39;00m client\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mUnauthorizedException:\n\u001b[0;32m-> 2126\u001b[0m     \u001b[39mraise\u001b[39;00m UnauthorizedSSOTokenError()\n\u001b[1;32m   2127\u001b[0m credentials \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mroleCredentials\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m   2129\u001b[0m credentials \u001b[39m=\u001b[39m {\n\u001b[1;32m   2130\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mProviderType\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msso\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2131\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mCredentials\u001b[39m\u001b[39m'\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2136\u001b[0m     },\n\u001b[1;32m   2137\u001b[0m }\n",
      "\u001b[0;31mUnauthorizedSSOTokenError\u001b[0m: The SSO session associated with this profile has expired or is otherwise invalid. To refresh this SSO session run aws sso login with the corresponding profile."
     ]
    }
   ],
   "source": [
    "dsetname ='mannequin_in_dust_v0'\n",
    "aletheia_ds = Dataset.retrieve(name=dsetname)\n",
    "aletheia_df = aletheia_ds.to_dataframe()\n",
    "dataset_save_dir = os.environ['DATASET_PATH'] + \"/\" + dsetname\n",
    "if not os.path.exists(dataset_save_dir):\n",
    "    os.makedirs(name=dataset_save_dir)\n",
    "    aletheia_ds.download(dataset_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1434\n",
      "2023-08-22T06:09:33.384000\n"
     ]
    }
   ],
   "source": [
    "dsetname ='mannequin_in_dust_v0_diverse_1500'\n",
    "aletheia_ds = Dataset.retrieve(name=dsetname)\n",
    "aletheia_df = aletheia_ds.to_dataframe()\n",
    "print(len(aletheia_df))\n",
    "print(max(aletheia_df['collected_on']))\n",
    "# dsetname ='mannequin_in_dust_v0'\n",
    "# aletheia_ds = Dataset.retrieve(name=dsetname)\n",
    "# aletheia_df = aletheia_ds.to_dataframe()\n",
    "# print(len(aletheia_df))\n",
    "# print(max(aletheia_df['collected_on']))\n",
    "# dsetname ='mannequin_in_dust_night_dawn_10pos'\n",
    "# aletheia_ds = Dataset.retrieve(name=dsetname)\n",
    "# aletheia_df = aletheia_ds.to_dataframe()\n",
    "# print(len(aletheia_df))\n",
    "# print(max(aletheia_df['collected_on']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'front-center-left', 'front-left-left', 'rear-left', 'side-left-left'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(aletheia_df[aletheia_df['camera_location'].str.endswith('left')]['camera_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(save_dir, df):\n",
    "    save_dir = Path(save_dir)\n",
    "    dirs = [save_dir / d for d in df.id]#[df['label_human']].id]\n",
    "    image_paths = []\n",
    "    for i, dir in dirs:\n",
    "        if i % 10 == 0:\n",
    "            print(i / len(dir))\n",
    "        for fname in os.listdir(dir):\n",
    "            if 'debayeredrgb' in fname:\n",
    "                image_paths.append(str(dir / p))\n",
    "    return image_paths\n",
    "save_file = Path(dataset_save_dir) / \"image_ids.npy\"\n",
    "image_paths = np.load(save_file).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = ImageSimilarity(images_full_path=image_paths, data_base_path=dataset_save_dir, dataset_name=dsetname, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17428"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aletheia_df['collected_on'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/272.296875 [00:00<?, ?it/s]/tmp/ipykernel_72566/3190044770.py:12: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_pil = self.transform(Image.fromarray(imageio.imread(img_path)))\n",
      "  3%|▎         | 9/272.296875 [00:31<15:11,  3.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sim\u001b[39m.\u001b[39;49mextract_embeddings()\n\u001b[1;32m      2\u001b[0m embeddings_np, paths_df \u001b[39m=\u001b[39m sim\u001b[39m.\u001b[39mload_embeddings()\n",
      "Cell \u001b[0;32mIn[6], line 163\u001b[0m, in \u001b[0;36mImageSimilarity.extract_embeddings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_dataloader()\n\u001b[1;32m    162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverwrite \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_embeddings()\n\u001b[1;32m    164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_embeddings()\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 65\u001b[0m, in \u001b[0;36mImageSimilarity.build_embeddings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     inference_loader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_dataloader()\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m idx, batch \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(inference_loader), total\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal): \n\u001b[1;32m     66\u001b[0m         batch, paths \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m], batch[\u001b[39m1\u001b[39m]\n\u001b[1;32m     67\u001b[0m         \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mDatasetpreparer.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     11\u001b[0m     img_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mloc[idx, \u001b[39m'\u001b[39m\u001b[39mimage_path\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m     img_pil \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(Image\u001b[39m.\u001b[39mfromarray(imageio\u001b[39m.\u001b[39;49mimread(img_path)))\n\u001b[1;32m     13\u001b[0m     \u001b[39m# Download and open the image        \u001b[39;00m\n\u001b[1;32m     14\u001b[0m     img_pil \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(img_pil)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/imageio/__init__.py:97\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"imread(uri, format=None, **kwargs)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[39mReads an image from the specified file. Returns a numpy array, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39m    to see what arguments are available for a particular format.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     90\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mStarting with ImageIO v3 the behavior of this function will switch to that of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m iio.v3.imread. To keep the current behavior (and make this warning disappear)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     95\u001b[0m )\n\u001b[0;32m---> 97\u001b[0m \u001b[39mreturn\u001b[39;00m imread_v2(uri, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/imageio/v2.py:360\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m imopen_args[\u001b[39m\"\u001b[39m\u001b[39mlegacy_mode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39mwith\u001b[39;00m imopen(uri, \u001b[39m\"\u001b[39m\u001b[39mri\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mimopen_args) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m--> 360\u001b[0m     result \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39;49mread(index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    362\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/imageio/plugins/pillow.py:224\u001b[0m, in \u001b[0;36mPillowPlugin.read\u001b[0;34m(self, index, mode, rotate, apply_gamma, writeable_output, pilmode, exifrotate, as_gray)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(index, \u001b[39mint\u001b[39m):\n\u001b[1;32m    222\u001b[0m     \u001b[39m# will raise IO error if index >= number of frames in image\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image\u001b[39m.\u001b[39mseek(index)\n\u001b[0;32m--> 224\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_transforms(\n\u001b[1;32m    225\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_image, mode, rotate, apply_gamma, writeable_output\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter(\n\u001b[1;32m    229\u001b[0m         mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m    230\u001b[0m         rotate\u001b[39m=\u001b[39mrotate,\n\u001b[1;32m    231\u001b[0m         apply_gamma\u001b[39m=\u001b[39mapply_gamma,\n\u001b[1;32m    232\u001b[0m         writeable_output\u001b[39m=\u001b[39mwriteable_output,\n\u001b[1;32m    233\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/imageio/plugins/pillow.py:307\u001b[0m, in \u001b[0;36mPillowPlugin._apply_transforms\u001b[0;34m(self, image, mode, rotate, apply_gamma, writeable_output)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[39melse\u001b[39;00m:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    304\u001b[0m         \u001b[39m# Let pillow know that it is okay to return 16-bit\u001b[39;00m\n\u001b[1;32m    305\u001b[0m         image\u001b[39m.\u001b[39mmode \u001b[39m=\u001b[39m desired_mode\n\u001b[0;32m--> 307\u001b[0m image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(image)\n\u001b[1;32m    309\u001b[0m meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata(index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image\u001b[39m.\u001b[39mtell(), exclude_applied\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    310\u001b[0m \u001b[39mif\u001b[39;00m rotate \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mOrientation\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m meta:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/PIL/Image.py:696\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    694\u001b[0m         new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtobytes(\u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    695\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 696\u001b[0m         new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtobytes()\n\u001b[1;32m    697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(e, (\u001b[39mMemoryError\u001b[39;00m, \u001b[39mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/PIL/Image.py:754\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39mif\u001b[39;00m encoder_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m args \u001b[39m==\u001b[39m ():\n\u001b[1;32m    752\u001b[0m     args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m--> 754\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    756\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheight \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    757\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sim.extract_embeddings()\n",
    "embeddings_np, paths_df = sim.load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_paths = [None for _ in range(n_images_final)]\n",
    "\n",
    "import random\n",
    "order = list(enumerate(kmeans.labels_))\n",
    "random.shuffle(order)\n",
    "\n",
    "for i, l in order:\n",
    "    if final_paths[l] == None:\n",
    "        final_paths[l] = paths_df.image_path.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imids = [p.split('_')[-1][:-4] for p in final_paths]\n",
    "fin_df = df[df.id.isin(imids)]\n",
    "print(len(fin_df))\n",
    "print(len(imids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataset\n",
    "\n",
    "desc = f\"Mannequins standing in dust, diversified. ({len(imids)} images)\"\n",
    "imageids_to_dataset(image_ids=imids, dataset_name=\"mannequin_in_dust_v0_diverse\", dataset_description=desc, dataset_kind=Dataset.KIND_ANNOTATION, production_dataset=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
