{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from brtdevkit.data import Dataset\n",
    "from email.mime import image\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset as torchDataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from pathlib import Path \n",
    "from sklearn.decomposition import PCA\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasetpreparer(torchDataset):    \n",
    "        def __init__(self, data, preprocess=None, transform=None, device=\"cuda\"):\n",
    "            self.data = data\n",
    "            self.transform =  transform \n",
    "            self.preprocess = preprocess\n",
    "            self.device = device \n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_path = self.data.loc[idx, 'image_path']\n",
    "            img_pil = self.transform(Image.fromarray(imageio.imread(img_path)))\n",
    "            # Download and open the image        \n",
    "            img_pil = self.preprocess(img_pil).to(self.device)\n",
    "            return img_pil, img_path\n",
    "\n",
    "class ImageSimilarity: \n",
    "    def __init__(self, images_full_path, data_base_path, dataset_name='image_list', overwrite=False):\n",
    "        self.data_base_path = data_base_path\n",
    "        os.makedirs(self.data_base_path, exist_ok=True)\n",
    "        self.images_base_path = data_base_path + \"/images\"\n",
    "        self.images_full_path = images_full_path\n",
    "        \n",
    "        self.image_path_df = None \n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((224,224))])\n",
    "        \n",
    "        self.inference_set = None \n",
    "        self.embeddings_np = None\n",
    "        self.image_paths = None \n",
    "        self.image_paths_df = None\n",
    "        self.embeddings_save_name = f\"{dataset_name}_embeddings\"\n",
    "        self.embeddings_image_paths = Path(self.data_base_path) / f\"{dataset_name}_embeddings_image_paths.csv\"\n",
    "        self.embeddings_save_loc = Path(self.data_base_path) / self.embeddings_save_name\n",
    "        self.overwrite = overwrite \n",
    "        self.model = None \n",
    "        self.preprocessor = None \n",
    "        self.sorted_scores = None \n",
    "        self.sorted_scores_save_loc = data_base_path \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.load_model()\n",
    "        \n",
    "    def prepare_images_path_df(self): \n",
    "        self.image_path_df = pd.DataFrame(data=self.images_full_path, columns=['image_path'])\n",
    "        return self.image_path_df\n",
    "    \n",
    "    def prepare_dataloader(self): \n",
    "        self.inference_set = Datasetpreparer(data=self.image_path_df, preprocess=self.preprocessor, transform=self.transform, device=self.device)\n",
    "        inference_loader = DataLoader(self.inference_set, batch_size=64, shuffle=False, num_workers=0, drop_last=True)\n",
    "        self.total = len(self.image_path_df) / 64\n",
    "        return inference_loader\n",
    " \n",
    "    def load_model(self): \n",
    "        self.model, self.preprocessor = clip.load(\"ViT-B/32\", device=self.device)\n",
    "        return self.model, self.preprocessor\n",
    "\n",
    "    def build_embeddings(self): \n",
    "        outputs = []\n",
    "        image_paths = []\n",
    "        if (os.path.isfile(self.embeddings_save_loc)==True) or (self.overwrite==False): \n",
    "            self.embeddings_np, self.image_paths = self.load_embeddings()\n",
    "            return self.embeddings_np, self.image_paths \n",
    "        else:\n",
    "            inference_loader = self.prepare_dataloader()\n",
    "            for idx, batch in tqdm(enumerate(inference_loader), total=self.total): \n",
    "                batch, paths = batch[0], batch[1]\n",
    "                with torch.no_grad():\n",
    "                        batch = batch.to(self.device)\n",
    "                        image_features = self.model.encode_image(batch)\n",
    "                        outputs.append(image_features)  \n",
    "                        image_paths.extend(paths)\n",
    "            outputs = torch.cat(outputs, dim=0)\n",
    "            self.image_paths = image_paths \n",
    "            self.embeddings_np = outputs.detach().cpu().numpy()\n",
    "            return self.embeddings_np, self.image_paths\n",
    "            \n",
    "    def save_embeddings(self): \n",
    "            np.savez(self.embeddings_save_loc, self.embeddings_np) \n",
    "            image_paths_df = pd.DataFrame(data=self.image_paths, columns=['image_path'])\n",
    "            image_paths_df.to_csv(self.embeddings_image_paths, index=False)\n",
    "            return None \n",
    "        \n",
    "    def load_embeddings(self): \n",
    "        embeddings_save_loc = str(self.embeddings_save_loc) +\".npz\"\n",
    "        embeddings = np.load(embeddings_save_loc)\n",
    "        self.embeddings_np = embeddings[embeddings.files[0]]       \n",
    "        self.image_paths_df= pd.read_csv(self.embeddings_image_paths )\n",
    "        return self.embeddings_np, self.image_paths_df \n",
    "\n",
    "    def get_image_embedding(self, image_path): \n",
    "        transformed_image = self.transform(Image.open(image_path))\n",
    "        img = self.preprocessor(transformed_image).unsqueeze(0).to(self.device)\n",
    "        embedding = self.model.encode_image(img)\n",
    "        embeddings_np = embedding.detach().cpu().numpy()\n",
    "        return embeddings_np\n",
    "    \n",
    "    def get_similar_images(self, image_path, calcuate_embeddings=False, images_base_path=None): \n",
    "        if images_base_path==None:\n",
    "            images_base_path = self.images_base_path\n",
    "        full_image_path = os.path.join(images_base_path, image_path)\n",
    "        embeddings_np, image_paths_df = self.load_embeddings()\n",
    "        image_paths = image_paths_df['image_path'].tolist()\n",
    "        if calcuate_embeddings==True:\n",
    "            reference_embedding = self.get_image_embedding(full_image_path)\n",
    "        else:\n",
    "            embedding_index = image_paths_df[image_paths_df['image_path'] == full_image_path].index[0]\n",
    "            reference_embedding = embeddings_np[embedding_index, :]\n",
    "        \n",
    "        similarity_score = np.dot(reference_embedding, embeddings_np.T)/(np.linalg.norm(reference_embedding)*np.linalg.norm( embeddings_np, axis=1))\n",
    "        score_df = pd.DataFrame(data=list(similarity_score.T), columns=['similarity_score'])\n",
    "        score_df['image_path'] = image_paths \n",
    "        self.sorted_scores = score_df.sort_values(by='similarity_score', ascending=False)\n",
    "        image_name = image_path.split(\"/\")[-1].replace(\".png\",\"\")\n",
    "        save_loc_sorted_scores = Path(self.sorted_scores_save_loc) / f\"{image_name}.csv\"\n",
    "        self.sorted_scores.to_csv(save_loc_sorted_scores, index=False)\n",
    "        return self.sorted_scores\n",
    "    \n",
    "    def similar_images_with_text(self, text_prompt):\n",
    "        \n",
    "        embeddings_np, image_paths_df = self.load_embeddings()\n",
    "        image_paths = image_paths_df['image_path'].tolist()\n",
    "        text = clip.tokenize(text_prompt).to(self.device)\n",
    "        text_features = self.model.encode_text(text)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features.detach().cpu().numpy()\n",
    "        reference_embedding = text_features\n",
    "            \n",
    "        similarity_score = np.dot(reference_embedding, embeddings_np.T)/(np.linalg.norm(reference_embedding)*np.linalg.norm( embeddings_np, axis=1))\n",
    "        score_df = pd.DataFrame(data=list(similarity_score.T), columns=['similarity_score'])\n",
    "        score_df['image_path'] = image_paths \n",
    "        self.sorted_scores = score_df.sort_values(by='similarity_score', ascending=False)\n",
    "        image_name = text_prompt.replace(\" \",\"_\")\n",
    "        save_loc_sorted_scores = Path(self.sorted_scores_save_loc) / f\"{image_name}.csv\"\n",
    "        self.sorted_scores.to_csv(save_loc_sorted_scores, index=False)\n",
    "        return self.sorted_scores\n",
    "        \n",
    "        \n",
    "    def plot_image_grid(self, image_paths_df, tail=0  ,nrows=5, ncols=2):\n",
    "        \n",
    "        # Assume image_paths is your list of image file paths\n",
    "        if tail > 0:\n",
    "            image_paths_df = image_paths_df.tail(tail)\n",
    "        image_paths = image_paths_df['image_path'].tolist()\n",
    "        n_rows = min(nrows, int(image_paths_df.shape[0] // 2 ))\n",
    "        fig, axes = plt.subplots(n_rows, ncols, figsize=(10, nrows*5))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            if i < len(image_paths)-1:\n",
    "                image_path = image_paths[i]\n",
    "                title = image_path.split(\"/\")[-1]\n",
    "                img = Image.open(image_path)\n",
    "                ax.imshow(img)\n",
    "                ax.set_title(f'{title}  indx: {i}', fontsize=6)\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def extract_embeddings(self): \n",
    "        self.prepare_images_path_df()\n",
    "        self.prepare_dataloader()\n",
    "        self.overwrite = True\n",
    "        self.build_embeddings()\n",
    "        self.save_embeddings()\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsetname ='mannequin_in_dust_v3'\n",
    "aletheia_ds = Dataset.retrieve(name=dsetname)\n",
    "aletheia_df = aletheia_ds.to_dataframe()\n",
    "dataset_save_dir = os.environ['DATASET_PATH'] + \"/\" + dsetname\n",
    "if not os.path.exists(dataset_save_dir):\n",
    "    os.makedirs(name=dataset_save_dir)\n",
    "    aletheia_ds.download(dataset_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(save_dir, df):\n",
    "    save_dir = Path(save_dir)\n",
    "    dirs = [save_dir / 'images' / d for d in df.id]#[df['label_human']].id]\n",
    "    image_paths = []\n",
    "    for i, dir in enumerate(dirs):\n",
    "        if i % 10 == 0:\n",
    "            print(i / len(str(dir)))\n",
    "        for fname in os.listdir(dir):\n",
    "            if 'debayeredrgb' in fname:\n",
    "                image_paths.append(str(dir / fname))\n",
    "    return image_paths\n",
    "image_paths = get_images(dataset_save_dir, aletheia_df)\n",
    "# save_file = Path(dataset_save_dir) / \"image_ids.npy\"\n",
    "# image_paths = np.load(save_file).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = ImageSimilarity(images_full_path=image_paths, data_base_path=dataset_save_dir, dataset_name=dsetname, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.extract_embeddings()\n",
    "embeddings_np, paths_df = sim.load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images_final = 1000\n",
    "kmeans = KMeans(n_clusters=n_images_final, random_state=0, n_init=\"auto\")\n",
    "kmeans.fit(embeddings_np)\n",
    "final_paths: list[None] = [None for _ in range(n_images_final)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_paths = [None for _ in range(n_images_final)]\n",
    "\n",
    "import random\n",
    "order = list(enumerate(kmeans.labels_))\n",
    "random.shuffle(order)\n",
    "\n",
    "for i, l in order:\n",
    "    if final_paths[l] == None:\n",
    "        final_paths[l] = paths_df.image_path.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imids = [p.split('_')[-1][:-4] for p in final_paths]\n",
    "print(len(imids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataset\n",
    "# desc = f\"Mannequins standing in dust, diversified. ({len(imids)} images)\"\n",
    "# imageids_to_dataset(image_ids=imids, dataset_name=\"mannequin_in_dust_v0_diverse\", dataset_description=desc, dataset_kind=Dataset.KIND_ANNOTATION, production_dataset=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
