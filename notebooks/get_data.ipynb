{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc6fd89-d6ab-4190-95ca-8f00178f1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "import datetime\n",
    "import io\n",
    "from collections import defaultdict\n",
    "\n",
    "import imageio\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from brtdevkit.core.db.athena import AthenaClient\n",
    "from brtdevkit.data import Dataset\n",
    "from timezonefinder import TimezoneFinderL\n",
    "import pytz\n",
    "\n",
    "from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataset, imageids_to_dataset_fast\n",
    "from aletheia_dataset_creator.config.dataset_config import LEFT_CAMERAS, ALL_CAMERA_PAIRS_LIST\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56268454-b2e4-455a-a8ab-e601f2f34b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b51a2-f2ff-410f-8500-1588a154e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "athena = AthenaClient()\n",
    "s3 = boto3.resource('s3')\n",
    "tf = TimezoneFinderL()\n",
    "home = os.path.expanduser(path='~')\n",
    "data_path = '/data/jupiter/alex.li/datasets/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "731129f1-4e20-47eb-b70e-67c07c3f8ddb",
   "metadata": {},
   "source": [
    "# Selecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HALO_LEFT_CAMERAS = ['T01', 'T02', 'T05', 'T06', 'T09', 'T10', 'T13', 'T14', 'I01', 'I02']\n",
    "allpath = data_path + \"/halo_all.parquet\"\n",
    "if os.path.exists(allpath):\n",
    "    df_all = pd.read_parquet(path=allpath)\n",
    "else:\n",
    "    query = f\"\"\"\n",
    "        SELECT collected_on, id, robot_name, geohash, camera_location, operation_time, latitude,\n",
    "            longitude, gps_can_data__json\n",
    "        FROM image_jupiter\n",
    "        WHERE sensor_type = 'VD6763'\n",
    "        AND camera_location IN {tuple(HALO_LEFT_CAMERAS)}\n",
    "        AND geohash IS NOT NULL\n",
    "        AND geohash NOT LIKE '7zzzz%'\n",
    "        AND gps_can_data__json IS NOT NULL\n",
    "        ORDER BY RAND()\n",
    "        LIMIT 1000000\n",
    "    \"\"\"\n",
    "    df_all = athena.get_df(query)\n",
    "    df_all.to_parquet(allpath)\n",
    "orangepath = data_path + \"/halo_orange_implement.parquet\"\n",
    "if os.path.exists(orangepath):\n",
    "    df_orange = pd.read_parquet(orangepath)\n",
    "else:\n",
    "    print('cache failed')\n",
    "    query1 = f\"\"\"\n",
    "    SELECT id, robot_name, collected_on, operation_time,\n",
    "        camera_location, gps_can_data__json, group_id, geohash\n",
    "    FROM image_jupiter\n",
    "    WHERE sensor_type = 'VD6763'\n",
    "    AND camera_location IN {tuple(HALO_LEFT_CAMERAS)}\n",
    "    AND geohash IS NOT NULL\n",
    "    AND geohash NOT LIKE '7zzzz%'\n",
    "    AND gps_can_data__json IS NOT NULL\n",
    "    AND image_jupiter.robot_name IN ('halohitchhiker_182')\n",
    "    ORDER BY RAND()\n",
    "    LIMIT 30000\n",
    "    \"\"\"\n",
    "    df_orange = athena.get_df(query1)\n",
    "    df_orange.to_parquet(orangepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e30aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "puddlepath = data_path + \"/halo_puddle.parquet\"\n",
    "if os.path.exists(puddlepath):\n",
    "    df_puddle = pd.read_parquet(puddlepath)\n",
    "else:\n",
    "    df_puddle = Dataset.retrieve(name='labelbox_import_puddle_slice').to_dataframe()\n",
    "    df_puddle.to_parquet(puddlepath)\n",
    "dustpath = data_path + \"/halo_dust.parquet\"\n",
    "if os.path.exists(dustpath):\n",
    "    df_dust = pd.read_parquet(dustpath)\n",
    "else:\n",
    "    df_dust = Dataset.retrieve(name='labelbox_import_dust_slice').to_dataframe()\n",
    "    df_dust.to_parquet(dustpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ed28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "geohash_df = pd.read_csv(filepath_or_buffer='/data/jupiter/alex.li/20231213_geohash_table_v6.csv', index_col=\"Unnamed: 0\")\n",
    "geohash_train_df = geohash_df[geohash_df['bucket'] == 'train']\n",
    "new_geohashes = set()\n",
    "def filter_df(df_orig):\n",
    "    global new_geohashes\n",
    "    df_orig[\"geohash_short\"] = df_orig[\"geohash\"].apply(lambda x: x[:6])\n",
    "    if 'speed' not in df_orig.columns:\n",
    "        if 'gps_can_data__json' in df_orig.columns:\n",
    "            df_orig[\"speed\"] = df_orig[\"gps_can_data__json\"].apply(lambda x: json.loads(x).get('speed', np.nan))\n",
    "        elif 'gps_can_data' in df_orig.columns:\n",
    "            df_orig[\"speed\"] = df_orig[\"gps_can_data\"].apply(lambda x: x.get('speed', np.nan))\n",
    "    df_atspeed = df_orig[(1 < df_orig[\"speed\"]) & (df_orig[\"speed\"] < 30)]\n",
    "\n",
    "    new_geohashes = new_geohashes.union([geohash for geohash in set(df_atspeed[\"geohash_short\"]) if geohash not in geohash_df.index])\n",
    "    df_train = df_atspeed[df_atspeed['geohash_short'].isin(geohash_train_df.index)]\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt_all = filter_df(df_all)[['id', 'camera_location', 'robot_name','collected_on', 'speed', 'geohash_short']]\n",
    "df_filt_orange = filter_df(df_orange)[['id', 'camera_location', 'robot_name','collected_on', 'speed', 'geohash_short']]\n",
    "df_filt_puddle = filter_df(df_puddle)[['id', 'camera_location', 'robot_name','collected_on', 'speed', 'geohash_short']]\n",
    "df_filt_dust = filter_df(df_dust)[['id', 'camera_location', 'robot_name','collected_on', 'speed', 'geohash_short']]\n",
    "print(len(new_geohashes))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adcd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_filt_all))\n",
    "df_filt_all = df_filt_all.sample(30000, replace=False)\n",
    "print(len(df_filt_orange))\n",
    "df_filt_all = df_filt_orange.sample(5000, replace=False)\n",
    "print(len(df_filt_puddle))\n",
    "df_filt_puddle = df_filt_puddle.sample(10000, replace=False)\n",
    "print(len(df_filt_dust))\n",
    "df_filt_dust = df_filt_dust.sample(10000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b508f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_filt_all, df_filt_orange, df_filt_puddle, df_filt_dust])\n",
    "df = df[df['camera_location'].isin(HALO_LEFT_CAMERAS)]\n",
    "df['collected_on']  = pd.to_datetime(df['collected_on'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360164ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('camera_location').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/data/jupiter/alex.li/wrong_label.csv')\n",
    "# Dataset.create(name='halo_v61_to_relabel', description='images with incorrect label from v61 train set', kind=Dataset.KIND_IMAGE, image_ids=list(df['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709265df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_slow(from_df, name, description) -> None:\n",
    "    imids = list(set(from_df[)'id'])\n",
    "    desc = f\"{description} ({len(from_df['id'])} images)\"\n",
    "    print(len(imids))\n",
    "    from_df.to_parquet(data_path + f'/{name}.parquet', index=False)\n",
    "    imageids_to_dataset(imids, name, dataset_kind='image',\n",
    "                            dataset_description=desc)\n",
    "# make_dataset_slow(df, 'halo_images_for_train_implement_dust_puddle_small', 'training images for halo, choosen based on recent fps. Needs to be filtered further...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e5e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_positive_df = pd.read_csv('/mnt/sandbox1/alex.li/model_positives/halo_images_for_train_implement_dust_puddle_small_repro_bug/image_similarity_reduced_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d247108",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model_positive_df))\n",
    "model_positive_df = model_positive_df.drop_duplicates(['cluster_id'])\n",
    "print(len(model_positive_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4afe512",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_positive_df = model_positive_df.drop_duplicates(['id'])\n",
    "imids = model_positive_df['id']\n",
    "print(sum(imids.isin(df_filt_all['id'])))\n",
    "print(sum(imids.isin(df_filt_orange['id'])))\n",
    "print(sum(imids.isin(df_filt_puddle['id'])))\n",
    "print(sum(imids.isin(df_filt_dust['id'])))\n",
    "print(len(imids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c9ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.create(name='model_positives_labelbox_search', \n",
    "            description=\"\"\"Images to label. Model positives on images from a few sources.\n",
    "            129: randomly sampled from athena\n",
    "            4443: sampled from athena on rear camera of halohitchhiker_182\n",
    "            121: sampled from labelbox, have puddles and tire tracks\n",
    "            28: sampled from labelbox, dusty images\"\"\",\n",
    "            kind=Dataset.KIND_IMAGE,\n",
    "            image_ids=imids,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
