{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m2024-03-12 07:03:21,242 - APIRequestor - ERROR - API error received | error_code : 403, error_message : {'extra': {'role_name': 'token_exchange'}, 'message': 'Role token_exchange is required to make this API call'}\n",
      "\u001b[0mERROR:APIRequestor:API error received | error_code : 403, error_message : {'extra': {'role_name': 'token_exchange'}, 'message': 'Role token_exchange is required to make this API call'}\n",
      "WARNING:root:Failed to refresh AWS Credential\n",
      "WARNING:root:Some functionalities (S3, Athena, etc) not useable {'extra': {'role_name': 'token_exchange'}, 'message': 'Role token_exchange is required to make this API call'}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "import datetime\n",
    "import io\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import imageio\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import seaborn as sns\n",
    "\n",
    "from brtdevkit.core.db.athena import AthenaClient\n",
    "from brtdevkit.data import Dataset\n",
    "from timezonefinder import TimezoneFinderL\n",
    "import pytz\n",
    "import cv2\n",
    "from brtdevkit.util.aws.s3 import S3\n",
    "from pathlib import Path\n",
    "client = S3()\n",
    "\n",
    "from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataset\n",
    "from aletheia_dataset_creator.config.dataset_config import LEFT_CAMERAS, ALL_CAMERA_PAIRS_LIST\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m2024-03-12 07:03:22,702 - APIRequestor - ERROR - API error received | error_code : 403, error_message : {'extra': {'role_name': 'token_exchange'}, 'message': 'Role token_exchange is required to make this API call'}\n",
      "\u001b[0mERROR:APIRequestor:API error received | error_code : 403, error_message : {'extra': {'role_name': 'token_exchange'}, 'message': 'Role token_exchange is required to make this API call'}\n",
      "WARNING:root:Failed to refresh AWS Credential\n",
      "WARNING:root:Some functionalities (S3, Athena, etc) not useable {'extra': {'role_name': 'token_exchange'}, 'message': 'Role token_exchange is required to make this API call'}\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.retrieve(name='halo_vehicles_in_dust_collection_march2024')\n",
    "df = dataset.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_path = '/data2/jupiter/datasets/halo_vehicles_in_dust_collection_march2024'\n",
    "data_path = '/mnt/sandbox1/alex.li/halo_vehicles_in_dust_collection_march2024'\n",
    "imids = os.listdir(dset_path + \"/images\")\n",
    "df['id'].isin(imids).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort DF into individual sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_runs = []\n",
    "run_notes = list(sorted(set(df['special_notes'].unique()) - set(['test', 'trial capture'])))\n",
    "for notes in run_notes:\n",
    "    merged_runs.append(df[df['special_notes'] == notes])\n",
    "merged_runs = pd.concat(merged_runs)\n",
    "# rebuild the index and groups\n",
    "df_groups = merged_runs.groupby('special_notes').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_notes.index('Dust data capture.  White pickup 1 Dusk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.datetime' has no attribute 'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mna\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m merged_runs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera_area\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_runs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera_location\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_camera_area)\n\u001b[0;32m---> 20\u001b[0m merged_runs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcollected_on\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_runs\u001b[38;5;241m.\u001b[39mcollected_on\u001b[38;5;241m.\u001b[39mapply(\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mfromisoformat)\n\u001b[1;32m     21\u001b[0m merged_runs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpod1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_runs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera_location\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT01\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT02\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT03\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT04\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT05\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT06\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT07\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT08\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'datetime.datetime' has no attribute 'datetime'"
     ]
    }
   ],
   "source": [
    "def get_run_id(df_row):\n",
    "    try:\n",
    "        return run_notes.index(df_row['special_notes'])\n",
    "    except ValueError:\n",
    "        print(df_row['special_notes'])\n",
    "        return pd.NA\n",
    "merged_runs['collect_id'] = merged_runs.apply(get_run_id, axis=1)\n",
    "def get_camera_area(camera_location):\n",
    "    if camera_location in ['T01','T02','T03','T04']:\n",
    "        return 'front'\n",
    "    elif camera_location in ['T05','T06','T07','T08']:\n",
    "        return 'right'\n",
    "    elif camera_location in ['T09','T10','T11','T12']:\n",
    "        return 'rear'\n",
    "    elif camera_location in ['T13','T14','T15','T16']:\n",
    "        return 'left'\n",
    "    else:\n",
    "        return 'na'\n",
    "merged_runs['camera_area'] = merged_runs['camera_location'].apply(get_camera_area)\n",
    "merged_runs['collected_on'] = merged_runs.collected_on.apply(datetime.datetime.fromisoformat)\n",
    "merged_runs['pod1'] = merged_runs['camera_location'].isin(['T01','T02','T03','T04','T05','T06','T07','T08'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "# Separate runs further if they consist of non contiguous data\n",
    "interval = 5\n",
    "total_sequences = 0\n",
    "merged_runs = merged_runs.sort_values('collected_on')\n",
    "delta = timedelta(seconds=interval)\n",
    "start_t = merged_runs.iloc[0].collected_on\n",
    "for i in range(1, len(merged_runs)):\n",
    "    end_t = merged_runs.iloc[i - 1].collected_on\n",
    "    next_t = merged_runs.iloc[i].collected_on\n",
    "    if next_t - end_t > delta or i == len(merged_runs) - 1:\n",
    "        total_sequences += 1\n",
    "        if i == len(merged_runs) - 1:\n",
    "            next_t += timedelta(microseconds=1)\n",
    "        merged_runs.loc[(start_t <= merged_runs['collected_on']) & (merged_runs['collected_on'] < next_t), 'run_id'] = total_sequences\n",
    "        start_t = next_t\n",
    "print(total_sequences)\n",
    "\n",
    "print(set(merged_runs['run_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group together the pods that represent the same timestamp but have different VPUs\n",
    "next_pod1 = ''\n",
    "next_pod2 = ''\n",
    "next_pod1_t = merged_runs.iloc[-1]['collected_on'] + timedelta(minutes=1)\n",
    "next_pod2_t = merged_runs.iloc[-1]['collected_on'] + timedelta(minutes=1)\n",
    "next_pod_id = []\n",
    "merged_runs = merged_runs.sort_values('collected_on')\n",
    "for idx, row in reversed(list(merged_runs.iterrows())):\n",
    "    if row['pod1']:\n",
    "        next_pod1 = row['group_id']\n",
    "        next_pod1_t = row['collected_on']\n",
    "        if next_pod2_t < row['collected_on'] + timedelta(seconds=.5):\n",
    "            next_pod_id.append(next_pod2)\n",
    "        else:\n",
    "            next_pod_id.append('')\n",
    "    else:\n",
    "        next_pod2 = row['group_id']\n",
    "        next_pod2_t = row['collected_on']\n",
    "        if next_pod1_t < row['collected_on'] + timedelta(seconds=.5):\n",
    "            next_pod_id.append(next_pod1)\n",
    "        else:\n",
    "            next_pod_id.append('')\n",
    "merged_runs['next_pod_id'] = list(reversed(next_pod_id))\n",
    "# merged_runs['gid_short'] = merged_runs['group_id'].apply(lambda s:s[:4])\n",
    "# merged_runs['ngid_short'] = merged_runs['next_pod_id'].apply(lambda s:s[:4])\n",
    "# with pd.option_context('display.min_rows', 500, 'display.max_columns', 4):\n",
    "#     print(merged_runs[['pod1','gid_short', 'ngid_short', 'collected_on']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_image(df_row, collected_on: str):\n",
    "    downsample_factor = 6\n",
    "    if len(df_row) == 0:\n",
    "        whiteFrame = 255 * np.ones((math.ceil(1204 / downsample_factor), math.ceil(1944 / downsample_factor), 3), np.uint8)\n",
    "        return whiteFrame\n",
    "    elif isinstance(df_row, pd.DataFrame):\n",
    "        if not(len(df_row) == 1):\n",
    "            print(\"Multiple images for this row\")\n",
    "            print(df_row)\n",
    "        df_row = df_row.iloc[0]\n",
    "    path = Path(dset_path) / 'images' / str(df_row['id']) / f'artifact_debayeredrgb_0_{df_row[\"artifact_debayeredrgb_0_image\"]}.png'\n",
    "    im = cv2.imread(str(path))\n",
    "#     cv2.putText(im, df_row['camera_location'], (20, 40), cv2.FONT_HERSHEY_PLAIN, 3, (0,0,0), 2)\n",
    "    return im[::downsample_factor, ::downsample_factor]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_frames(video_dir: Path, base_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Given dictionary with image paths creates concatenated image and video and saves to output_dir.\n",
    "    \"\"\"\n",
    "    os.makedirs(video_dir, exist_ok=True)\n",
    "    video_name = video_dir / \"video.mp4\"\n",
    "    k_df = base_df.sort_values('collected_on')\n",
    "    k_groups = base_df.groupby('group_id').groups\n",
    "    seen = set()\n",
    "    with imageio.get_writer(video_name, mode='I', fps=3) as writer:\n",
    "        for _, row in k_df.iterrows():\n",
    "            gid = row['group_id']\n",
    "            next_gid = row['next_pod_id']\n",
    "            if gid in seen:\n",
    "                continue\n",
    "            seen.add(gid)\n",
    "            values = k_groups[gid] \n",
    "            if next_gid not in seen and next_gid != '':\n",
    "                seen.add(next_gid)\n",
    "                next_values = k_groups[next_gid]\n",
    "                try:\n",
    "                    next_values = k_groups[next_gid]\n",
    "                except KeyError:\n",
    "                    print(f\"Could not find next GID {next_gid}\")\n",
    "                    continue\n",
    "                values = list(values) + list(next_values)\n",
    "            group = k_df.loc[values]\n",
    "            collected_on_str = str(group.iloc[0].collected_on)[11:21]\n",
    "            # concatenate image Horizontally\n",
    "            front_pod = np.concatenate(\n",
    "                (\n",
    "                    get_image(group[group['camera_location'] == 'T01'], collected_on_str),\n",
    "                    get_image(group[group['camera_location'] == 'T02'], collected_on_str),\n",
    "#                     get_image(group[group['camera_location'] == 'T03'], collected_on_str),\n",
    "#                     get_image(group[group['camera_location'] == 'T04'], collected_on_str),\n",
    "                ),\n",
    "                axis=0,\n",
    "            )\n",
    "            right_pod = np.concatenate(\n",
    "                (\n",
    "                    get_image(group[group['camera_location'] == 'T05'], collected_on_str),\n",
    "                    get_image(group[group['camera_location'] == 'T06'], collected_on_str),\n",
    "#                     get_image(group[group['camera_location'] == 'T07'], collected_on_str),\n",
    "#                     get_image(group[group['camera_location'] == 'T08'], collected_on_str),\n",
    "                ),\n",
    "                axis=0,\n",
    "            )\n",
    "            rear_pod = np.concatenate(\n",
    "                (\n",
    "                    get_image(group[group['camera_location'] == 'T09'], collected_on_str),\n",
    "                    get_image(group[group['camera_location'] == 'T10'], collected_on_str),\n",
    "#                     get_image(group[group['camera_location'] == 'T11'], collected_on_str),\n",
    "#                     get_image(group[group['camera_location'] == 'T12'], collected_on_str),\n",
    "                ),\n",
    "                axis=0,\n",
    "            )\n",
    "            left_pod = np.concatenate(\n",
    "                (\n",
    "                    get_image(group[group['camera_location'] == 'T13'], collected_on_str),\n",
    "                    get_image(group[group['camera_location'] == 'T14'], collected_on_str),\n",
    "#                     get_image(group[group['camera_location'] == 'T15'], collected_on_str),\n",
    "#                     get_image(group[group['camera_location'] == 'T16'], collected_on_str),\n",
    "                ),\n",
    "                axis=0,\n",
    "            )\n",
    "            all_cameras = np.concatenate((front_pod, right_pod, rear_pod, left_pod), axis=1)\n",
    "            cv2.putText(all_cameras, \"FRBL\" + collected_on_str, (20, 40), cv2.FONT_HERSHEY_PLAIN, 3, (0,0,0), 2)\n",
    "            all_cameras = all_cameras[:,:,::-1]\n",
    "            # save concatenated image file\n",
    "            full_img_name = f\"{collected_on_str}.png\"\n",
    "            file_path = os.path.join(video_dir, full_img_name)\n",
    "            cv2.imwrite(file_path, all_cameras)\n",
    "\n",
    "            all_cameras = all_cameras[:(all_cameras.shape[0] - (all_cameras.shape[0] % 16)),:(all_cameras.shape[1] - (all_cameras.shape[1] % 16))]\n",
    "            writer.append_data(all_cameras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_runs = merged_runs[~merged_runs['artifact_debayeredrgb_0_image'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Create all of the videos\n",
    "# from tqdm import tqdm\n",
    "# for i in tqdm(range(20, 1 + total_sequences)):\n",
    "#     video_dir = Path(data_path) / str(i)\n",
    "#     os.makedirs(video_dir, exist_ok=True)\n",
    "#     base_df = merged_runs[merged_runs['run_id'] == i]\n",
    "#     create_video_frames(video_dir, base_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time cutoffs such that the video shows one pass of the vehicle moving forwards.\n",
    "# 'L', 'B', 'R' # left, back, right - for choosing which pod(s) to keep\n",
    "# Remove any time that the vehicle is lingering/ not moving\n",
    "# All found by hand via observation of the downloaded videos\n",
    "from typing import Dict, List, Tuple\n",
    "cutoff_dict: Dict[int, List[Tuple[str, str, str]]] = {\n",
    "    # White SUV\n",
    "    1: [], # For some reason there is just 1 frame even though it's repeated many times\n",
    "    3: [('21:28:03', '21:28:16', 'BL')],\n",
    "    4: [('00:00:00', '21:59:59', 'B'), ('21:31:31', '23:59:59', 'L')],\n",
    "    5: [],\n",
    "    7: [('00:00:00', '21:41:25', 'RB')],\n",
    "    # GATOR TIME\n",
    "    8: [('00:00:00', '23:59:59', 'RB')],\n",
    "    9: [('00:00:00', '23:59:59', 'RB')],\n",
    "    10: [('00:00:00', '23:59:59', 'RB')],\n",
    "    12: [('00:00:00', '22:13:40', 'RB')],\n",
    "    14: [('00:00:00', '23:59:59', 'RB')],\n",
    "    15: [('00:00:00', '23:59:59', 'RB')],\n",
    "    16: [('00:00:00', '23:59:59', 'RB')],\n",
    "    19:  [('00:00:00', '20:08:07', 'B'), ('20:08:07', '23:59:59', 'BL')],\n",
    "    20:  [('00:00:00', '23:59:59', 'B')],\n",
    "    22:  [('00:00:00', '20:22:48', 'BL')],\n",
    "    23:  [],\n",
    "    24:  [('00:00:00', '20:35:05', 'B'), ('20:35:05', '23:59:59', 'BL')],\n",
    "    26:  [('00:00:00', '20:41:19', 'B'), ('20:41:19', '23:59:59', 'BL')],\n",
    "    27:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    28:  [('00:00:00', '20:42:16', 'B'), ('20:42:16', '23:59:59', 'BL')],\n",
    "    30:  [('00:00:00', '20:48:15', 'B'), ('20:48:15', '23:59:59', 'BL')],\n",
    "    31:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    32:  [('00:00:00', '23:59:50', 'B'), ('20:59:50', '23:59:59', 'BL')],\n",
    "    33: [],\n",
    "    34: [],\n",
    "    35: [],\n",
    "    36: [],\n",
    "    37: [('00:00:00', '23:59:59', 'BR')],\n",
    "    38: [('00:00:00', '23:59:59', 'BR')],\n",
    "    41: [('00:00:00', '23:59:59', 'BR')],\n",
    "    42: [('00:00:00', '23:59:59', 'BR')],\n",
    "    43: [('00:00:00', '00:12:00', 'BR')],\n",
    "    44: [('00:00:00', '23:59:59', 'BL')],\n",
    "    45:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    46:  [], # could be good but the vehicle does not move\n",
    "    48:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    49:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    50:  [('00:27:30', '23:59:59', 'BL')],\n",
    "    51:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    52:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    53:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    54: [],\n",
    "    55: [('00:00:00', '23:59:59', 'BL')],\n",
    "    56: [('01:09:15', '23:59:59', 'BL')],\n",
    "    57: [],\n",
    "    58: [('01:09:56', '23:59:59', 'BL')],\n",
    "    60: [('00:00:00', '23:59:59', 'BL')], # really hard to see!\n",
    "    61: [],\n",
    "    62: [('00:00:00', '01:16:09', 'B'), ('01:16:09', '23:59:59', 'BL')],\n",
    "    63: [],\n",
    "    64: [('00:00:00', '23:59:59', 'BL')],\n",
    "    66: [('00:00:00', '23:59:59', 'BL')],\n",
    "    67: [],\n",
    "    68: [('00:00:00', '23:59:59', 'BL')],\n",
    "    69: [('00:00:00', '23:59:59', 'BL')],\n",
    "    70: [('01:30:14','23:59:59', 'BL')],\n",
    "    71: [('00:00:00', '23:59:59', 'BL')],\n",
    "    72: [('00:00:00', '23:59:59', 'BL')],\n",
    "    73: [],\n",
    "    75: [('01:32:10', '23:59:59', 'BL')],\n",
    "    76: [],\n",
    "    77: [('00:00:00', '23:59:59', 'BL')],\n",
    "    78: [('00:00:00', '23:59:59', 'BL')],\n",
    "    79: [('00:00:00', '23:59:59', 'BL')],\n",
    "    80: [('00:00:00', '23:59:59', 'BL')],\n",
    "    81: [('00:00:00', '23:59:59', 'BL')],\n",
    "    82: [('00:00:00', '23:59:59', 'BL')],\n",
    "    83: [('01:40:33', '23:59:59', 'BL')],\n",
    "    84: [('01:45:14', '23:59:59', 'BL')],\n",
    "    85: [('00:00:00', '23:59:59', 'BL')],\n",
    "    86: [('00:00:00', '23:59:59', 'BL')],\n",
    "    88: [('00:00:00', '23:59:59', 'BL')],\n",
    "    89: [('00:00:00', '23:59:59', 'RB')],\n",
    "    90: [('00:00:00', '23:59:59', 'RB')],\n",
    "}\n",
    "vehicle_test_set = {\n",
    "    2: [('00:00:00', '23:59:59', 'BL')],\n",
    "    6: [('00:00:00', '23:59:59', 'FR')],\n",
    "    11: [('00:00:00', '23:59:59', 'BL')],\n",
    "    12: [('22:13:40',  '23:59:59', 'RB')],\n",
    "    13: [('00:00:00', '23:59:59', 'RB')],\n",
    "    17: [('00:00:00', '23:59:59', 'BL')],\n",
    "    18: [('00:00:00', '23:59:59', 'BL')],\n",
    "    21:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    25:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    29:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    33:  [('00:00:00', '23:59:59', 'BL')],\n",
    "    39: [('00:10:40', '23:59:59', 'R')],\n",
    "    40: [('00:00:00', '23:59:59', 'BR')],\n",
    "    47: [('00:24:55', '23:59:59', 'B')],\n",
    "    54: [('01:08:35', '23:59:59', 'B')],\n",
    "    59: [('00:00:00', '23:59:59', 'BL')],\n",
    "    65: [('00:00:00', '23:59:59', 'BL')],\n",
    "    74: [('00:00:00', '23:59:59', 'BL')],\n",
    "    87: [('00:00:00', '01:46:55', 'BL')],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def filter_movie(movie, start_t, end_t, cam_loc):\n",
    "    cam_locs = []\n",
    "    if 'L' in cam_loc:\n",
    "        cam_locs.append('left')\n",
    "    if 'B' in cam_loc:\n",
    "        cam_locs.append('rear')\n",
    "    if 'R' in cam_loc:\n",
    "        cam_locs.append('right')\n",
    "    if 'F' in cam_loc:\n",
    "        cam_locs.append('front')\n",
    "\n",
    "    timestamp = movie.iloc[0]['collected_on']\n",
    "    s_hour, s_minute, s_second = map(int, start_t.split(':'))\n",
    "    e_hour, e_minute, e_second = map(int, end_t.split(':'))\n",
    "    y, m, d = timestamp.year, timestamp.month, timestamp.day\n",
    "    tzinfo = movie['collected_on'].iloc[0].tzinfo\n",
    "    start_dt = datetime(y, m, d, s_hour, s_minute, s_second, tzinfo=tzinfo)\n",
    "    end_dt = datetime(y, m, d, e_hour, e_minute, e_second, tzinfo=tzinfo)\n",
    "    return movie[(start_dt < movie['collected_on']) & (movie['collected_on'] < end_dt) & (movie['camera_area'].isin(cam_locs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_runs_from_dict(cutoff_dict):\n",
    "    cleaned_runs = []\n",
    "    n_runs = 0\n",
    "    for run_id in range(1, 1 + total_sequences):\n",
    "        sequence = merged_runs[merged_runs['run_id'] == run_id]\n",
    "        if run_id in cutoff_dict:\n",
    "            times = cutoff_dict[run_id]\n",
    "            if len(times):\n",
    "                n_runs += 1\n",
    "            for start_t, end_t, cam_locs in times:\n",
    "                filtered = filter_movie(sequence, start_t, end_t, cam_locs)\n",
    "                if not len(filtered):\n",
    "                    print(run_id, start_t, end_t, cam_locs) # oops\n",
    "                cleaned_runs.append(filtered)\n",
    "    cleaned_df = pd.concat(cleaned_runs, keys=list(range(len(cleaned_runs)))).drop_duplicates(['id', 'camera_location'])\n",
    "    print(f\"Total runs: {n_runs} Total images {len(cleaned_df)}\")\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs: 19 Total images 3291\n",
      "1641\n"
     ]
    }
   ],
   "source": [
    "HALO_LEFT_CAMS = ['T01', 'T02', 'T05','T06','T09','T10','T13','T14']\n",
    "for_vehicle_test_set = gather_runs_from_dict(vehicle_test_set)\n",
    "for_vehicle_test_set = for_vehicle_test_set[for_vehicle_test_set.camera_location.isin(HALO_LEFT_CAMS)]\n",
    "print(len(for_vehicle_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for_vehicle_test_set['second'] = for_vehicle_test_set.collected_on.dt.strftime('%Y-%m-%d%H:%M:%S')\n",
    "# for_vehicle_test_set = for_vehicle_test_set.drop_duplicates(['second', 'camera_location'])\n",
    "# print(len(for_vehicle_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs: 59 Total images 15187\n",
      "7598\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = gather_runs_from_dict(cutoff_dict)\n",
    "cleaned_df = cleaned_df[cleaned_df.camera_location.isin(HALO_LEFT_CAMS)]\n",
    "print(len(cleaned_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['65e9ca5ff66412769e139957', '65e9c83a5e301af12dab16b0', '65e9c83b60509af006f79919', '65e9c837042072f9d621e8e4', '65e9c8388e6451f92fda37fc']\n"
     ]
    }
   ],
   "source": [
    "image_ids = list(cleaned_df['id'])\n",
    "print(image_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.create(name= \"halo_vehicles_driving_through_dust_images_nodust_reserved\",\n",
    "    description=\"left images for 59 sequences of halo data where a vehicle drives through dust, starting from behind the tractor and ending up on the side of it.\",\n",
    "    kind=Dataset.KIND_IMAGE,\n",
    "    image_ids=image_ids\n",
    ")\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m2024-03-12 08:23:15,947 - APIRequestor - ERROR - Warning: It looks like your installed version of the\n",
      "                    \"requests\" library is not compatible with brtdevkit's\n",
      "                    usage thereof. (HINT: The most likely cause is that\n",
      "                    your \"requests\" library is out of date. You can fix\n",
      "                    that by running \"pip install -U requests\".)\n",
      "\u001b[0mERROR:APIRequestor:Warning: It looks like your installed version of the\n",
      "                    \"requests\" library is not compatible with brtdevkit's\n",
      "                    usage thereof. (HINT: The most likely cause is that\n",
      "                    your \"requests\" library is out of date. You can fix\n",
      "                    that by running \"pip install -U requests\".)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type Series is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhalo_vehicles_test_set_originally_from_dust_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft images of vehicles driving in mildly/not at all dusty conditions reserved for the vehicle test set\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKIND_IMAGE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfor_vehicle_test_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/brtdevkit/core/api/swagger.py:136\u001b[0m, in \u001b[0;36minclude_docs.<locals>.wrap.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/brtdevkit/core/api/resources/abstract/createable_api_resource.py:37\u001b[0m, in \u001b[0;36mCreateableAPIResource.create\u001b[0;34m(cls, **params)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m        params (dict) : any extra parameters\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m        APIObject\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mENDPOINT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(response\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/brtdevkit/core/api/resources/abstract/api_resource.py:15\u001b[0m, in \u001b[0;36mAPIResource.request\u001b[0;34m(method, url, params, headers)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(method, url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# TODO (eric): APIRequestor might work better as a util function, rather than an object\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     requestor \u001b[38;5;241m=\u001b[39m APIRequestor()\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/brtdevkit/core/api/api_requestor.py:47\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, format)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    Makes an API call for the given url. converts response object to APIResource.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m        Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m            resp (APIResponse) : APIResponse object\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     rbody, rcode, rheaders \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpret_response(rbody, rcode, rheaders, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/brtdevkit/core/api/api_requestor.py:201\u001b[0m, in \u001b[0;36mAPIRequestor.request_with_retries\u001b[0;34m(self, method, url, params, supplied_headers)\u001b[0m\n\u001b[1;32m    198\u001b[0m retry_sleep_time \u001b[38;5;241m=\u001b[39m retry_sleep_time_base \u001b[38;5;241m*\u001b[39m exponential_backoff_base \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m attempt \\\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attempt \u001b[38;5;241m<\u001b[39m brtdevkit\u001b[38;5;241m.\u001b[39mmax_network_retries \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     rbody, rcode, rheaders \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent, response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mheaders\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/brtdevkit/core/api/http_client.py:23\u001b[0m, in \u001b[0;36mHTTPClient.request\u001b[0;34m(self, method, url, headers, post_data, stream, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_local, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_local\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session \u001b[38;5;129;01mor\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mSession()\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thread_local\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/requests/sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[1;32m    564\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m    565\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    579\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    580\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    581\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/requests/sessions.py:486\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    483\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    485\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 486\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/requests/models.py:371\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_auth(auth, url)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Note that prepare_auth must be last to enable authentication schemes\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# such as OAuth to work on a fully prepared request.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# This MUST go after prepare_auth. Authenticators could add a hook\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/site-packages/requests/models.py:511\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_body\u001b[0;34m(self, data, files, json)\u001b[0m\n\u001b[1;32m    508\u001b[0m content_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidJSONError(ve, request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/json/__init__.py:234\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvml/lib/python3.8/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Series is not JSON serializable"
     ]
    }
   ],
   "source": [
    "Dataset.create(name= \"halo_vehicles_test_set_originally_from_dust_dataset\",\n",
    "    description=\"left images of vehicles driving in mildly/not at all dusty conditions reserved for the vehicle test set\",\n",
    "    kind=Dataset.KIND_IMAGE,\n",
    "    image_ids=for_vehicle_test_set['id']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
