{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/alexli/git/JupiterScripts/apps/embedded_metrics')\n",
    "\n",
    "%matplotlib inline\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from metrics.generic_metrics import get_runs, get_window_df, get_recall_at_dust\n",
    "from metrics.embedded_product_metrics_config import EmbeddedProductMetricsConfig as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPUTE_DUST_THRESHOLD = (os.environ['COMPUTE_DUST_THRESHOLD'].lower() == 'true') if 'COMPUTE_DUST_THRESHOLD' in os.environ else False\n",
    "RUN_LEVEL_ANALYSIS = (os.environ['RUN_LEVEL_ANALYSIS'].lower() == 'true') if 'RUN_LEVEL_ANALYSIS' in os.environ else False\n",
    "if 'EMBEDDED_RESULTS_DIR' in os.environ:\n",
    "    EMBEDDED_RESULTS_DIR = os.environ['EMBEDDED_RESULTS_DIR']\n",
    "else:\n",
    "    EMBEDDED_RESULTS_DIR = '/metrics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/home/alexli/logs/summary_1_2_5.csv'\n",
    "if os.path.exists(my_path):\n",
    "    df = pd.read_csv(my_path)\n",
    "    RUN_LEVEL_ANALYSIS = True\n",
    "    COMPUTE_DUST_THRESHOLD = True\n",
    "    df_orig = df.copy()\n",
    "# The original dust dataset. To ensure that the data does not drift too much in difficulty, we want the average the dust level across runs to be close to the average dust level of this dataset\n",
    "runs = get_runs(df)\n",
    "runs = [r for r in runs if np.mean(r['dust_percent']) > 0 and len(r) > 2]\n",
    "good_dust_distribution_data = pd.concat([r for r in runs if (('2023-03-29' < r.iloc[0]['collected_on'])  & (r.iloc[0]['collected_on'] < '2023-04-06'))])\n",
    "if len(good_dust_distribution_data):\n",
    "    all_dust_distribution_data = pd.concat(runs)\n",
    "    # We would like to have an average dust level 'close' to this, let's define it as being in the interval [min_required_dust_percent, max_required_dust_percent]\n",
    "    min_required_dust_percent = min(np.percentile(good_dust_distribution_data['dust_percent'], 40), np.mean(good_dust_distribution_data['dust_percent']) * .95)\n",
    "    max_required_dust_percent = max(np.percentile(good_dust_distribution_data['dust_percent'], 60), np.mean(good_dust_distribution_data['dust_percent']) * 1.05)\n",
    "    print(min_required_dust_percent)\n",
    "    print(max_required_dust_percent) # We don't enforce max ATP\n",
    "\n",
    "    # np.percentile(good_dust_distribution_data['dust_percent'], 30)\n",
    "    runs_sorted = sorted(runs, key=lambda r: np.mean(r['dust_percent']))\n",
    "    all_dust_distribution_data = pd.concat(runs_sorted)\n",
    "    while np.mean(all_dust_distribution_data['dust_percent']) <= min_required_dust_percent:\n",
    "        all_dust_distribution_data = pd.concat(runs_sorted)\n",
    "        droppable_runs = np.sum(np.array([[np.mean(r['dust_percent']) < min_required_dust_percent] for r in runs_sorted]))\n",
    "        to_drop_ind = int(np.random.triangular(0, 0, droppable_runs - 1e-6))\n",
    "        runs_sorted.pop(to_drop_ind)\n",
    "    ok_images = pd.concat(runs_sorted)\n",
    "    print(np.mean(ok_images['dust_percent']))\n",
    "df = df[df['id'].isin(ok_images['id'])]\n",
    "print(\"Updated DF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataset\n",
    "imageids_to_dataset(df['id'], dataset_name=f'vehicles_driving_through_dust_1_2_5_hard ({len(df[\"id\"])} images)',\n",
    "                    dataset_description=\"Vehicles driving through dust behind the tractor\",\n",
    "                    dataset_kind='annotation', production_dataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_DUST_THRESHOLD:\n",
    "    if max(df['dust_percent']) == 0:\n",
    "        print(\"Possible error in publishing dust percent, all values are 0\")\n",
    "    # plt.show()\n",
    "    def plot_recall_at_dust_hist(df, ax, subset):\n",
    "        bins = np.arange(0, np.max(df['dust_percent']) + .01, 2.5)\n",
    "        ax.hist(df[df[config.PREDICTED_ANY_STOP_CLASS] & df[config.LABEL_ANY_STOP_CLASS]]['dust_percent'], bins=bins, alpha=.7, label='tp', color='blue')\n",
    "        ax.hist(df[(~df[config.PREDICTED_ANY_STOP_CLASS]) & df[config.LABEL_ANY_STOP_CLASS]]['dust_percent'], bins=bins, alpha=.6, label='fn', color='orange')\n",
    "        ax.set_title(f\"Recall at different dust ratios ({subset})\")\n",
    "        ax.set_xlabel(\"Dust Level\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.legend()\n",
    "    def plot_recall_at_dust_threshold(df, ax, subset):\n",
    "        at_dust = get_recall_at_dust(df)\n",
    "        if subset == 'Overall':\n",
    "            print(f\"Based on the overall metrics, the recommended dust threshold is {at_dust['recommended_thresh']}\")\n",
    "        ax.fill_between(at_dust['dust_ratio'], [p['low'] for p in at_dust['tp_rate']], [p['high'] for p in at_dust['tp_rate']], facecolor='lightskyblue')\n",
    "        ax.hlines([.7, .8, .9], 0, 26, linestyles='dotted')\n",
    "        ax.vlines([0, 5, 10, 15, 20, 25], 0, 1, linestyles='dotted')\n",
    "        ax.scatter(at_dust['dust_ratio'], [p['val'] for p in at_dust['tp_rate']], color='b')\n",
    "        ax.set_title(f\"Recall at different dust ratios ({subset})\")\n",
    "        ax.set_xlabel(\"Dust ratio (%)\")\n",
    "        ax.set_ylabel(\"Recall: On images with dust ~ratio between 0 and dust_ratio (90% ci)\")\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, squeeze=False, figsize=(20, 18))\n",
    "    plot_recall_at_dust_hist(df, axs[0][0], 'Overall')\n",
    "    plot_recall_at_dust_threshold(df, axs[0][1], 'Overall')\n",
    "    plot_recall_at_dust_by_collection(df, axs[0][2])\n",
    "    times = ['daytime', 'dawn_dusk', 'nightime']\n",
    "    for i in range(len(times)):\n",
    "        plot_recall_at_dust_hist(df[df['operation_time'] == times[i]], axs[1][i], times[i])\n",
    "        plot_recall_at_dust_threshold(df[df['operation_time'] == times[i]], axs[2][i], times[i])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_and_cumulative(points, title, xlabel, ax):\n",
    "    # plt.figure(1, figsize=(8, 4))\n",
    "    bins = [0,0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,4.99, 6]\n",
    "    ax.hist(points, bins=bins)\n",
    "    values, base = np.histogram(points, bins=bins)\n",
    "    #evaluate the cumulative\n",
    "    cumulative = np.cumsum(values)\n",
    "    cum_x = [x + .1 for x in bins[1:]]\n",
    "    # plot the cumulative function\n",
    "    ax.plot(cum_x, cumulative, c='blue')\n",
    "    ax.scatter(cum_x, cumulative)\n",
    "    for b,c in zip(base[:-1], cumulative):\n",
    "        ax.annotate(f'{c/cumulative[-1]*100:.0f}%', (b+0.35,c-1))\n",
    "    ax.set_title(title, fontsize=15)\n",
    "    ax.set_xlabel(xlabel, fontsize=15)\n",
    "    ax.set_ylabel('Count', fontsize=15)\n",
    "    ax.set_xticks(bins) \n",
    "    ylim = cumulative[-1]\n",
    "    ax.set_ylim([0, ylim * 1.05])\n",
    "    ax.vlines([2, 4], 0, ylim, linestyles='dotted')\n",
    "\n",
    "if RUN_LEVEL_ANALYSIS:\n",
    "    runs = get_runs(df)\n",
    "    \n",
    "    all_windows = [get_window_df(run, 5) for run in runs]\n",
    "    sliding_window_df = pd.concat(all_windows)\n",
    "    all_windows_full = [get_window_df(run, window_size_seconds='full') for run in runs]\n",
    "    all_windows_full = [w for w in all_windows_full if len(w) > 0]\n",
    "    full_run_df = pd.concat(all_windows_full)\n",
    "\n",
    "    # Plot histograms with cumulative distribution of detections as time passes\n",
    "    fig, axarr = plt.subplots(2, 3, figsize=(23, 13))\n",
    "    fig.suptitle(\"Time to see vehicle driving by in dusty conditions\")\n",
    "    for ind, op_time in enumerate(['daytime', 'dawn_dusk', 'nightime']):\n",
    "        window = sliding_window_df[sliding_window_df['operation_time'] == op_time]\n",
    "        if not len(window):\n",
    "            continue\n",
    "        title = f'{op_time}'\n",
    "        xlabel = 'Avg delta_t'\n",
    "        plot_histogram_and_cumulative(window['avg_delta_t'], title, xlabel, axarr[0][ind])\n",
    "\n",
    "        title = f'{op_time}'\n",
    "        xlabel = 'Max delta_t'\n",
    "        plot_histogram_and_cumulative(window['max_delta_t'], title, xlabel, axarr[1][ind])\n",
    "    fig.show()\n",
    "\n",
    "    # Plot scatter with dust level vs time to get a detection\n",
    "    fig, axarr = plt.subplots(1, 3, figsize=(23, 13))\n",
    "    fig.suptitle(\"Dust level vs time it took to predict a stop\")\n",
    "\n",
    "    xlim = max(5, max(full_run_df['max_delta_t']))\n",
    "    ylim = max(max(full_run_df['avg_dust_level']), max(sliding_window_df['avg_dust_level']))\n",
    "    for ind, op_time in enumerate(['daytime', 'dawn_dusk', 'nightime']):\n",
    "        ax = axarr[ind]\n",
    "        window_5s = sliding_window_df[sliding_window_df['operation_time'] == op_time]\n",
    "        window_full = full_run_df[full_run_df['operation_time'] == op_time]\n",
    "        if not len(window_full):\n",
    "            continue\n",
    "        ax.scatter(window_full['max_delta_t'], window_full['avg_dust_level'], c='red', label='entire_sequence')\n",
    "        ax.scatter(window_5s['max_delta_t'], window_5s['avg_dust_level'], label='5s windows')\n",
    "        ax.set_title(f'Average dust ratio vs. maximum delta_t at {op_time}', fontsize=15)\n",
    "        ax.set_xlabel(f'Max delta_t between two TPs (s)', fontsize=15)\n",
    "        ax.set_ylabel('Avg dust ratio', fontsize=15)\n",
    "        ax.set_xlim([0, xlim])\n",
    "        ax.set_ylim([0, ylim])\n",
    "        ax.legend()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_run(run: pd.DataFrame, ax, ind) -> None:\n",
    "    \"\"\"Plot the detections for one sequence of video images\n",
    "\n",
    "    Args:\n",
    "        run: A df with at least the columns\n",
    "            - camera_location, predicted_stop, label_stop, dust_percent (same meaning as elsewhere)\n",
    "            and \n",
    "            - collected_on_dt: The datetime that this run was collected, to be plotted on the x axis\n",
    "    \"\"\"\n",
    "    start_t = run.iloc[0]['collected_on_dt']\n",
    "    ax.set_title(f\"Dust level vs time it took to predict a stop ({run.iloc[0]['operation_time']} {ind})\")\n",
    "\n",
    "    def seconds_since_start(datetime):\n",
    "        return float((datetime - start_t).total_seconds())\n",
    "\n",
    "    for cam_desc, cam_array in zip(('rear', 'rear-side'), (['rear-left', 'rear-right'], ['side-left-left', 'side-right-left', 'side-left-right', 'side-right-right'])):\n",
    "        for label_stop, predicted_stop, error_type in (\n",
    "            (False, False, 'tn'),\n",
    "            (True, False, 'fn'),\n",
    "            (False, True, 'fp'),\n",
    "            (True, True, 'tp')):\n",
    "            run_subset = run.loc[run['camera_location'].isin(cam_array) & (run[config.PREDICTED_ANY_STOP_CLASS] == predicted_stop) & (run[config.LABEL_ANY_STOP_CLASS] == label_stop)]\n",
    "            # Really hard to choose a color scheme because green/red=stop and also green/red=right/wrong.\n",
    "            # If you try to mix the marker I think it's even more confusing, so just use that to indicate camera\n",
    "            marker = 'o' if cam_desc == 'rear' else '+'\n",
    "\n",
    "            if label_stop: # Darker colors\n",
    "                if predicted_stop:\n",
    "                    color = 'blue'\n",
    "                else:\n",
    "                    color = 'crimson' # Color of blood because u crash\n",
    "            else: # lighter colors as they are less important\n",
    "                if predicted_stop:\n",
    "                    color = 'papayawhip'\n",
    "                else:\n",
    "                    color = 'lightgray'\n",
    "            x = run_subset['collected_on_dt'].apply(seconds_since_start)\n",
    "            if len(x):\n",
    "                ax.scatter(x, run_subset['dust_percent'], label=f'{cam_desc} {error_type}', color=color, marker=marker)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Time (seconds since start)\")\n",
    "    ax.set_ylabel(\"Dust level (%)\")\n",
    "    ax.set_ylim([0, 100])\n",
    "\n",
    "if RUN_LEVEL_ANALYSIS:\n",
    "    to_plot = []\n",
    "    for i in range(len(all_windows_full)):\n",
    "        window = all_windows_full[i].iloc[0]\n",
    "        if window['max_delta_t'] - window['max_delta_t_gt'] >= 3:\n",
    "            to_plot.append((runs[i].iloc[0]['collected_on_dt'].strftime('%Y-%m-%d %H:%M:%S'), runs[i]))\n",
    "    if len(to_plot):\n",
    "        print(\"Plot sequence detections for runs with a period of no detections 3s or more longer than ground truth.\")\n",
    "        fig, axarr = plt.subplots(len(to_plot), figsize=(13, 6 * len(to_plot)), squeeze=False)\n",
    "        for i, (ind, run) in enumerate(to_plot):\n",
    "            axarr[i][0].clear()\n",
    "            plot_one_run(run, axarr[i][0], ind)\n",
    "            run_fns = run[(~run[config.PREDICTED_ANY_STOP_CLASS]) & run[config.LABEL_ANY_STOP_CLASS]]\n",
    "            print(f\"False negatives for run starting at {ind}\")\n",
    "            print(\",\".join(list(run_fns['id'])))\n",
    "        print(\"You can view all failed images at https://www.aletheiav2.prod.mesa.brtws.com/images?project_name=jupiter\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
