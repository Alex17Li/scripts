{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc6fd89-d6ab-4190-95ca-8f00178f1dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex.li/.conda/envs/cvml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "import datetime\n",
    "import io\n",
    "from collections import defaultdict\n",
    "\n",
    "import imageio\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from brtdevkit.core.db.athena import AthenaClient\n",
    "from brtdevkit.data import Dataset\n",
    "from timezonefinder import TimezoneFinderL\n",
    "import pytz\n",
    "\n",
    "from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataset\n",
    "from aletheia_dataset_creator.config.dataset_config import LEFT_CAMERAS, ALL_CAMERA_PAIRS_LIST\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56268454-b2e4-455a-a8ab-e601f2f34b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802b51a2-f2ff-410f-8500-1588a154e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "athena = AthenaClient()\n",
    "s3 = boto3.resource('s3')\n",
    "tf = TimezoneFinderL()\n",
    "home = os.path.expanduser('~')\n",
    "data_path = home + '/data/get_dust_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2626b0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jupiter_prod'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv('AWS_PROFILE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aff9d65-b0df-47a4-a6b1-c69128415df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibration(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return {}   \n",
    "def get_adjusted_timezone(timestamp, latitude, longitude):\n",
    "    if (latitude == 0) or (longitude == 0):\n",
    "        return np.nan\n",
    "    \n",
    "    if isinstance(timestamp, np.datetime64):\n",
    "        timestamp = pd.to_datetime(timestamp)\n",
    "    # Localize and adjust UTC timestamps to local timezone\n",
    "    utc = pytz.utc.localize(timestamp)\n",
    "    tz = tf.timezone_at(lat=latitude, lng=longitude)\n",
    "    adjusted_timestamp = utc.astimezone(tz).to_pydatetime()\n",
    "\n",
    "    return adjusted_timestamp\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "731129f1-4e20-47eb-b70e-67c07c3f8ddb",
   "metadata": {},
   "source": [
    "# Selecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c493de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file not found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    halo_df = pd.read_parquet(data_path + '/hh_df.parquet')\n",
    "except FileNotFoundError:\n",
    "    print(\"file not found\")\n",
    "    query = f\"\"\"\n",
    "    SELECT id, hard_drive_name, robot_name, collected_on,\n",
    "        bag_name, operating_field_name, operation_time, latitude, longitude, geohash, camera_location, sensor_type, created_at, \n",
    "        bundle, gps_can_data__json, weather_summary__json, group_id\n",
    "    FROM image_jupiter \n",
    "    WHERE LENGTH(robot_name) = 14 AND robot_name LIKE 'hitchhiker_1%'\n",
    "    \"\"\"\n",
    "#--AND camera_location IN {left_tractor_cameras}\n",
    "    start = time.time()\n",
    "    halo_df = athena.get_df(query)\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    halo_df.to_parquet(data_path + '/hh_df.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1339330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"SELECT id, hard_drive_name, robot_name, collected_on,\n",
    "#     bag_name, operating_field_name, operation_time, latitude, longitude, geohash, camera_location, sensor_type, created_at, \n",
    "#     bundle, gps_can_data__json, weather_summary__json, group_id\n",
    "# FROM image_jupiter \n",
    "# WHERE \"hard_drive_name\" IN ('JUPD-172_2023-6-28', 'JUPD-173_2023-6-28', 'JUPD-174_2023-6-28')\n",
    "# \"\"\"\n",
    "# start = time.time()\n",
    "# df = athena.get_df(query)\n",
    "# end = time.time()\n",
    "# print(end - start)\n",
    "query1 = f\"\"\"\n",
    "SELECT id, hard_drive_name, robot_name, collected_on,\n",
    "    bag_name, operating_field_name, operation_time, latitude, longitude, geohash, camera_location, sensor_type, created_at, \n",
    "    bundle, gps_can_data__json, weather_summary__json, group_id\n",
    "FROM image_jupiter \n",
    "WHERE robot_name = 'hitchhiker_35' AND \"collected_on\" BETWEEN TIMESTAMP'2022-07-05 10:00:00' AND TIMESTAMP'2022-07-05 23:00:00'\n",
    "\"\"\"\n",
    "df = athena.get_df(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rev1_df = pd.read_parquet(home + '/data/all_hitchiker_images/rev1_df.parquet')\n",
    "except FileNotFoundError:\n",
    "    print(\"file not found\")\n",
    "    query = f\"\"\"\n",
    "    SELECT id, hard_drive_name, robot_name, collected_on,\n",
    "        bag_name, operating_field_name, operation_time, latitude, longitude, geohash, camera_location, sensor_type, created_at, \n",
    "        bundle, gps_can_data__json, weather_summary__json, group_id\n",
    "    FROM image_jupiter \n",
    "    WHERE LENGTH(robot_name) = 9 AND SUBSTR(robot_name, 7, 9) IN ('619', '646', '708', '710', '733', '735', '750', '756', '768', '799', '812', '817', '842', '869', '872', '909') AND \"collected_on\" BETWEEN TIMESTAMP'2023-03-15 0:00:00' AND TIMESTAMP'2023-05-15 0:00:00'\n",
    "    \"\"\"\n",
    "#--AND camera_location IN {left_tractor_cameras}\n",
    "    start = time.time()\n",
    "    rev1_df = athena.get_df(query)\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    rev1_df.to_parquet(data_dir + 'all_hitchiker_images/rev1_df.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb456f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30012, 20)\n",
      "(30012, 20)\n"
     ]
    }
   ],
   "source": [
    "# df = pd.concat([rev1_df, halo_df], ignore_index=True)\n",
    "# print(set(df.camera_location))\n",
    "# # drop invalid GPS\n",
    "# df = df[(df.geohash != '7zzzzzzzzzzz')].copy()\n",
    "# print(set(df.camera_location))\n",
    "print(df.shape)\n",
    "# drop no speed data\n",
    "def valid_speed(x):\n",
    "    load = json.loads(x)\n",
    "    return 'speed' in load and 200 > load['speed'] > -200 #remove NaN or impossible values\n",
    "df = df[df['gps_can_data__json'].apply(valid_speed)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b204e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day(collect_str):\n",
    "    t = pd.Timestamp(collect_str)\n",
    "    return t.strftime(\"%m/%d\")\n",
    "def get_minute(collect_str):\n",
    "    t = pd.Timestamp(collect_str)\n",
    "    return t.strftime(\"%m/%d %H:%M\")\n",
    "\n",
    "df['day'] = df['collected_on'].map(get_day)\n",
    "df['minute'] = df['collected_on'].map(get_minute)\n",
    "df['speed_kph'] = df['gps_can_data__json'].map(lambda x:(json.loads(x)['speed']))\n",
    "# df.to_parquet('/home/alexli/data/all_hitchiker_images/full_df.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(data_path + f'/hhh.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "709265df",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional_dict = {}\n",
    "for pair_dict in ALL_CAMERA_PAIRS_LIST:\n",
    "    for k, v in pair_dict.items():\n",
    "        bidirectional_dict[k] = v\n",
    "        bidirectional_dict[v] = k\n",
    "\n",
    "def make_dataset(from_df, name, description, pairs=[bidirectional_dict]) -> None:\n",
    "    imids = list(from_df['id'])\n",
    "    # print(len(imids))\n",
    "    from_df.to_parquet(data_path + f'/{name}.parquet', index=False)\n",
    "    # desc = f\"{description} ({len(from_df['id'])} images)\"\n",
    "    # imageids_to_dataset_fast(from_df, name, desc,\n",
    "    #                          camera_pairs_list=pairs, camera_pair_df=df)\n",
    "    Dataset.create(\n",
    "        name=name,\n",
    "        description=description,\n",
    "        kind=Dataset.KIND_IMAGE,\n",
    "        image_ids=imids,\n",
    "    )\n",
    "    print(\"k\")\n",
    "\n",
    "def make_dataset_slow(from_df, name, description) -> None:\n",
    "    imids = list(from_df['id'])\n",
    "    desc = f\"{description} ({len(from_df['id'])} images)\"\n",
    "    print(len(imids))\n",
    "    from_df.to_parquet(f'/home/alexli/data/all_hitchiker_images/{name}.parquet', index=False)\n",
    "    imageids_to_dataset(imids, name, dataset_kind='image',\n",
    "                             dataset_description=desc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85f2ab12",
   "metadata": {},
   "source": [
    "# Sample a bunch of random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "217f2a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30012\n"
     ]
    }
   ],
   "source": [
    "df=df.sample(frac=1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f10ae2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13864\n"
     ]
    }
   ],
   "source": [
    "stratified_df = df.groupby(['robot_name', 'camera_location', 'minute']).head(4)\n",
    "print(len(stratified_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c6184b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rear-left',\n",
       " 'rear-right',\n",
       " 'side-left-left',\n",
       " 'side-left-right',\n",
       " 'side-right-left',\n",
       " 'side-right-right'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stratified_df.camera_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified_df_tiny = stratified_df.groupby(['camera_location']).head(1)\n",
    "# make_dataset(stratified_df, \"hhh_field_data_stratified\", description=\"first 3 hard drives from the field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecaa4052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m2023-07-19 13:21:42,710 - APIRequestor - ERROR - API error received | error_code : 400, error_message : {'message': 'Invalid request parameter: Dataset with name: apparent_dusty_day already exists, Dataset kind: image'}\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "{'message': 'Invalid request parameter: Dataset with name: apparent_dusty_day already exists, Dataset kind: image'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# stratified_df_tiny = stratified_df.groupby(['camera_location']).head(1)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m make_dataset(stratified_df, \u001b[39m\"\u001b[39;49m\u001b[39mapparent_dusty_day\u001b[39;49m\u001b[39m\"\u001b[39;49m, description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mImages from one suspicious day\u001b[39;49m\u001b[39m\"\u001b[39;49m, pairs\u001b[39m=\u001b[39;49mALL_CAMERA_PAIRS_LIST)\n\u001b[1;32m      3\u001b[0m \u001b[39m# make_dataset_slow(stratified_df, \"Stratefied \", description=\"test only the left cameras imageids\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDONE MADE DATASET\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 14\u001b[0m, in \u001b[0;36mmake_dataset\u001b[0;34m(from_df, name, description, pairs)\u001b[0m\n\u001b[1;32m     10\u001b[0m from_df\u001b[39m.\u001b[39mto_parquet(data_path \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m.parquet\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[39m# desc = f\"{description} ({len(from_df['id'])} images)\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# imageids_to_dataset_fast(from_df, name, desc,\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m#                          camera_pairs_list=pairs, camera_pair_df=df)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m Dataset\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     15\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m     16\u001b[0m     description\u001b[39m=\u001b[39;49mdescription,\n\u001b[1;32m     17\u001b[0m     kind\u001b[39m=\u001b[39;49mDataset\u001b[39m.\u001b[39;49mKIND_IMAGE,\n\u001b[1;32m     18\u001b[0m     image_ids\u001b[39m=\u001b[39;49mimids,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mk\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cvml/lib/python3.10/site-packages/brtdevkit/core/api/swagger.py:136\u001b[0m, in \u001b[0;36minclude_docs.<locals>.wrap.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/cvml/lib/python3.10/site-packages/brtdevkit/core/api/resources/abstract/createable_api_resource.py:37\u001b[0m, in \u001b[0;36mCreateableAPIResource.create\u001b[0;34m(cls, **params)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m     31\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m        params (dict) : any extra parameters\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m        APIObject\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mENDPOINT, params, headers\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(response\u001b[39m.\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/.conda/envs/cvml/lib/python3.10/site-packages/brtdevkit/core/api/resources/abstract/api_resource.py:15\u001b[0m, in \u001b[0;36mAPIResource.request\u001b[0;34m(method, url, params, headers)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(method, url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m     \u001b[39m# TODO (eric): APIRequestor might work better as a util function, rather than an object\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     requestor \u001b[39m=\u001b[39m APIRequestor()\n\u001b[0;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m requestor\u001b[39m.\u001b[39;49mrequest(method, url, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders)\n",
      "File \u001b[0;32m~/.conda/envs/cvml/lib/python3.10/site-packages/brtdevkit/core/api/api_requestor.py:47\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mMakes an API call for the given url. converts response object to APIResource.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39m        resp (APIResponse) : APIResponse object\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m rbody, rcode, rheaders \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_with_retries(method\u001b[39m.\u001b[39mlower(), url, params, headers)\n\u001b[0;32m---> 47\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpret_response(rbody, rcode, rheaders)\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.conda/envs/cvml/lib/python3.10/site-packages/brtdevkit/core/api/api_requestor.py:263\u001b[0m, in \u001b[0;36mAPIRequestor.interpret_response\u001b[0;34m(self, rbody, rcode, rheaders)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mAPIError(error_data, rbody, rcode, rheaders)\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[0;32m--> 263\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_error_response(rbody, rcode, resp\u001b[39m.\u001b[39;49mdata, rheaders)\n\u001b[1;32m    265\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.conda/envs/cvml/lib/python3.10/site-packages/brtdevkit/core/api/api_requestor.py:72\u001b[0m, in \u001b[0;36mAPIRequestor.handle_error_response\u001b[0;34m(self, rbody, rcode, resp, rheaders)\u001b[0m\n\u001b[1;32m     70\u001b[0m log\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI error received | error_code : \u001b[39m\u001b[39m{\u001b[39;00mrcode\u001b[39m}\u001b[39;00m\u001b[39m, error_message : \u001b[39m\u001b[39m{\u001b[39;00merror_data\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m error_class \u001b[39m=\u001b[39m error\u001b[39m.\u001b[39mSTATUS_CODE_TO_ERROR\u001b[39m.\u001b[39mget(rcode, error\u001b[39m.\u001b[39mAPIError)\n\u001b[0;32m---> 72\u001b[0m \u001b[39mraise\u001b[39;00m error_class(error_data, rbody, rcode, rheaders)\n",
      "\u001b[0;31mBadRequestError\u001b[0m: {'message': 'Invalid request parameter: Dataset with name: apparent_dusty_day already exists, Dataset kind: image'}"
     ]
    }
   ],
   "source": [
    "# stratified_df_tiny = stratified_df.groupby(['camera_location']).head(1)\n",
    "make_dataset(stratified_df, \"apparent_dusty_day\", description=\"Images from one suspicious day\", pairs=ALL_CAMERA_PAIRS_LIST)\n",
    "# make_dataset_slow(stratified_df, \"Stratefied \", description=\"test only the left cameras imageids\")\n",
    "print(\"DONE MADE DATASET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382bc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataframe\n",
    "# from aletheia_dataset_creator.config.dataset_config import ALL_CAMERA_PAIRS_LIST, IMAGE_DATASET_COLS, LEFT_CAMERAS\n",
    "\n",
    "# images = imageids_to_dataframe(\n",
    "#                 stratified_df_tiny, fields=IMAGE_DATASET_COLS, camera_location=LEFT_CAMERAS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185743a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['front-center-left',\n",
       " 'front-left-left',\n",
       " 'front-right-left',\n",
       " 'side-left-left',\n",
       " 'side-right-left',\n",
       " 'rear-left',\n",
       " 'T01',\n",
       " 'T02',\n",
       " 'T05',\n",
       " 'T06',\n",
       " 'T09',\n",
       " 'T10',\n",
       " 'T13',\n",
       " 'T14',\n",
       " 'I01',\n",
       " 'I03',\n",
       " 'I05',\n",
       " 'I07']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEFT_CAMERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f9ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'front-center-left': 'front-center-right',\n",
       "  'front-left-left': 'front-left-right',\n",
       "  'front-right-left': 'front-right-right',\n",
       "  'side-left-left': 'side-left-right',\n",
       "  'side-right-left': 'side-right-right',\n",
       "  'rear-left': 'rear-right',\n",
       "  'front-center-right': 'front-center-left',\n",
       "  'front-left-right': 'front-left-left',\n",
       "  'front-right-right': 'front-right-left',\n",
       "  'side-left-right': 'side-left-left',\n",
       "  'side-right-right': 'side-right-left',\n",
       "  'rear-right': 'rear-left'},\n",
       " {'T01': 'T03',\n",
       "  'T02': 'T04',\n",
       "  'T05': 'T07',\n",
       "  'T06': 'T08',\n",
       "  'T09': 'T11',\n",
       "  'T10': 'T12',\n",
       "  'T13': 'T15',\n",
       "  'T14': 'T16'},\n",
       " {'T02': 'T03', 'T06': 'T07', 'T10': 'T11', 'T14': 'T15'},\n",
       " {'I01': 'I02', 'I03': 'I04', 'I05': 'I06', 'I07': 'I08'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_CAMERA_PAIRS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b16f361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
