{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brtdevkit.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "geohash_df = pd.read_csv(filepath_or_buffer='/data/jupiter/alex.li/20240212_geohash_table_v7_0_rc.csv', index_col=\"Unnamed: 0\")\n",
    "geohash_train_df = geohash_df[geohash_df['bucket'] == 'train']\n",
    "geohash_test_df = geohash_df[geohash_df['bucket'] == 'test']\n",
    "new_geohashes = set()\n",
    "def filter_df(df_orig):\n",
    "    global new_geohashes\n",
    "    df_orig[\"geohash_short\"] = df_orig[\"geohash\"].apply(lambda x: x[:6])\n",
    "    new_geohashes = new_geohashes.union([geohash for geohash in set(df_orig[\"geohash_short\"]) if geohash not in geohash_df.index])\n",
    "    print(f\"Found {len(new_geohashes)} new geohashes\")\n",
    "    df_train = df_orig[df_orig['geohash_short'].isin(geohash_train_df.index)]\n",
    "    df_test = df_orig[df_orig['geohash_short'].isin(geohash_test_df.index)]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m2024-03-18 09:34:22,132 - APIRequestor - ERROR - API error received | error_code : 403, error_message : {'extra': {'role_name': 'token_exchange'}, 'message': 'Role token_exchange is required to make this API call'}\n",
      "\u001b[0mWARNING:root:Failed to refresh AWS Credential\n",
      "WARNING:root:Some functionalities (S3, Athena, etc) not useable {'extra': {'role_name': 'token_exchange'}, 'message': 'Role token_exchange is required to make this API call'}\n"
     ]
    }
   ],
   "source": [
    "dset = Dataset.retrieve(name='labelbox_import_tire_tracks_100k')\n",
    "df = dset.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97036\n",
      "Found 0 new geohashes\n",
      "79854 79854 0\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df['speed'] = df['gps_can_data'].apply(lambda x: x.get('speed', np.nan))\n",
    "df = df[df[\"speed\"] > 0.1]\n",
    "df = df[df[\"speed\"] < 30]\n",
    "df['day'] = pd.to_datetime(df['collected_on']).dt.strftime('%Y-%m-%d')\n",
    "df[\"geohash_8\"] = df[\"geohash\"].apply(lambda x: x[:8])\n",
    "df[\"geohash_7\"] = df[\"geohash\"].apply(lambda x: x[:7])\n",
    "df[\"geohash_6\"] = df[\"geohash\"].apply(lambda x: x[:6])\n",
    "train_df, test_df = filter_df(df)\n",
    "print(len(df), len(train_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39903\n"
     ]
    }
   ],
   "source": [
    "df_diverse = train_df.groupby(['geohash_8', 'day', 'camera_location', 'robot_name']).first()\n",
    "ids = list(df_diverse['id'])\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to unactivate jupyter notebook, switch envs, run jupyter notebook again\n",
    "# !conda activate jupiterdata39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex.li/miniconda3/envs/jupiterdata39/lib/python3.9/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running create dataset with many images, it will take some time, consider using         the Dataset.create API directly or the imageids_df_to_dataset_fast function\n",
      "Preparing stereo dataframe for {'T01': 'T03', 'T02': 'T04', 'T05': 'T07', 'T06': 'T08', 'T09': 'T11', 'T10': 'T12', 'T13': 'T15', 'T14': 'T16', 'I01': 'I03', 'I02': 'I04'}...\n",
      "Size of left dataframe: 39903\n",
      "Size of stereo dataframe: 39749\n",
      "Preparing stereo dataframe for {'T02': 'T03', 'T06': 'T07', 'T10': 'T11', 'T14': 'T15', 'I02': 'I03'}...\n",
      "Size of left dataframe: 22509\n",
      "Size of stereo dataframe: 22439\n",
      "Sending 101455 image ids for creating dataset\n",
      "Time taken to prepare data for dataset creation job: 1.23 mins\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append('/home/alex.li/git/JupiterData')\n",
    "from jupiterdata.config import dataset_config\n",
    "from jupiterdata.utils.dataset import imageids_to_dataset\n",
    "imageids_to_dataset(\n",
    "    ids,\n",
    "    dataset_name=f\"{dset.name}_diverse\",\n",
    "    dataset_description=f\"{dset.description}, choosing one from each day/camera location/robot/geohash to get {len(df_diverse)} left ids\",\n",
    "    dataset_kind = \"image\",\n",
    "    mode = \"stereo\",\n",
    "    annotation_state = dataset_config.VALID_ANNOTATION_STATES,\n",
    "    camera_location = dataset_config.LEFT_CAMERAS,\n",
    "    production_dataset = False,\n",
    "    camera_pairs_list = dataset_config.ALL_CAMERA_PAIRS_LIST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.notebooks.manny.diversify import diversify_dataset\n",
    "# diversify_dataset('labelbox_import_tire_tracks_100k', 30000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
