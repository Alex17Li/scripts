{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from dl.utils.helpers import load_master_csv\n",
    "from dl.dataset.datamodes.npz.rgbd import RGBDNPZ\n",
    "\n",
    "# dataset_path = '/data2/jupiter/datasets/Jupiter_train_v6_2/'\n",
    "# anno_path = 'master_annotations_20231019_clean.csv'\n",
    "dataset_path = '/mnt/datasets/halo_rgb_stereo_train_v6_1/'\n",
    "anno_path = 'master_annotations_1k.csv'\n",
    "df = load_master_csv(dataset_path + anno_path)\n",
    "rgbdnpz = RGBDNPZ(dataset_path)\n",
    "artifacts = rgbdnpz.get_artifacts(df.iloc[0])\n",
    "plt.imshow(artifacts['depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (_, row) in enumerate(df.iterrows()):\n",
    "    artifacts = rgbdnpz.get_artifacts(row)\n",
    "    if np.sum(artifacts['label'] == 11) > 1:\n",
    "        print(i)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl.dataset.datamodes.npz.rgbd import RGBDNPZ\n",
    "\n",
    "rgbdnpz = RGBDNPZ(dataset_path)\n",
    "def viz_some_images(rows):\n",
    "    fig, ax = plt.subplots(len(rows), 2,  figsize=(5,16), squeeze=False)\n",
    "    for i, (_, row) in enumerate(rows.iterrows()):\n",
    "        artifacts = rgbdnpz.get_artifacts(row)\n",
    "        ax[i][0].imshow(artifacts['image'])\n",
    "        ax[i][1].imshow(artifacts['label'] == 11)\n",
    "viz_some_images(df[24:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = artifacts['image']\n",
    "plt.imshow(artifacts['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import grid_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = torch.FloatTensor(list(range(im.shape[0]))) / (.5 * im.shape[0]) - 1\n",
    "yvals =  torch.FloatTensor(list(range(im.shape[1]))) / (.5 * im.shape[1]) - 1\n",
    "im_tensor = torch.Tensor(im)[None, ].permute([0, 3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_row, grid_col = torch.meshgrid(xvals, yvals)\n",
    "grid = torch.stack([grid_col, grid_row], axis=0)[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tensor = grid_sample(im_tensor, grid.permute([0,  2, 3, 1]))\n",
    "out_np = np.array(out_tensor.permute([0, 2, 3, 1])[0])\n",
    "out_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "kernel_size = 10\n",
    "sigma = 8\n",
    "\n",
    "# Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
    "x_cord = torch.arange(kernel_size)\n",
    "x_grid = x_cord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "y_grid = x_grid.t()\n",
    "xy_grid = torch.stack([x_grid, y_grid], dim=-1)\n",
    "\n",
    "mean = (kernel_size - 1)/2.\n",
    "variance = sigma**2.\n",
    "\n",
    "gaussian_kernel = (1./(2.*math.pi*variance)) *\\\n",
    "                  torch.exp(\n",
    "                      -torch.sum((xy_grid - mean)**2., dim=-1) /\\\n",
    "                      (2*variance)\n",
    "                  )\n",
    "# Make sure sum of values in gaussian kernel equals 1.\n",
    "gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "\n",
    "# Reshape to 2d depthwise convolutional weight\n",
    "gaussian_kernel = gaussian_kernel.view(1, kernel_size, kernel_size)\n",
    "gaussian_kernel = torch.nn.Parameter(gaussian_kernel.repeat(1, 1, 1, 1))\n",
    "gaussian_kernel.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency = artifacts['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_torch = torch.Tensor(saliency)[None, None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = torch.FloatTensor(list(range(im.shape[0] // 2))) / (.25 * im.shape[0]) - 1\n",
    "yvals =  torch.FloatTensor(list(range(im.shape[1] // 2))) / (.25 * im.shape[1]) - 1\n",
    "grid_row, grid_col = torch.meshgrid(xvals, yvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 1, kernel_size, bias=False, padding='same', padding_mode='replicate')\n",
    "conv.weight = gaussian_kernel\n",
    "new_grid_num_x = conv.forward(saliency_torch * grid_col)\n",
    "new_grid_num_y = conv.forward(saliency_torch * grid_row)\n",
    "new_grid_denom = conv.forward(saliency_torch)\n",
    "\n",
    "new_grid = torch.concat([new_grid_num_x, new_grid_num_y], dim=1) / new_grid_denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tensor = grid_sample(im_tensor, new_grid.permute([0, 2, 3, 1]))\n",
    "out_np = out_tensor.permute([0, 2, 3, 1])[0].detach().numpy()\n",
    "plt.imshow(out_np)\n",
    "# Looks good but I don't thinks we invert this quickly on onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK let's try a simple, fixed transform. If we fix the transform globally then we should be able to invert it quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonUniformSamplingLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            downsample_rows: int = 32,\n",
    "            downsample_cols: int = 32,\n",
    "            n_row_divisions: int = 16,\n",
    "            n_col_divisions: int = 16,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        assert downsample_rows % n_row_divisions == 0\n",
    "        assert downsample_cols % n_col_divisions == 0\n",
    "        self.row_expand_copies = downsample_rows // n_row_divisions\n",
    "        self.col_expand_copies = downsample_cols // n_col_divisions\n",
    "\n",
    "    def performn_nonuniform_s(self, image: torch.Tensor, saliency: torch.Tensor):\n",
    "        \"\"\"\n",
    "        image shape: [B, C, H, W]\n",
    "        saliency shape: floats with value >0 corresponding to the desired zoom for a tile of the image.\n",
    "        Shape [B, 1, n_row_divisions, n_col_divisions]\n",
    "        \"\"\"\n",
    "        # For simpler computation, we sum the saliency of each row and determine the total size of a row\n",
    "        # proportional to that\n",
    "        x_weights = torch.repeat_interleave(torch.mean(saliency, dim=3), repeats=self.row_expand_copies, dim=2)\n",
    "        y_weights = torch.repeat_interleave(torch.mean(saliency, dim=2), repeats=self.col_expand_copies, dim=2)\n",
    "\n",
    "        # The ouput image coordinate at [r,c] will take the value of the image at [xvals[r], yvals[c]], normalized\n",
    "        # to lie within [-1, 1]\n",
    "        xvals = 2 * torch.cumsum(x_weights, 0) / torch.sum(x_weights) - 1\n",
    "        yvals = 2 * torch.cumsum(y_weights, 0) / torch.sum(y_weights) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_weights = torch.repeat_interleave(torch.mean(saliency_torch_resize, dim=3), repeats=2, dim=2)\n",
    "y_weights = torch.repeat_interleave(torch.mean(saliency_torch_resize, dim=2), repeats=2, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_rows = 32\n",
    "downsample_cols = 32\n",
    "n_row_divisions = 16\n",
    "n_col_divisions = 16\n",
    "x_weight_base_tensor = torch.arange(.1, 1.1, 1 / n_row_divisions)[None, :]\n",
    "y_weight_base_tensor = torch.arange(.1, 1.1, 1 / n_col_divisions)[None, :]\n",
    "print(len(x_weight_base_tensor))\n",
    "x_weights = torch.nn.Parameter(x_weight_base_tensor)\n",
    "y_weights = torch.nn.Parameter(x_weight_base_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = 2 * torch.cumsum(x_weights, 0) / torch.sum(x_weights) - 1\n",
    "yvals = 2 * torch.cumsum(y_weights, 0) / torch.sum(y_weights) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_row, grid_col = torch.meshgrid(xvals[1:-1], yvals[:-1])\n",
    "grid = torch.stack([grid_col, grid_row], axis=0)[None, :]\n",
    "out_tensor = grid_sample(im_tensor, grid.permute([0,  2, 3, 1]))\n",
    "out_np = np.array(out_tensor.permute([0, 2, 3, 1])[0].detach())\n",
    "plt.imshow(out_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_x = torch.arange(-1, 1.0001, 2 / downsample_rows)\n",
    "transformed_y = torch.arange(-1, 1.0001, 2 / downsample_cols)\n",
    "target_orig_x = torch.arange(-1, 1, 2 / im.shape[0])\n",
    "target_orig_y = torch.arange(-1, 1, 2 / im.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals_pad = torch.cat((-torch.ones(1), xvals))\n",
    "yvals_pad = torch.cat((-torch.ones(1), xvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think searchsorted is not available with onnx which is why using global constants will be good\n",
    "x_r_pix = torch.searchsorted(xvals_pad, target_orig_x, side='right')\n",
    "y_r_pix = torch.searchsorted(yvals_pad, target_orig_y, side='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_l_vals = torch.index_select(xvals_pad, 0, x_r_pix - 1)\n",
    "x_r_vals = torch.index_select(xvals_pad, 0, x_r_pix)\n",
    "y_l_vals = torch.index_select(yvals_pad, 0, y_r_pix - 1)\n",
    "y_r_vals = torch.index_select(yvals_pad, 0, y_r_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_l_inds = transformed_x[x_r_pix - 1]\n",
    "x_r_inds = transformed_x[x_r_pix]\n",
    "y_l_inds = transformed_y[y_r_pix - 1]\n",
    "y_r_inds = transformed_y[y_r_pix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inds = torch.lerp(x_l_inds, x_r_inds, (target_orig_x - x_l_vals) / (x_r_vals - x_l_vals))\n",
    "y_inds = torch.lerp(y_l_inds, y_r_inds, (target_orig_y - y_l_vals) / (y_r_vals - y_l_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_row_inv, grid_col_inv = torch.meshgrid(x_inds, y_inds)\n",
    "grid = torch.stack([grid_col_inv, grid_row_inv], axis=0)[None, :]\n",
    "out_tensor_inv = grid_sample(out_tensor, grid.permute([0,  2, 3, 1]))\n",
    "out_inv_np = out_tensor_inv.permute([0, 2, 3, 1])[0].detach().numpy()\n",
    "plt.imshow(out_inv_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
