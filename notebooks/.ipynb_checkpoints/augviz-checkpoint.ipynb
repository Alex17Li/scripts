{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "import datetime\n",
    "from rich.progress import track\n",
    "\n",
    "import io\n",
    "from collections import defaultdict\n",
    "\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from rich.progress import track\n",
    "from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataset\n",
    "from aletheia_dataset_creator.config.dataset_config import LEFT_CAMERAS, ALL_CAMERA_PAIRS_LIST\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import multiprocessing as mp    \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dl.utils.io_utils import normalize_image\n",
    "import imageio\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "from cv.core.image_quality_server_side import ImageQuality\n",
    "\n",
    "# from cv.core.image_quality_server_side_halo import ImageQuality\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "import albumentations as A\n",
    "import random\n",
    "from dl.utils.config import DEFAULT_TONEMAP_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '/data2/jupiter/datasets/halo_rgb_stereo_train_v6_1/'\n",
    "# csv_name = 'master_annotations.csv' \n",
    "directory = '/mnt/datasets/halo_rgb_stereo_train_v6_1/'\n",
    "csv_name = 'master_annotations_10k.csv' \n",
    "\n",
    "from dl.dataset.datamodes.npz.rgbd import RGBDNPZ\n",
    "dataloader = RGBDNPZ(directory)\n",
    "albumentation_transform_path = \"/home/alexli/git/JupiterCVML/kore/configs/data/albumentations/seg_trivialaugment.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135675/3412761839.py:1: DtypeWarning: Columns (25,94,95,96,97,98,100,101,103,104,105,106,107,108,109,110,111,232) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(directory + csv_name)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(directory + csv_name)\n",
    "df = df.drop_duplicates('unique_id')\n",
    "df = df.sample(frac=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_several_images(img_list, titles=None):\n",
    "    cols = 4\n",
    "    rows = (len(img_list) + 3) // cols\n",
    "    fig, ax = plt.subplots(rows, cols, squeeze=False, figsize = (32, rows * 8))\n",
    "    for i, img in enumerate(img_list):\n",
    "        ax[i // cols][i % cols].imshow(img)\n",
    "        if titles is not None:\n",
    "            ax[i // cols][i % cols].set_title(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = []\n",
    "sample_labels = []\n",
    "\n",
    "for i in range(100):\n",
    "    artifacts= dataloader.get_artifacts(df.iloc[i])\n",
    "    im = normalize_image(artifacts['image'], hdr_mode=df.iloc[i]['hdr_mode'])\n",
    "    sample_images.append(im)\n",
    "    sample_labels.append(artifacts['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ruamel.yaml\n",
    "from functools import partial\n",
    "\n",
    "yaml = ruamel.yaml.YAML(typ=\"safe\")\n",
    "def shape_elem_constructor(\n",
    "    index: int, loader: ruamel.yaml.Constructor, node: ruamel.yaml.ScalarNode\n",
    ") -> int:\n",
    "    assert loader.construct_scalar(node) == \"\"\n",
    "    return (512,640)[index]\n",
    "\n",
    "constructor: ruamel.yaml.Constructor = yaml.constructor\n",
    "constructor.add_constructor(\"!height\", partial(shape_elem_constructor, 0))\n",
    "constructor.add_constructor(\"!width\", partial(shape_elem_constructor, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kore.configs.data.custom_augmentations import StableGammaAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135675/4279255430.py:36: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if not np.all(out['mask'] == sample_labels[i]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images in 0.22938203811645508 seconds\n"
     ]
    }
   ],
   "source": [
    "# aug = A.ReplayCompose([\n",
    "#     A.FromFloat(dtype='uint8'),\n",
    "#     StableGammaAugment(\n",
    "#         p=1.0,\n",
    "#     ),\n",
    "#     A.ToFloat(),\n",
    "# ])\n",
    "import time\n",
    "with open(albumentation_transform_path) as f:\n",
    "    aug = yaml.load(f)\n",
    "\n",
    "if isinstance(aug, dict):\n",
    "    aug = A.from_dict(aug)\n",
    "aug_images = []\n",
    "aug_titles = []\n",
    "offset = 0\n",
    "viz = 100\n",
    "st = time.time()\n",
    "for i in range(offset, viz + offset):\n",
    "    out = aug(image=sample_images[i], mask=sample_labels[i])\n",
    "    aug_images.append(sample_images[i])\n",
    "    aug_titles.append('orig')\n",
    "    aug_images.append(out['image']) \n",
    "    if 'replay' in out:\n",
    "        try:\n",
    "            int_transforms = [x for x in out['replay']['transforms'][0]['transforms'][0]['transforms'][1]['transforms'] if x['applied']]\n",
    "            float_transforms = [x  for x in out['replay']['transforms'][0]['transforms'][1]['transforms'] if x['applied']]\n",
    "            applied = (int_transforms + float_transforms)[0]\n",
    "        except KeyError:\n",
    "            applied = out['replay']['transforms'][1]\n",
    "        print(applied['__class_fullname__'] + str(applied['params']))\n",
    "        aug_titles.append(applied['__class_fullname__'])\n",
    "    else:\n",
    "        aug_titles.append(\"aug\")\n",
    "\n",
    "    if not np.all(out['mask'] == sample_labels[i]):\n",
    "        aug_titles.append('orig mask')\n",
    "        aug_images.append(sample_labels[i])\n",
    "        aug_titles.append('aug mask')\n",
    "        aug_images.append(out['mask'])  \n",
    "print(f\"{viz} images in {time.time() - st} seconds\")\n",
    "# plot_several_images(aug_images, aug_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
