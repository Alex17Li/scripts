{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc6fd89-d6ab-4190-95ca-8f00178f1dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex.li/.conda/envs/cvml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import ast\n",
    "import datetime\n",
    "import io\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.dates as mdates\n",
    "import imageio\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from brtdevkit.core.db.athena import AthenaClient\n",
    "from brtdevkit.data import Dataset\n",
    "from timezonefinder import TimezoneFinderL\n",
    "import pytz\n",
    "\n",
    "from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import imageids_to_dataset#, imageids_to_dataset_fast\n",
    "from aletheia_dataset_creator.config.dataset_config import LEFT_CAMERAS, ALL_CAMERA_PAIRS_LIST\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56268454-b2e4-455a-a8ab-e601f2f34b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "802b51a2-f2ff-410f-8500-1588a154e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "athena = AthenaClient()\n",
    "s3 = boto3.resource('s3')\n",
    "tf = TimezoneFinderL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aff9d65-b0df-47a4-a6b1-c69128415df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibration(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return {}   \n",
    "def get_adjusted_timezone(timestamp, latitude, longitude):\n",
    "    if (latitude == 0) or (longitude == 0):\n",
    "        return np.nan\n",
    "    \n",
    "    if isinstance(timestamp, np.datetime64):\n",
    "        timestamp = pd.to_datetime(timestamp)\n",
    "    # Localize and adjust UTC timestamps to local timezone\n",
    "    utc = pytz.utc.localize(timestamp)\n",
    "    tz = tf.timezone_at(lat=latitude, lng=longitude)\n",
    "    adjusted_timestamp = utc.astimezone(tz).to_pydatetime()\n",
    "\n",
    "    return adjusted_timestamp\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "731129f1-4e20-47eb-b70e-67c07c3f8ddb",
   "metadata": {},
   "source": [
    "# Selecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99872467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c493de",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    halo_df = pd.read_parquet(home + '/workspace/hh_df.parquet')\n",
    "except FileNotFoundError:\n",
    "    print(\"file not found\")\n",
    "    query = f\"\"\"\n",
    "    SELECT id, hard_drive_name, robot_name, collected_on,\n",
    "        bag_name, operating_field_name, operation_time, latitude, longitude, geohash, camera_location, sensor_type, created_at, \n",
    "        bundle, gps_can_data__json, weather_summary__json, group_id\n",
    "    FROM image_jupiter \n",
    "    WHERE LENGTH(robot_name) = 14 AND robot_name LIKE 'hitchhiker_1%'\n",
    "    \"\"\"\n",
    "#--AND camera_location IN {left_tractor_cameras}\n",
    "    start = time.time()\n",
    "    halo_df = athena.get_df(query)\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    halo_df.to_parquet(home + '/workspace/hh_df.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3175198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4524864\n"
     ]
    }
   ],
   "source": [
    "print(len(halo_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d5d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     rev1_df = pd.read_parquet('/home/alexli/data/all_hitchiker_images/rev1_df.parquet')\n",
    "# except FileNotFoundError:\n",
    "#     print(\"file not found\")\n",
    "#     query = f\"\"\"\n",
    "#     SELECT id, hard_drive_name, robot_name, collected_on,\n",
    "#         bag_name, operating_field_name, operation_time, latitude, longitude, geohash, camera_location, sensor_type, created_at, \n",
    "#         bundle, gps_can_data__json, weather_summary__json, group_id\n",
    "#     FROM image_jupiter \n",
    "#     WHERE LENGTH(robot_name) = 9 AND SUBSTR(robot_name, 7, 9) IN ('619', '646', '708', '710', '733', '735', '750', '756', '768', '799', '812', '817', '842', '869', '872', '909') AND \"collected_on\" BETWEEN TIMESTAMP'2023-03-15 0:00:00' AND TIMESTAMP'2023-05-15 0:00:00'\n",
    "#     \"\"\"\n",
    "# #--AND camera_location IN {left_tractor_cameras}\n",
    "#     start = time.time()\n",
    "#     rev1_df = athena.get_df(query)\n",
    "#     end = time.time()\n",
    "#     print(end - start)\n",
    "#     rev1_df.to_parquet('/home/alexli/data/all_hitchiker_images/rev1_df.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb456f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4480035, 17)\n",
      "(4479965, 17)\n"
     ]
    }
   ],
   "source": [
    "# full_df = pd.concat([rev1_df, halo_df], ignore_index=True)\n",
    "full_df = halo_df.copy()\n",
    "# drop invalid GPS\n",
    "full_df = full_df[(full_df.geohash != '7zzzzzzzzzzz')].copy()\n",
    "print(full_df.shape)\n",
    "# # drop no speed data\n",
    "def valid_speed(x):\n",
    "    load = json.loads(x)\n",
    "    return 'speed' in load and 200 > load['speed'] > -200 #remove NaN or impossible values\n",
    "full_df = full_df[full_df['gps_can_data__json'].apply(valid_speed)]\n",
    "print(full_df.shape)\n",
    "full_df['speed_kph'] = full_df['gps_can_data__json'].map(lambda x:(json.loads(x)['speed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b584b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TimezoneFinderL()\n",
    "def get_adjusted_timezone(df_row):\n",
    "    timestamp = pd.to_datetime(df_row['collected_on'])\n",
    "    latitude, longitude = df_row['latitude'], df_row['longitude']\n",
    "    if (latitude == 0) or (longitude == 0):\n",
    "        return np.nan\n",
    "    \n",
    "    if isinstance(timestamp, np.datetime64):\n",
    "        timestamp = pd.to_datetime(timestamp)\n",
    "\n",
    "    # Localize and adjust UTC timestamps to local timezone\n",
    "    utc =  pytz.utc.localize(timestamp)\n",
    "    tz = tf.timezone_at(lat=latitude, lng=longitude)\n",
    "    adjusted_timestamp = utc.astimezone(tz).to_pydatetime()\n",
    "\n",
    "    return adjusted_timestamp\n",
    "full_df['collected_on_localtime'] = full_df.apply(get_adjusted_timezone, axis=1)\n",
    "def get_day(t):\n",
    "    return t.strftime(\"%m/%d\")\n",
    "def get_second(t):\n",
    "    return t.strftime(\"%H:%M:%S\")\n",
    "full_df['daystr'] = full_df['collected_on_localtime'].apply(get_day)\n",
    "full_df['secstr'] = full_df['collected_on_localtime'].apply(get_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709265df",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional_dict = {}\n",
    "for pair_dict in ALL_CAMERA_PAIRS_LIST:\n",
    "    for k, v in pair_dict.items():\n",
    "        bidirectional_dict[k] = v\n",
    "        bidirectional_dict[v] = k\n",
    "\n",
    "def make_dataset(from_df, name, description, pairs=[bidirectional_dict]) -> None:\n",
    "    imids = list(from_df['id'])\n",
    "    # print(len(imids))\n",
    "    from_df.to_parquet(f'/home/alexli/data/all_hitchiker_images/{name}.parquet', index=False)\n",
    "    desc = f\"{description} ({len(from_df['id'])} images)\"\n",
    "    # imageids_to_dataset_fast(from_df, name, desc,\n",
    "    #                          camera_pairs_list=pairs, camera_pair_df=df)\n",
    "    Dataset.create(\n",
    "        name=name,\n",
    "        description=desc,\n",
    "        kind=Dataset.KIND_IMAGE,\n",
    "        image_ids=imids,\n",
    "    )\n",
    "\n",
    "def make_dataset_slow(from_df, name, description) -> None:\n",
    "    imids = list(from_df['id'])\n",
    "    desc = f\"{description} ({len(from_df['id'])} images)\"\n",
    "    print(len(imids))\n",
    "    from_df.to_parquet(f'/home/alexli/data/all_hitchiker_images/{name}.parquet', index=False)\n",
    "    imageids_to_dataset(imids, name, dataset_kind='image',\n",
    "                             dataset_description=desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82a182e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stratified_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mrobot_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcamera_location\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mminute\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mhead(\u001b[39m6\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "stratified_df = df.groupby(['robot_name', 'camera_location', 'minute']).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a0f05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_groups \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mrobot_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcamera_location\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdaystr\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mgroups\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_groups = df.groupby(['robot_name', 'camera_location', 'daystr']).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf4188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70489\n"
     ]
    }
   ],
   "source": [
    "imids = list(smudge_df['id'])\n",
    "print(len(imids))\n",
    "# imageids_to_dataset(imids, \"hitchhiker_smudge\", \"Hitchhiker images on smudgy days.\", dataset_kind='image', mode='stereo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7864de8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_groups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m movie \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[df_groups[SMUDGE_DAYS[\u001b[39m0\u001b[39m]]]\u001b[39m.\u001b[39msort_values(\u001b[39m'\u001b[39m\u001b[39mcollected_on_localtime\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_groups' is not defined"
     ]
    }
   ],
   "source": [
    "movie = df.iloc[df_groups[SMUDGE_DAYS[0]]].sort_values('collected_on_localtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fde858",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = df.iloc[df_groups[SMUDGE_DAYS[0]]].sort_values('collected_on_localtime')\n",
    "ncols = len(movie)\n",
    "page = 0\n",
    "rows_per_cat = (4 + ncols) // 5\n",
    "nrows = rows_per_cat\n",
    "fig, ax = plt.subplots(nrows, 5, figsize=(16, nrows * 4))\n",
    "# ax0 = ax[i * rows_per_cat][0]\n",
    "# info = dusty_unmoving_days[i]\n",
    "# ax0.scatter(df.iloc[df_groups[info]]['collected_on_localtime'],\n",
    "#             df.iloc[df_groups[info]]['collected_on_localtime'])#, df.iloc[df_groups[info]]['pred_dust_percent'])\n",
    "# ax0.set_title(str(dusty_unmoving_days[i]))\n",
    "# ax0.set_xlabel(\"Time of day\")\n",
    "# ax0.set_ylabel(\"Predicted dust level\")\n",
    "# tz = tf.timezone_at(lng=dust_df.iloc[0]['longitude'], lat=dust_df.iloc[0]['latitude'])\n",
    "# ax0.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M', tz=tz))\n",
    "# ax0.xaxis.set_major_locator(mdates.HourLocator(interval=3, tz=tz))\n",
    "for j in range(0, ncols):\n",
    "    if j - 1 >= len(movie):\n",
    "        break\n",
    "    df_row = movie.iloc[j - 1 + page * ncols]\n",
    "    im = cv2.imread(str(Path(data_dir) / df_row['artifact_debayeredrgb_0_save_path']))\n",
    "    ax[j // 5][j % 5].imshow(im)\n",
    "    ax[j // 5][j % 5].set_title(df_row['secstr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8be46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
