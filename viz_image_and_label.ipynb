{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "from unittest.mock import MagicMock, patch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "from dl import TEST_DIR\n",
    "from dl.config.label_map_helper import LabelMapHelper\n",
    "from dl.dataset import cutnpaste_presampling\n",
    "from dl.dataset.cutnpaste_preparer import CutnPastePreparer\n",
    "from dl.dataset.dataframe_schema_constants import (\n",
    "    CAMERA_LOCATION,\n",
    "    CAMERA_LOCATION_RIGHT,\n",
    "    HDR_MODE,\n",
    "    UNIQUE_ID,\n",
    ")\n",
    "from dl.utils.config import (\n",
    "    DEFAULT_CUTNPASTE_PREPARER_PARAMS,\n",
    "    DEFAULT_CUTNPASTE_RUNTIME_PARAMS,\n",
    "    DEFAULT_IMAGE_SIZE,\n",
    "    HUMAN_LABELSTR_IN_ANNOTATIONS,\n",
    "    MAX_DEPTH,\n",
    ")\n",
    "from dl.utils.cutnpaste import CutnPaste\n",
    "from dl.utils.helpers import load_master_csv, save_master_csv\n",
    "from tests.example_images.load_image import DatasetWithDatamode\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.rank_zero import rank_zero_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl.utils.helpers import load_master_csv\n",
    "dataset_path = '/data2/jupiter/datasets/Jupiter_train_v6_2/'\n",
    "df = load_master_csv(dataset_path + 'master_annotations_20231019_clean.csv')\n",
    "from dl.dataset.datamodes.npz.rgbd import RGBDNPZ\n",
    "rgbdnpz = RGBDNPZ(dataset_path)\n",
    "artifacts = rgbdnpz.get_artifacts(df.iloc[0])\n",
    "plt.imshow(artifacts['depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_df = df[df['id'] == '5f9d6a1bd61e89229bd3c90a']\n",
    "# save_master_csv(bad_df, dataset_path + 'one_image_sus_label.csv')\n",
    "df = load_master_csv(csv_path=dataset_path + 'one_image_sus_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['id'] == '5f9d6a1bd61e89229bd3c90a']['label_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl.dataset.datamodes.npz.rgbd import RGBDNPZ\n",
    "\n",
    "rgbdnpz = RGBDNPZ(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df[df['id'] == '5f9d6a1bd61e89229bd3c90a'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = rgbdnpz.get_artifacts(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "classlabels_viz_colors = [\n",
    "    \"white\",  # Ignored labels mapped to white so that they do not change color when masked - we don't care about them either way, so a color change does not make sense\n",
    "    \"green\",\n",
    "    \"yellow\",\n",
    "    \"blue\",\n",
    "    \"red\",\n",
    "    \"magenta\",\n",
    "    \"cyan\",\n",
    "    \"lightseagreen\",\n",
    "    \"brown\",\n",
    "    \"magenta\",\n",
    "    \"olive\",\n",
    "    \"wheat\",\n",
    "    \"black\",\n",
    "]\n",
    "classlabels_viz_bounds = [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "classlabels_viz_cmap = mpl.colors.ListedColormap(classlabels_viz_colors)\n",
    "classlabels_viz_norm = mpl.colors.BoundaryNorm(classlabels_viz_bounds, classlabels_viz_cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(artifacts['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = artifacts['label'].copy()\n",
    "label[label == 0] = -1\n",
    "label[label == 2] = 0\n",
    "label[label == 11] = 5\n",
    "plt.imshow(label,classlabels_viz_cmap,classlabels_viz_norm,interpolation=\"nearest\",alpha=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(artifacts['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    s = np.sum(rgbdnpz.get_artifacts(df.iloc[i])['label'] == 11)\n",
    "    if s > 0 and df.iloc[i]['label_map']['11'] == 'Humans':\n",
    "        print(i, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ind = 2\n",
    "hum_ind = 50\n",
    "im_no_hum = rgbdnpz.get_artifacts(df.iloc[base_ind])['image']\n",
    "im_w_hum =  rgbdnpz.get_artifacts(df.iloc[hum_ind])['image']\n",
    "mask =(rgbdnpz.get_artifacts(df.iloc[hum_ind])['label'] == 11)[:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla CNP\n",
    "# plt.imshow(im_w_hum * mask)\n",
    "# plt.imshow(im_no_hum)\n",
    "plt.imshow(im_no_hum * (1 - mask) + im_w_hum * mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pietorch import blend_dst_numpy\n",
    "import torch\n",
    "target : torch.Tensor = torch.Tensor(im_no_hum) # 3 x N x M image to be blended into\n",
    "source : torch.Tensor = torch.Tensor(im_w_hum) # 3 x H x W image to be blended\n",
    "human_mask : torch.Tensor = torch.Tensor(mask)[:,:,0] # H x W mask of which pixels from source to be included\n",
    "corner : torch.Tensor = torch.IntTensor([0,0]) # [y, x] coordinate of location in target for source to be blended\n",
    "# result = blend(target, source, human_mask,corner, True, channels_dim=2)\n",
    "result = blend_dst_numpy(im_no_hum, im_w_hum, mask[:,:,0],corner.numpy(), False, channels_dim=2)\n",
    "\n",
    "plt.imshow(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
